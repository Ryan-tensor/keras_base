{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB400T6B\\Anaconda3\\envs\\venv\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 2.2576 - acc: 0.1643 - val_loss: 2.2272 - val_acc: 0.1633\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 2.2072 - acc: 0.1657 - val_loss: 2.1908 - val_acc: 0.1800\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 2.1730 - acc: 0.1729 - val_loss: 2.1631 - val_acc: 0.1867\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 2.1441 - acc: 0.1786 - val_loss: 2.1372 - val_acc: 0.1867\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 2.1177 - acc: 0.1900 - val_loss: 2.1141 - val_acc: 0.1867\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 2.0940 - acc: 0.2029 - val_loss: 2.0931 - val_acc: 0.2033\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 2.0721 - acc: 0.2071 - val_loss: 2.0727 - val_acc: 0.2067\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 2.0520 - acc: 0.2129 - val_loss: 2.0564 - val_acc: 0.2067\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 2.0342 - acc: 0.2157 - val_loss: 2.0410 - val_acc: 0.2033\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 2.0190 - acc: 0.2143 - val_loss: 2.0269 - val_acc: 0.2067\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 2.0041 - acc: 0.2186 - val_loss: 2.0125 - val_acc: 0.2100\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.9911 - acc: 0.2186 - val_loss: 2.0036 - val_acc: 0.2100\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.9788 - acc: 0.2286 - val_loss: 1.9955 - val_acc: 0.2100\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.9684 - acc: 0.2329 - val_loss: 1.9833 - val_acc: 0.2067\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.9581 - acc: 0.2214 - val_loss: 1.9752 - val_acc: 0.2100\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.9484 - acc: 0.2357 - val_loss: 1.9685 - val_acc: 0.2000\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.9393 - acc: 0.2343 - val_loss: 1.9612 - val_acc: 0.2033\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.9309 - acc: 0.2314 - val_loss: 1.9537 - val_acc: 0.2100\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.9232 - acc: 0.2271 - val_loss: 1.9451 - val_acc: 0.2100\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.9156 - acc: 0.2386 - val_loss: 1.9391 - val_acc: 0.2100\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.9085 - acc: 0.2343 - val_loss: 1.9363 - val_acc: 0.2100\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.9011 - acc: 0.2386 - val_loss: 1.9289 - val_acc: 0.2033\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.8954 - acc: 0.2357 - val_loss: 1.9234 - val_acc: 0.2100\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.8894 - acc: 0.2314 - val_loss: 1.9201 - val_acc: 0.2067\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.8830 - acc: 0.2343 - val_loss: 1.9178 - val_acc: 0.2167\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.8769 - acc: 0.2300 - val_loss: 1.9105 - val_acc: 0.2167\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.8715 - acc: 0.2357 - val_loss: 1.9098 - val_acc: 0.2167\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.8662 - acc: 0.2400 - val_loss: 1.9094 - val_acc: 0.2000\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.8615 - acc: 0.2400 - val_loss: 1.9041 - val_acc: 0.1900\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.8565 - acc: 0.2243 - val_loss: 1.8976 - val_acc: 0.2167\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.8513 - acc: 0.2471 - val_loss: 1.8971 - val_acc: 0.1933\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.8463 - acc: 0.2371 - val_loss: 1.8925 - val_acc: 0.1900\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.8423 - acc: 0.2229 - val_loss: 1.8874 - val_acc: 0.2067\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.8382 - acc: 0.2371 - val_loss: 1.8808 - val_acc: 0.1933\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.8335 - acc: 0.2471 - val_loss: 1.8836 - val_acc: 0.1900\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.8299 - acc: 0.2343 - val_loss: 1.8756 - val_acc: 0.1967\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.8257 - acc: 0.2486 - val_loss: 1.8744 - val_acc: 0.1800\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.8220 - acc: 0.2371 - val_loss: 1.8700 - val_acc: 0.1933\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.8184 - acc: 0.2457 - val_loss: 1.8706 - val_acc: 0.1767\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.8144 - acc: 0.2314 - val_loss: 1.8677 - val_acc: 0.2000\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.8105 - acc: 0.2400 - val_loss: 1.8668 - val_acc: 0.1833\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.8075 - acc: 0.2471 - val_loss: 1.8635 - val_acc: 0.1800\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.8046 - acc: 0.2429 - val_loss: 1.8610 - val_acc: 0.1700\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.8001 - acc: 0.2371 - val_loss: 1.8566 - val_acc: 0.1967\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.7970 - acc: 0.2429 - val_loss: 1.8564 - val_acc: 0.1700\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7939 - acc: 0.2271 - val_loss: 1.8528 - val_acc: 0.1933\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.7913 - acc: 0.2600 - val_loss: 1.8551 - val_acc: 0.1833\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.7886 - acc: 0.2471 - val_loss: 1.8543 - val_acc: 0.1833\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.7858 - acc: 0.2486 - val_loss: 1.8504 - val_acc: 0.1867\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.7819 - acc: 0.2471 - val_loss: 1.8443 - val_acc: 0.2267\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.7794 - acc: 0.2643 - val_loss: 1.8468 - val_acc: 0.1900\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.7762 - acc: 0.2486 - val_loss: 1.8411 - val_acc: 0.1933\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.7744 - acc: 0.2514 - val_loss: 1.8486 - val_acc: 0.2000\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7716 - acc: 0.2700 - val_loss: 1.8472 - val_acc: 0.1800\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.7687 - acc: 0.2500 - val_loss: 1.8363 - val_acc: 0.2033\n",
      "Epoch 56/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7672 - acc: 0.2543 - val_loss: 1.8430 - val_acc: 0.2200\n",
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.7641 - acc: 0.2714 - val_loss: 1.8389 - val_acc: 0.2167\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.7616 - acc: 0.2557 - val_loss: 1.8347 - val_acc: 0.2267\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.7590 - acc: 0.2671 - val_loss: 1.8329 - val_acc: 0.2233\n",
      "Epoch 60/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7552 - acc: 0.2614 - val_loss: 1.8256 - val_acc: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7566 - acc: 0.2814 - val_loss: 1.8335 - val_acc: 0.2400\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.7531 - acc: 0.2729 - val_loss: 1.8311 - val_acc: 0.2267\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.7505 - acc: 0.2857 - val_loss: 1.8299 - val_acc: 0.2000\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.7483 - acc: 0.2800 - val_loss: 1.8268 - val_acc: 0.2200\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7457 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2033\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.7439 - acc: 0.2786 - val_loss: 1.8296 - val_acc: 0.2067\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.7419 - acc: 0.2714 - val_loss: 1.8299 - val_acc: 0.2067\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.7405 - acc: 0.2729 - val_loss: 1.8238 - val_acc: 0.2000\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7376 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2167\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7356 - acc: 0.2857 - val_loss: 1.8269 - val_acc: 0.2433\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.7345 - acc: 0.2800 - val_loss: 1.8214 - val_acc: 0.2167\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7328 - acc: 0.2857 - val_loss: 1.8226 - val_acc: 0.2133\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.7298 - acc: 0.2800 - val_loss: 1.8252 - val_acc: 0.2467\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.7283 - acc: 0.2857 - val_loss: 1.8257 - val_acc: 0.1967\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.7268 - acc: 0.2786 - val_loss: 1.8190 - val_acc: 0.2267\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.7255 - acc: 0.2857 - val_loss: 1.8196 - val_acc: 0.2233\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.7228 - acc: 0.3057 - val_loss: 1.8232 - val_acc: 0.2033\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.7212 - acc: 0.2857 - val_loss: 1.8187 - val_acc: 0.1933\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.7199 - acc: 0.2829 - val_loss: 1.8203 - val_acc: 0.2433\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.7188 - acc: 0.2929 - val_loss: 1.8196 - val_acc: 0.2067\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.7165 - acc: 0.2843 - val_loss: 1.8256 - val_acc: 0.2067\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.7142 - acc: 0.2829 - val_loss: 1.8144 - val_acc: 0.2667\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.7132 - acc: 0.2857 - val_loss: 1.8190 - val_acc: 0.2400\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.7127 - acc: 0.2986 - val_loss: 1.8220 - val_acc: 0.2167\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.7097 - acc: 0.2971 - val_loss: 1.8159 - val_acc: 0.2267\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.7082 - acc: 0.2800 - val_loss: 1.8136 - val_acc: 0.2633\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.7051 - acc: 0.3100 - val_loss: 1.8191 - val_acc: 0.2733\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.7062 - acc: 0.3043 - val_loss: 1.8125 - val_acc: 0.2433\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.7043 - acc: 0.3043 - val_loss: 1.8167 - val_acc: 0.2167\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.7027 - acc: 0.2843 - val_loss: 1.8151 - val_acc: 0.2233\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.7017 - acc: 0.3086 - val_loss: 1.8185 - val_acc: 0.2167\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6987 - acc: 0.3129 - val_loss: 1.8215 - val_acc: 0.2067\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.6980 - acc: 0.3071 - val_loss: 1.8173 - val_acc: 0.2767\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6970 - acc: 0.3157 - val_loss: 1.8176 - val_acc: 0.2100\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.6943 - acc: 0.2986 - val_loss: 1.8194 - val_acc: 0.2833\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6948 - acc: 0.3014 - val_loss: 1.8095 - val_acc: 0.2233\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6930 - acc: 0.3057 - val_loss: 1.8228 - val_acc: 0.2300\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6921 - acc: 0.3043 - val_loss: 1.8117 - val_acc: 0.2200\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.6901 - acc: 0.3129 - val_loss: 1.8252 - val_acc: 0.2233\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6890 - acc: 0.3129 - val_loss: 1.8210 - val_acc: 0.2267\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.6878 - acc: 0.3143 - val_loss: 1.8190 - val_acc: 0.2200\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.6877 - acc: 0.3014 - val_loss: 1.8219 - val_acc: 0.2300\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.6843 - acc: 0.3000 - val_loss: 1.8102 - val_acc: 0.2500\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.6842 - acc: 0.3200 - val_loss: 1.8122 - val_acc: 0.2200\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.6821 - acc: 0.3071 - val_loss: 1.8063 - val_acc: 0.2067\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6814 - acc: 0.3114 - val_loss: 1.8173 - val_acc: 0.2200\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6805 - acc: 0.3071 - val_loss: 1.8228 - val_acc: 0.2367\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6784 - acc: 0.3071 - val_loss: 1.8167 - val_acc: 0.2767\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.6782 - acc: 0.3143 - val_loss: 1.8178 - val_acc: 0.2300\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.6775 - acc: 0.3171 - val_loss: 1.8147 - val_acc: 0.2133\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.6775 - acc: 0.3043 - val_loss: 1.8174 - val_acc: 0.2233\n",
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.6745 - acc: 0.3129 - val_loss: 1.8193 - val_acc: 0.2267\n",
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.6737 - acc: 0.3100 - val_loss: 1.8196 - val_acc: 0.2300\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.6724 - acc: 0.3014 - val_loss: 1.8221 - val_acc: 0.2300\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.6711 - acc: 0.3071 - val_loss: 1.8128 - val_acc: 0.2333\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6703 - acc: 0.3157 - val_loss: 1.8255 - val_acc: 0.2300\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6694 - acc: 0.3100 - val_loss: 1.8229 - val_acc: 0.2333\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6682 - acc: 0.3114 - val_loss: 1.8262 - val_acc: 0.2333\n",
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.6670 - acc: 0.3257 - val_loss: 1.8216 - val_acc: 0.2200\n",
      "Epoch 120/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6661 - acc: 0.3114 - val_loss: 1.8219 - val_acc: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6646 - acc: 0.3071 - val_loss: 1.8132 - val_acc: 0.2233\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.6637 - acc: 0.3229 - val_loss: 1.8194 - val_acc: 0.2200\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.6629 - acc: 0.3100 - val_loss: 1.8139 - val_acc: 0.2200\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.6619 - acc: 0.3143 - val_loss: 1.8187 - val_acc: 0.2267\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.6606 - acc: 0.3229 - val_loss: 1.8212 - val_acc: 0.2333\n",
      "Epoch 126/3000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.6592 - acc: 0.3143 - val_loss: 1.8245 - val_acc: 0.2233\n",
      "Epoch 127/3000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.6583 - acc: 0.3143 - val_loss: 1.8147 - val_acc: 0.2333\n",
      "Epoch 128/3000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 1.6565 - acc: 0.3314 - val_loss: 1.8280 - val_acc: 0.2300\n",
      "Epoch 129/3000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.6570 - acc: 0.3143 - val_loss: 1.8193 - val_acc: 0.2200\n",
      "Epoch 130/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6548 - acc: 0.3214 - val_loss: 1.8124 - val_acc: 0.2500\n",
      "Epoch 131/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6547 - acc: 0.3229 - val_loss: 1.8202 - val_acc: 0.2500\n",
      "Epoch 132/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6545 - acc: 0.3200 - val_loss: 1.8133 - val_acc: 0.2267\n",
      "Epoch 133/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.6524 - acc: 0.3143 - val_loss: 1.8317 - val_acc: 0.2400\n",
      "Epoch 134/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.6514 - acc: 0.3214 - val_loss: 1.8227 - val_acc: 0.2733\n",
      "Epoch 135/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6512 - acc: 0.3314 - val_loss: 1.8233 - val_acc: 0.2267\n",
      "Epoch 136/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6493 - acc: 0.3186 - val_loss: 1.8168 - val_acc: 0.2200\n",
      "Epoch 137/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.6483 - acc: 0.3214 - val_loss: 1.8191 - val_acc: 0.2200\n",
      "Epoch 138/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.6488 - acc: 0.3257 - val_loss: 1.8199 - val_acc: 0.2167\n",
      "Epoch 139/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.6466 - acc: 0.3257 - val_loss: 1.8512 - val_acc: 0.2433\n",
      "Epoch 140/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6465 - acc: 0.3214 - val_loss: 1.8168 - val_acc: 0.2200\n",
      "Epoch 141/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.6446 - acc: 0.3229 - val_loss: 1.8284 - val_acc: 0.2267\n",
      "Epoch 142/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.6437 - acc: 0.3243 - val_loss: 1.8154 - val_acc: 0.2633\n",
      "Epoch 143/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6437 - acc: 0.3329 - val_loss: 1.8292 - val_acc: 0.2433\n",
      "Epoch 144/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6431 - acc: 0.3329 - val_loss: 1.8273 - val_acc: 0.2300\n",
      "Epoch 145/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.6419 - acc: 0.3271 - val_loss: 1.8198 - val_acc: 0.2200\n",
      "Epoch 146/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.6392 - acc: 0.3343 - val_loss: 1.8324 - val_acc: 0.2233\n",
      "Epoch 147/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.6412 - acc: 0.3100 - val_loss: 1.8328 - val_acc: 0.2333\n",
      "Epoch 148/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6390 - acc: 0.3243 - val_loss: 1.8306 - val_acc: 0.2500\n",
      "Epoch 149/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.6375 - acc: 0.3271 - val_loss: 1.8189 - val_acc: 0.2133\n",
      "Epoch 150/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.6367 - acc: 0.3229 - val_loss: 1.8276 - val_acc: 0.2233\n",
      "Epoch 151/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.6364 - acc: 0.3257 - val_loss: 1.8245 - val_acc: 0.2267\n",
      "Epoch 152/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6350 - acc: 0.3214 - val_loss: 1.8290 - val_acc: 0.2233\n",
      "Epoch 153/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.6340 - acc: 0.3400 - val_loss: 1.8270 - val_acc: 0.2300\n",
      "Epoch 154/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.6319 - acc: 0.3457 - val_loss: 1.8343 - val_acc: 0.2233\n",
      "Epoch 155/3000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 1.6316 - acc: 0.3243 - val_loss: 1.8183 - val_acc: 0.2367\n",
      "Epoch 156/3000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.6326 - acc: 0.3329 - val_loss: 1.8309 - val_acc: 0.2200\n",
      "Epoch 157/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6308 - acc: 0.3300 - val_loss: 1.8241 - val_acc: 0.2200\n",
      "Epoch 158/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.6308 - acc: 0.3343 - val_loss: 1.8329 - val_acc: 0.2300\n",
      "Epoch 159/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.6285 - acc: 0.3257 - val_loss: 1.8337 - val_acc: 0.2433\n",
      "Epoch 160/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.6278 - acc: 0.3300 - val_loss: 1.8304 - val_acc: 0.2233\n",
      "Epoch 161/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.6271 - acc: 0.3257 - val_loss: 1.8406 - val_acc: 0.2300\n",
      "Epoch 162/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6265 - acc: 0.3271 - val_loss: 1.8351 - val_acc: 0.2267\n",
      "Epoch 163/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6254 - acc: 0.3371 - val_loss: 1.8365 - val_acc: 0.2300\n",
      "Epoch 164/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6239 - acc: 0.3314 - val_loss: 1.8264 - val_acc: 0.2100\n",
      "Epoch 165/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.6236 - acc: 0.3200 - val_loss: 1.8397 - val_acc: 0.2367\n",
      "Epoch 166/3000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.6231 - acc: 0.3286 - val_loss: 1.8345 - val_acc: 0.2233\n",
      "Epoch 167/3000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 1.6221 - acc: 0.3314 - val_loss: 1.8389 - val_acc: 0.2633\n",
      "Epoch 168/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.6208 - acc: 0.3400 - val_loss: 1.8444 - val_acc: 0.2200\n",
      "Epoch 169/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.6198 - acc: 0.3400 - val_loss: 1.8524 - val_acc: 0.2233\n",
      "Epoch 170/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6191 - acc: 0.3371 - val_loss: 1.8369 - val_acc: 0.2233\n",
      "Epoch 171/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6170 - acc: 0.3271 - val_loss: 1.8517 - val_acc: 0.2600\n",
      "Epoch 172/3000\n",
      "700/700 [==============================] - 0s 159us/step - loss: 1.6164 - acc: 0.3371 - val_loss: 1.8403 - val_acc: 0.2133\n",
      "Epoch 173/3000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 1.6182 - acc: 0.3400 - val_loss: 1.8396 - val_acc: 0.2367\n",
      "Epoch 174/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6167 - acc: 0.3314 - val_loss: 1.8425 - val_acc: 0.2200\n",
      "Epoch 175/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.6167 - acc: 0.3343 - val_loss: 1.8392 - val_acc: 0.2200\n",
      "Epoch 176/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6143 - acc: 0.3243 - val_loss: 1.8419 - val_acc: 0.2633\n",
      "Epoch 177/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.6134 - acc: 0.3386 - val_loss: 1.8377 - val_acc: 0.2167\n",
      "Epoch 178/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.6139 - acc: 0.3386 - val_loss: 1.8441 - val_acc: 0.2267\n",
      "Epoch 179/3000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.6134 - acc: 0.3386 - val_loss: 1.8371 - val_acc: 0.2233\n",
      "Epoch 180/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.6110 - acc: 0.3371 - val_loss: 1.8411 - val_acc: 0.2667\n",
      "Epoch 181/3000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.6115 - acc: 0.3457 - val_loss: 1.8336 - val_acc: 0.2567\n",
      "Epoch 182/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.6106 - acc: 0.3457 - val_loss: 1.8362 - val_acc: 0.2167\n",
      "Epoch 183/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.6114 - acc: 0.3286 - val_loss: 1.8409 - val_acc: 0.2333\n",
      "Epoch 184/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.6093 - acc: 0.3457 - val_loss: 1.8452 - val_acc: 0.2267\n",
      "Epoch 185/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6076 - acc: 0.3386 - val_loss: 1.8639 - val_acc: 0.2200\n",
      "Epoch 186/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6086 - acc: 0.3443 - val_loss: 1.8447 - val_acc: 0.2233\n",
      "Epoch 187/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.6066 - acc: 0.3543 - val_loss: 1.8452 - val_acc: 0.2167\n",
      "Epoch 188/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.6075 - acc: 0.3386 - val_loss: 1.8419 - val_acc: 0.2133\n",
      "Epoch 189/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.6045 - acc: 0.3529 - val_loss: 1.8536 - val_acc: 0.2233\n",
      "Epoch 190/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.6065 - acc: 0.3314 - val_loss: 1.8407 - val_acc: 0.2333\n",
      "Epoch 191/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.6042 - acc: 0.3529 - val_loss: 1.8569 - val_acc: 0.2233\n",
      "Epoch 192/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.6044 - acc: 0.3486 - val_loss: 1.8507 - val_acc: 0.2200\n",
      "Epoch 193/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6029 - acc: 0.3371 - val_loss: 1.8543 - val_acc: 0.2267\n",
      "Epoch 194/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.6025 - acc: 0.3414 - val_loss: 1.8474 - val_acc: 0.2300\n",
      "Epoch 195/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6019 - acc: 0.3457 - val_loss: 1.8456 - val_acc: 0.2467\n",
      "Epoch 196/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.6016 - acc: 0.3514 - val_loss: 1.8475 - val_acc: 0.2167\n",
      "Epoch 197/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.6002 - acc: 0.3443 - val_loss: 1.8491 - val_acc: 0.2267\n",
      "Epoch 198/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.6005 - acc: 0.3386 - val_loss: 1.8594 - val_acc: 0.2200\n",
      "Epoch 199/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6003 - acc: 0.3414 - val_loss: 1.8560 - val_acc: 0.2200\n",
      "Epoch 200/3000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.5975 - acc: 0.3457 - val_loss: 1.8606 - val_acc: 0.2633\n",
      "Epoch 201/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5986 - acc: 0.3471 - val_loss: 1.8472 - val_acc: 0.2167\n",
      "Epoch 202/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5979 - acc: 0.3429 - val_loss: 1.8493 - val_acc: 0.2133\n",
      "Epoch 203/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5965 - acc: 0.3329 - val_loss: 1.8564 - val_acc: 0.2267\n",
      "Epoch 204/3000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 1.5953 - acc: 0.3557 - val_loss: 1.8463 - val_acc: 0.2100\n",
      "Epoch 205/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.5953 - acc: 0.3429 - val_loss: 1.8491 - val_acc: 0.2133\n",
      "Epoch 206/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.5945 - acc: 0.3486 - val_loss: 1.8468 - val_acc: 0.2133\n",
      "Epoch 207/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5947 - acc: 0.3543 - val_loss: 1.8545 - val_acc: 0.2233\n",
      "Epoch 208/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.5920 - acc: 0.3414 - val_loss: 1.8555 - val_acc: 0.2233\n",
      "Epoch 209/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.5919 - acc: 0.3500 - val_loss: 1.8519 - val_acc: 0.2300\n",
      "Epoch 210/3000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5914 - acc: 0.3443 - val_loss: 1.8497 - val_acc: 0.2267\n",
      "Epoch 211/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5903 - acc: 0.3357 - val_loss: 1.8455 - val_acc: 0.2567\n",
      "Epoch 212/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5913 - acc: 0.3471 - val_loss: 1.8592 - val_acc: 0.2200\n",
      "Epoch 213/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5894 - acc: 0.3500 - val_loss: 1.8517 - val_acc: 0.2233\n",
      "Epoch 214/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5905 - acc: 0.3443 - val_loss: 1.8541 - val_acc: 0.2267\n",
      "Epoch 215/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5886 - acc: 0.3514 - val_loss: 1.8602 - val_acc: 0.2667\n",
      "Epoch 216/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5895 - acc: 0.3486 - val_loss: 1.8624 - val_acc: 0.2267\n",
      "Epoch 217/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5880 - acc: 0.3486 - val_loss: 1.8654 - val_acc: 0.2300\n",
      "Epoch 218/3000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 1.5876 - acc: 0.3457 - val_loss: 1.8605 - val_acc: 0.2333\n",
      "Epoch 219/3000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.5866 - acc: 0.3486 - val_loss: 1.8680 - val_acc: 0.2267\n",
      "Epoch 220/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5855 - acc: 0.3514 - val_loss: 1.8590 - val_acc: 0.2267\n",
      "Epoch 221/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.5856 - acc: 0.3471 - val_loss: 1.8581 - val_acc: 0.2267\n",
      "Epoch 222/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.5845 - acc: 0.3514 - val_loss: 1.8742 - val_acc: 0.2500\n",
      "Epoch 223/3000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 1.5844 - acc: 0.3443 - val_loss: 1.8609 - val_acc: 0.2600\n",
      "Epoch 224/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.5845 - acc: 0.3514 - val_loss: 1.8760 - val_acc: 0.2433\n",
      "Epoch 225/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5833 - acc: 0.3457 - val_loss: 1.8568 - val_acc: 0.2167\n",
      "Epoch 226/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.5836 - acc: 0.3486 - val_loss: 1.8685 - val_acc: 0.2233\n",
      "Epoch 227/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5825 - acc: 0.3500 - val_loss: 1.8636 - val_acc: 0.2167\n",
      "Epoch 228/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.5824 - acc: 0.3457 - val_loss: 1.8677 - val_acc: 0.2233\n",
      "Epoch 229/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5801 - acc: 0.3486 - val_loss: 1.8690 - val_acc: 0.2233\n",
      "Epoch 230/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5818 - acc: 0.3471 - val_loss: 1.8636 - val_acc: 0.2167\n",
      "Epoch 231/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5797 - acc: 0.3529 - val_loss: 1.8606 - val_acc: 0.2200\n",
      "Epoch 232/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5810 - acc: 0.3514 - val_loss: 1.8732 - val_acc: 0.2133\n",
      "Epoch 233/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.5796 - acc: 0.3471 - val_loss: 1.8782 - val_acc: 0.2200\n",
      "Epoch 234/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5791 - acc: 0.3457 - val_loss: 1.8666 - val_acc: 0.2133\n",
      "Epoch 235/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5777 - acc: 0.3557 - val_loss: 1.8694 - val_acc: 0.2100\n",
      "Epoch 236/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5778 - acc: 0.3457 - val_loss: 1.8665 - val_acc: 0.2133\n",
      "Epoch 237/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5770 - acc: 0.3429 - val_loss: 1.8719 - val_acc: 0.2267\n",
      "Epoch 238/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5774 - acc: 0.3471 - val_loss: 1.8614 - val_acc: 0.2200\n",
      "Epoch 239/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5770 - acc: 0.3571 - val_loss: 1.8683 - val_acc: 0.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5749 - acc: 0.3571 - val_loss: 1.8721 - val_acc: 0.2500\n",
      "Epoch 241/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5749 - acc: 0.3571 - val_loss: 1.8739 - val_acc: 0.2433\n",
      "Epoch 242/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5743 - acc: 0.3514 - val_loss: 1.8734 - val_acc: 0.2100\n",
      "Epoch 243/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5743 - acc: 0.3629 - val_loss: 1.8807 - val_acc: 0.2200\n",
      "Epoch 244/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5713 - acc: 0.3571 - val_loss: 1.8725 - val_acc: 0.2200\n",
      "Epoch 245/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5715 - acc: 0.3586 - val_loss: 1.8840 - val_acc: 0.2200\n",
      "Epoch 246/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5711 - acc: 0.3543 - val_loss: 1.8706 - val_acc: 0.2533\n",
      "Epoch 247/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5722 - acc: 0.3571 - val_loss: 1.8629 - val_acc: 0.2167\n",
      "Epoch 248/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5716 - acc: 0.3557 - val_loss: 1.8699 - val_acc: 0.2233\n",
      "Epoch 249/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5712 - acc: 0.3457 - val_loss: 1.8840 - val_acc: 0.2267\n",
      "Epoch 250/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5680 - acc: 0.3657 - val_loss: 1.8980 - val_acc: 0.2167\n",
      "Epoch 251/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5704 - acc: 0.3486 - val_loss: 1.8793 - val_acc: 0.2400\n",
      "Epoch 252/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5682 - acc: 0.3643 - val_loss: 1.8744 - val_acc: 0.2200\n",
      "Epoch 253/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5689 - acc: 0.3600 - val_loss: 1.8819 - val_acc: 0.2133\n",
      "Epoch 254/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5677 - acc: 0.3586 - val_loss: 1.8835 - val_acc: 0.2267\n",
      "Epoch 255/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5681 - acc: 0.3457 - val_loss: 1.8713 - val_acc: 0.2267\n",
      "Epoch 256/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5657 - acc: 0.3571 - val_loss: 1.8761 - val_acc: 0.2533\n",
      "Epoch 257/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5667 - acc: 0.3514 - val_loss: 1.8913 - val_acc: 0.2467\n",
      "Epoch 258/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5649 - acc: 0.3614 - val_loss: 1.8946 - val_acc: 0.2567\n",
      "Epoch 259/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5648 - acc: 0.3643 - val_loss: 1.8911 - val_acc: 0.2167\n",
      "Epoch 260/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.5657 - acc: 0.3600 - val_loss: 1.8977 - val_acc: 0.2233\n",
      "Epoch 261/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5637 - acc: 0.3557 - val_loss: 1.8740 - val_acc: 0.2167\n",
      "Epoch 262/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.5637 - acc: 0.3600 - val_loss: 1.8847 - val_acc: 0.2100\n",
      "Epoch 263/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5632 - acc: 0.3629 - val_loss: 1.8858 - val_acc: 0.2100\n",
      "Epoch 264/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5639 - acc: 0.3529 - val_loss: 1.8824 - val_acc: 0.2133\n",
      "Epoch 265/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5638 - acc: 0.3686 - val_loss: 1.8911 - val_acc: 0.2200\n",
      "Epoch 266/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5614 - acc: 0.3614 - val_loss: 1.8974 - val_acc: 0.2500\n",
      "Epoch 267/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.5613 - acc: 0.3629 - val_loss: 1.8883 - val_acc: 0.2300\n",
      "Epoch 268/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5612 - acc: 0.3586 - val_loss: 1.8755 - val_acc: 0.2100\n",
      "Epoch 269/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5601 - acc: 0.3629 - val_loss: 1.8843 - val_acc: 0.2133\n",
      "Epoch 270/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5595 - acc: 0.3671 - val_loss: 1.8682 - val_acc: 0.2333\n",
      "Epoch 271/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5610 - acc: 0.3657 - val_loss: 1.8912 - val_acc: 0.2333\n",
      "Epoch 272/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5596 - acc: 0.3600 - val_loss: 1.9029 - val_acc: 0.2267\n",
      "Epoch 273/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5591 - acc: 0.3571 - val_loss: 1.8965 - val_acc: 0.2167\n",
      "Epoch 274/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5588 - acc: 0.3457 - val_loss: 1.8842 - val_acc: 0.2233\n",
      "Epoch 275/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.5589 - acc: 0.3614 - val_loss: 1.8915 - val_acc: 0.2200\n",
      "Epoch 276/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5579 - acc: 0.3529 - val_loss: 1.8969 - val_acc: 0.2533\n",
      "Epoch 277/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.5581 - acc: 0.3729 - val_loss: 1.8910 - val_acc: 0.2167\n",
      "Epoch 278/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5579 - acc: 0.3600 - val_loss: 1.9032 - val_acc: 0.2300\n",
      "Epoch 279/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5559 - acc: 0.3571 - val_loss: 1.8859 - val_acc: 0.2167\n",
      "Epoch 280/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5559 - acc: 0.3700 - val_loss: 1.8876 - val_acc: 0.2167\n",
      "Epoch 281/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5541 - acc: 0.3571 - val_loss: 1.8907 - val_acc: 0.2333\n",
      "Epoch 282/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5553 - acc: 0.3671 - val_loss: 1.8840 - val_acc: 0.2133\n",
      "Epoch 283/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5543 - acc: 0.3557 - val_loss: 1.8928 - val_acc: 0.2167\n",
      "Epoch 284/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5542 - acc: 0.3614 - val_loss: 1.8937 - val_acc: 0.2600\n",
      "Epoch 285/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5535 - acc: 0.3543 - val_loss: 1.8887 - val_acc: 0.2200\n",
      "Epoch 286/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5536 - acc: 0.3586 - val_loss: 1.8990 - val_acc: 0.2233\n",
      "Epoch 287/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.5527 - acc: 0.3671 - val_loss: 1.9020 - val_acc: 0.2133\n",
      "Epoch 288/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5525 - acc: 0.3600 - val_loss: 1.8931 - val_acc: 0.2133\n",
      "Epoch 289/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5519 - acc: 0.3586 - val_loss: 1.9015 - val_acc: 0.2167\n",
      "Epoch 290/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.5514 - acc: 0.3657 - val_loss: 1.9033 - val_acc: 0.2200\n",
      "Epoch 291/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5514 - acc: 0.3586 - val_loss: 1.9038 - val_acc: 0.2167\n",
      "Epoch 292/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5509 - acc: 0.3543 - val_loss: 1.8996 - val_acc: 0.2433\n",
      "Epoch 293/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5507 - acc: 0.3543 - val_loss: 1.9012 - val_acc: 0.2300\n",
      "Epoch 294/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5497 - acc: 0.3543 - val_loss: 1.9003 - val_acc: 0.2533\n",
      "Epoch 295/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5499 - acc: 0.3657 - val_loss: 1.9121 - val_acc: 0.2200\n",
      "Epoch 296/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5495 - acc: 0.3571 - val_loss: 1.9105 - val_acc: 0.2133\n",
      "Epoch 297/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5479 - acc: 0.3571 - val_loss: 1.9129 - val_acc: 0.2167\n",
      "Epoch 298/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5477 - acc: 0.3486 - val_loss: 1.8958 - val_acc: 0.2267\n",
      "Epoch 299/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.5485 - acc: 0.3686 - val_loss: 1.9146 - val_acc: 0.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.5472 - acc: 0.3629 - val_loss: 1.9031 - val_acc: 0.2300\n",
      "Epoch 301/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5470 - acc: 0.3629 - val_loss: 1.8935 - val_acc: 0.2200\n",
      "Epoch 302/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5479 - acc: 0.3657 - val_loss: 1.9082 - val_acc: 0.2167\n",
      "Epoch 303/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5465 - acc: 0.3529 - val_loss: 1.9016 - val_acc: 0.2333\n",
      "Epoch 304/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5452 - acc: 0.3671 - val_loss: 1.9067 - val_acc: 0.2200\n",
      "Epoch 305/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.5431 - acc: 0.3643 - val_loss: 1.9153 - val_acc: 0.2267\n",
      "Epoch 306/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5458 - acc: 0.3614 - val_loss: 1.9109 - val_acc: 0.2267\n",
      "Epoch 307/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5436 - acc: 0.3657 - val_loss: 1.9071 - val_acc: 0.2267\n",
      "Epoch 308/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.5453 - acc: 0.3600 - val_loss: 1.9137 - val_acc: 0.2333\n",
      "Epoch 309/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5436 - acc: 0.3643 - val_loss: 1.9128 - val_acc: 0.2367\n",
      "Epoch 310/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5448 - acc: 0.3657 - val_loss: 1.9117 - val_acc: 0.2167\n",
      "Epoch 311/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.5426 - acc: 0.3571 - val_loss: 1.9065 - val_acc: 0.2300\n",
      "Epoch 312/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5423 - acc: 0.3729 - val_loss: 1.9281 - val_acc: 0.2367\n",
      "Epoch 313/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5387 - acc: 0.3657 - val_loss: 1.9055 - val_acc: 0.2600\n",
      "Epoch 314/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.5431 - acc: 0.3714 - val_loss: 1.9104 - val_acc: 0.2300\n",
      "Epoch 315/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5406 - acc: 0.3657 - val_loss: 1.9130 - val_acc: 0.2233\n",
      "Epoch 316/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5405 - acc: 0.3600 - val_loss: 1.9144 - val_acc: 0.2267\n",
      "Epoch 317/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.5412 - acc: 0.3600 - val_loss: 1.9220 - val_acc: 0.2300\n",
      "Epoch 318/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5408 - acc: 0.3614 - val_loss: 1.9107 - val_acc: 0.2300\n",
      "Epoch 319/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5390 - acc: 0.3600 - val_loss: 1.9100 - val_acc: 0.2300\n",
      "Epoch 320/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.5392 - acc: 0.3629 - val_loss: 1.9287 - val_acc: 0.2267\n",
      "Epoch 321/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5392 - acc: 0.3686 - val_loss: 1.9266 - val_acc: 0.2300\n",
      "Epoch 322/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5375 - acc: 0.3671 - val_loss: 1.9188 - val_acc: 0.2533\n",
      "Epoch 323/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5383 - acc: 0.3714 - val_loss: 1.9200 - val_acc: 0.2300\n",
      "Epoch 324/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.5373 - acc: 0.3671 - val_loss: 1.9233 - val_acc: 0.2200\n",
      "Epoch 325/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5386 - acc: 0.3600 - val_loss: 1.9139 - val_acc: 0.2100\n",
      "Epoch 326/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.5366 - acc: 0.3614 - val_loss: 1.9263 - val_acc: 0.2267\n",
      "Epoch 327/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5360 - acc: 0.3743 - val_loss: 1.9368 - val_acc: 0.2333\n",
      "Epoch 328/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5367 - acc: 0.3614 - val_loss: 1.9304 - val_acc: 0.2233\n",
      "Epoch 329/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5355 - acc: 0.3714 - val_loss: 1.9144 - val_acc: 0.2300\n",
      "Epoch 330/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5352 - acc: 0.3586 - val_loss: 1.9220 - val_acc: 0.2333\n",
      "Epoch 331/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5339 - acc: 0.3700 - val_loss: 1.9151 - val_acc: 0.2200\n",
      "Epoch 332/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5345 - acc: 0.3586 - val_loss: 1.9316 - val_acc: 0.2500\n",
      "Epoch 333/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5358 - acc: 0.3686 - val_loss: 1.9233 - val_acc: 0.2233\n",
      "Epoch 334/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.5349 - acc: 0.3629 - val_loss: 1.9286 - val_acc: 0.2233\n",
      "Epoch 335/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.5326 - acc: 0.3771 - val_loss: 1.9245 - val_acc: 0.2567\n",
      "Epoch 336/3000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.5335 - acc: 0.3800 - val_loss: 1.9244 - val_acc: 0.2267\n",
      "Epoch 337/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5330 - acc: 0.3743 - val_loss: 1.9318 - val_acc: 0.2267\n",
      "Epoch 338/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5320 - acc: 0.3757 - val_loss: 1.9207 - val_acc: 0.2133\n",
      "Epoch 339/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5314 - acc: 0.3700 - val_loss: 1.9155 - val_acc: 0.2167\n",
      "Epoch 340/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5328 - acc: 0.3743 - val_loss: 1.9400 - val_acc: 0.2267\n",
      "Epoch 341/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5316 - acc: 0.3771 - val_loss: 1.9258 - val_acc: 0.2267\n",
      "Epoch 342/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5313 - acc: 0.3600 - val_loss: 1.9436 - val_acc: 0.2167\n",
      "Epoch 343/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5310 - acc: 0.3671 - val_loss: 1.9324 - val_acc: 0.2300\n",
      "Epoch 344/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5308 - acc: 0.3671 - val_loss: 1.9425 - val_acc: 0.2300\n",
      "Epoch 345/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5291 - acc: 0.3686 - val_loss: 1.9437 - val_acc: 0.2567\n",
      "Epoch 346/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5301 - acc: 0.3700 - val_loss: 1.9310 - val_acc: 0.2267\n",
      "Epoch 347/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5279 - acc: 0.3814 - val_loss: 1.9183 - val_acc: 0.2200\n",
      "Epoch 348/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5284 - acc: 0.3643 - val_loss: 1.9294 - val_acc: 0.2133\n",
      "Epoch 349/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5281 - acc: 0.3686 - val_loss: 1.9272 - val_acc: 0.2133\n",
      "Epoch 350/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5281 - acc: 0.3657 - val_loss: 1.9311 - val_acc: 0.2300\n",
      "Epoch 351/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.5264 - acc: 0.3771 - val_loss: 1.9309 - val_acc: 0.2333\n",
      "Epoch 352/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5283 - acc: 0.3729 - val_loss: 1.9339 - val_acc: 0.2300\n",
      "Epoch 353/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.5256 - acc: 0.3671 - val_loss: 1.9413 - val_acc: 0.2267\n",
      "Epoch 354/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5279 - acc: 0.3671 - val_loss: 1.9339 - val_acc: 0.2167\n",
      "Epoch 355/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5262 - acc: 0.3629 - val_loss: 1.9548 - val_acc: 0.2267\n",
      "Epoch 356/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.5259 - acc: 0.3700 - val_loss: 1.9440 - val_acc: 0.2433\n",
      "Epoch 357/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.5258 - acc: 0.3714 - val_loss: 1.9372 - val_acc: 0.2267\n",
      "Epoch 358/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5250 - acc: 0.3743 - val_loss: 1.9498 - val_acc: 0.2200\n",
      "Epoch 359/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5252 - acc: 0.3700 - val_loss: 1.9458 - val_acc: 0.2133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5232 - acc: 0.3743 - val_loss: 1.9460 - val_acc: 0.2233\n",
      "Epoch 361/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.5231 - acc: 0.3671 - val_loss: 1.9480 - val_acc: 0.2300\n",
      "Epoch 362/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5239 - acc: 0.3629 - val_loss: 1.9499 - val_acc: 0.2233\n",
      "Epoch 363/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5215 - acc: 0.3743 - val_loss: 1.9519 - val_acc: 0.2333\n",
      "Epoch 364/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.5230 - acc: 0.3643 - val_loss: 1.9377 - val_acc: 0.2267\n",
      "Epoch 365/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.5224 - acc: 0.3771 - val_loss: 1.9521 - val_acc: 0.2267\n",
      "Epoch 366/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.5223 - acc: 0.3686 - val_loss: 1.9409 - val_acc: 0.2133\n",
      "Epoch 367/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5222 - acc: 0.3771 - val_loss: 1.9565 - val_acc: 0.2300\n",
      "Epoch 368/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5206 - acc: 0.3786 - val_loss: 1.9550 - val_acc: 0.2367\n",
      "Epoch 369/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5207 - acc: 0.3643 - val_loss: 1.9322 - val_acc: 0.2367\n",
      "Epoch 370/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5200 - acc: 0.3757 - val_loss: 1.9536 - val_acc: 0.2367\n",
      "Epoch 371/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5209 - acc: 0.3671 - val_loss: 1.9510 - val_acc: 0.2233\n",
      "Epoch 372/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5195 - acc: 0.3729 - val_loss: 1.9591 - val_acc: 0.2333\n",
      "Epoch 373/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5205 - acc: 0.3757 - val_loss: 1.9453 - val_acc: 0.2133\n",
      "Epoch 374/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5197 - acc: 0.3686 - val_loss: 1.9519 - val_acc: 0.2267\n",
      "Epoch 375/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5181 - acc: 0.3843 - val_loss: 1.9387 - val_acc: 0.2267\n",
      "Epoch 376/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5183 - acc: 0.3786 - val_loss: 1.9457 - val_acc: 0.2200\n",
      "Epoch 377/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5170 - acc: 0.3743 - val_loss: 1.9758 - val_acc: 0.2267\n",
      "Epoch 378/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5182 - acc: 0.3757 - val_loss: 1.9757 - val_acc: 0.2367\n",
      "Epoch 379/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.5187 - acc: 0.3657 - val_loss: 1.9521 - val_acc: 0.2367\n",
      "Epoch 380/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5166 - acc: 0.3700 - val_loss: 1.9606 - val_acc: 0.2567\n",
      "Epoch 381/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5180 - acc: 0.3786 - val_loss: 1.9715 - val_acc: 0.2167\n",
      "Epoch 382/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5161 - acc: 0.3743 - val_loss: 1.9588 - val_acc: 0.2267\n",
      "Epoch 383/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5155 - acc: 0.3700 - val_loss: 1.9716 - val_acc: 0.2400\n",
      "Epoch 384/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5164 - acc: 0.3771 - val_loss: 1.9512 - val_acc: 0.2233\n",
      "Epoch 385/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.5163 - acc: 0.3743 - val_loss: 1.9582 - val_acc: 0.2267\n",
      "Epoch 386/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5156 - acc: 0.3714 - val_loss: 1.9507 - val_acc: 0.2333\n",
      "Epoch 387/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.5153 - acc: 0.3729 - val_loss: 1.9581 - val_acc: 0.2300\n",
      "Epoch 388/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5142 - acc: 0.3714 - val_loss: 1.9672 - val_acc: 0.2467\n",
      "Epoch 389/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5159 - acc: 0.3800 - val_loss: 1.9493 - val_acc: 0.2267\n",
      "Epoch 390/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.5125 - acc: 0.3671 - val_loss: 1.9575 - val_acc: 0.2400\n",
      "Epoch 391/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5132 - acc: 0.3743 - val_loss: 1.9542 - val_acc: 0.2367\n",
      "Epoch 392/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.5137 - acc: 0.3714 - val_loss: 1.9600 - val_acc: 0.2233\n",
      "Epoch 393/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5136 - acc: 0.3757 - val_loss: 1.9731 - val_acc: 0.2233\n",
      "Epoch 394/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.5135 - acc: 0.3771 - val_loss: 1.9566 - val_acc: 0.2267\n",
      "Epoch 395/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5130 - acc: 0.3757 - val_loss: 1.9571 - val_acc: 0.2167\n",
      "Epoch 396/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5122 - acc: 0.3786 - val_loss: 1.9652 - val_acc: 0.2200\n",
      "Epoch 397/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5111 - acc: 0.3843 - val_loss: 1.9760 - val_acc: 0.2333\n",
      "Epoch 398/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5124 - acc: 0.3629 - val_loss: 1.9592 - val_acc: 0.2200\n",
      "Epoch 399/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5107 - acc: 0.3743 - val_loss: 1.9875 - val_acc: 0.2333\n",
      "Epoch 400/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5113 - acc: 0.3629 - val_loss: 1.9602 - val_acc: 0.2167\n",
      "Epoch 401/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.5109 - acc: 0.3657 - val_loss: 1.9596 - val_acc: 0.2267\n",
      "Epoch 402/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5086 - acc: 0.3771 - val_loss: 1.9652 - val_acc: 0.2233\n",
      "Epoch 403/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5069 - acc: 0.3843 - val_loss: 1.9932 - val_acc: 0.2200\n",
      "Epoch 404/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5085 - acc: 0.3743 - val_loss: 1.9680 - val_acc: 0.2333\n",
      "Epoch 405/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5074 - acc: 0.3800 - val_loss: 1.9814 - val_acc: 0.2300\n",
      "Epoch 406/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.5085 - acc: 0.3771 - val_loss: 1.9747 - val_acc: 0.2200\n",
      "Epoch 407/3000\n",
      "700/700 [==============================] - 0s 166us/step - loss: 1.5080 - acc: 0.3714 - val_loss: 1.9794 - val_acc: 0.2300\n",
      "Epoch 408/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5077 - acc: 0.3757 - val_loss: 1.9708 - val_acc: 0.2267\n",
      "Epoch 409/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5040 - acc: 0.3700 - val_loss: 1.9785 - val_acc: 0.2367\n",
      "Epoch 410/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5058 - acc: 0.3771 - val_loss: 1.9613 - val_acc: 0.2267\n",
      "Epoch 411/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.5056 - acc: 0.3714 - val_loss: 1.9818 - val_acc: 0.2300\n",
      "Epoch 412/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5048 - acc: 0.3843 - val_loss: 1.9720 - val_acc: 0.2233\n",
      "Epoch 413/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5033 - acc: 0.3771 - val_loss: 1.9762 - val_acc: 0.2333\n",
      "Epoch 414/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5043 - acc: 0.3800 - val_loss: 1.9844 - val_acc: 0.2333\n",
      "Epoch 415/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5015 - acc: 0.3786 - val_loss: 1.9780 - val_acc: 0.2333\n",
      "Epoch 416/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5031 - acc: 0.3843 - val_loss: 1.9890 - val_acc: 0.2267\n",
      "Epoch 417/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5032 - acc: 0.3786 - val_loss: 1.9806 - val_acc: 0.2233\n",
      "Epoch 418/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5016 - acc: 0.3871 - val_loss: 1.9745 - val_acc: 0.2333\n",
      "Epoch 419/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5019 - acc: 0.3786 - val_loss: 1.9665 - val_acc: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5015 - acc: 0.3800 - val_loss: 1.9879 - val_acc: 0.2300\n",
      "Epoch 421/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5011 - acc: 0.3814 - val_loss: 1.9693 - val_acc: 0.2433\n",
      "Epoch 422/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.5005 - acc: 0.3743 - val_loss: 1.9748 - val_acc: 0.2433\n",
      "Epoch 423/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5003 - acc: 0.3814 - val_loss: 1.9794 - val_acc: 0.2367\n",
      "Epoch 424/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5001 - acc: 0.3757 - val_loss: 1.9679 - val_acc: 0.2200\n",
      "Epoch 425/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4991 - acc: 0.3886 - val_loss: 1.9620 - val_acc: 0.2400\n",
      "Epoch 426/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4984 - acc: 0.3914 - val_loss: 1.9793 - val_acc: 0.2167\n",
      "Epoch 427/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4984 - acc: 0.3829 - val_loss: 1.9834 - val_acc: 0.2533\n",
      "Epoch 428/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4984 - acc: 0.3843 - val_loss: 2.0050 - val_acc: 0.2300\n",
      "Epoch 429/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4982 - acc: 0.3771 - val_loss: 1.9699 - val_acc: 0.2300\n",
      "Epoch 430/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4978 - acc: 0.3829 - val_loss: 1.9813 - val_acc: 0.2467\n",
      "Epoch 431/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4991 - acc: 0.3800 - val_loss: 1.9871 - val_acc: 0.2333\n",
      "Epoch 432/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4975 - acc: 0.3829 - val_loss: 1.9818 - val_acc: 0.2233\n",
      "Epoch 433/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4968 - acc: 0.3786 - val_loss: 1.9854 - val_acc: 0.2367\n",
      "Epoch 434/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4976 - acc: 0.3786 - val_loss: 1.9878 - val_acc: 0.2233\n",
      "Epoch 435/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4957 - acc: 0.3857 - val_loss: 1.9820 - val_acc: 0.2267\n",
      "Epoch 436/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4975 - acc: 0.3843 - val_loss: 1.9695 - val_acc: 0.2233\n",
      "Epoch 437/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4957 - acc: 0.3929 - val_loss: 1.9954 - val_acc: 0.2200\n",
      "Epoch 438/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4948 - acc: 0.3871 - val_loss: 1.9637 - val_acc: 0.2300\n",
      "Epoch 439/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4946 - acc: 0.3757 - val_loss: 1.9784 - val_acc: 0.2233\n",
      "Epoch 440/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4960 - acc: 0.3814 - val_loss: 1.9800 - val_acc: 0.2300\n",
      "Epoch 441/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4951 - acc: 0.3900 - val_loss: 1.9827 - val_acc: 0.2300\n",
      "Epoch 442/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4945 - acc: 0.3843 - val_loss: 1.9938 - val_acc: 0.2233\n",
      "Epoch 443/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4937 - acc: 0.3857 - val_loss: 1.9898 - val_acc: 0.2400\n",
      "Epoch 444/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4947 - acc: 0.3814 - val_loss: 1.9925 - val_acc: 0.2233\n",
      "Epoch 445/3000\n",
      "700/700 [==============================] - 0s 207us/step - loss: 1.4943 - acc: 0.3829 - val_loss: 1.9936 - val_acc: 0.2300\n",
      "Epoch 446/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4931 - acc: 0.3871 - val_loss: 2.0035 - val_acc: 0.2267\n",
      "Epoch 447/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4926 - acc: 0.3814 - val_loss: 2.0148 - val_acc: 0.2300\n",
      "Epoch 448/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4928 - acc: 0.3829 - val_loss: 1.9928 - val_acc: 0.2267\n",
      "Epoch 449/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4918 - acc: 0.3886 - val_loss: 2.0031 - val_acc: 0.2333\n",
      "Epoch 450/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4929 - acc: 0.3843 - val_loss: 1.9932 - val_acc: 0.2233\n",
      "Epoch 451/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4920 - acc: 0.3843 - val_loss: 1.9966 - val_acc: 0.2233\n",
      "Epoch 452/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4908 - acc: 0.3857 - val_loss: 1.9947 - val_acc: 0.2300\n",
      "Epoch 453/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4910 - acc: 0.3871 - val_loss: 1.9900 - val_acc: 0.2333\n",
      "Epoch 454/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4908 - acc: 0.3871 - val_loss: 1.9968 - val_acc: 0.2333\n",
      "Epoch 455/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4907 - acc: 0.3843 - val_loss: 1.9882 - val_acc: 0.2267\n",
      "Epoch 456/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4898 - acc: 0.3786 - val_loss: 1.9917 - val_acc: 0.2467\n",
      "Epoch 457/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4898 - acc: 0.3871 - val_loss: 2.0000 - val_acc: 0.2333\n",
      "Epoch 458/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4903 - acc: 0.3814 - val_loss: 1.9943 - val_acc: 0.2267\n",
      "Epoch 459/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4881 - acc: 0.3957 - val_loss: 1.9953 - val_acc: 0.2467\n",
      "Epoch 460/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4901 - acc: 0.3900 - val_loss: 2.0011 - val_acc: 0.2300\n",
      "Epoch 461/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4884 - acc: 0.3971 - val_loss: 1.9997 - val_acc: 0.2300\n",
      "Epoch 462/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4883 - acc: 0.3914 - val_loss: 1.9926 - val_acc: 0.2267\n",
      "Epoch 463/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4872 - acc: 0.3886 - val_loss: 1.9994 - val_acc: 0.2467\n",
      "Epoch 464/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4871 - acc: 0.3886 - val_loss: 1.9881 - val_acc: 0.2333\n",
      "Epoch 465/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4877 - acc: 0.3900 - val_loss: 1.9966 - val_acc: 0.2233\n",
      "Epoch 466/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4872 - acc: 0.3757 - val_loss: 2.0005 - val_acc: 0.2267\n",
      "Epoch 467/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4873 - acc: 0.3871 - val_loss: 2.0061 - val_acc: 0.2267\n",
      "Epoch 468/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4866 - acc: 0.3843 - val_loss: 1.9905 - val_acc: 0.2267\n",
      "Epoch 469/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4859 - acc: 0.3871 - val_loss: 2.0315 - val_acc: 0.2333\n",
      "Epoch 470/3000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4870 - acc: 0.3871 - val_loss: 2.0106 - val_acc: 0.2233\n",
      "Epoch 471/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4860 - acc: 0.3943 - val_loss: 2.0065 - val_acc: 0.2233\n",
      "Epoch 472/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4845 - acc: 0.3957 - val_loss: 2.0087 - val_acc: 0.2367\n",
      "Epoch 473/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4849 - acc: 0.3914 - val_loss: 2.0126 - val_acc: 0.2367\n",
      "Epoch 474/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4838 - acc: 0.3900 - val_loss: 1.9974 - val_acc: 0.2267\n",
      "Epoch 475/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4842 - acc: 0.3900 - val_loss: 2.0051 - val_acc: 0.2233\n",
      "Epoch 476/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4835 - acc: 0.3914 - val_loss: 2.0060 - val_acc: 0.2267\n",
      "Epoch 477/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4841 - acc: 0.3914 - val_loss: 2.0093 - val_acc: 0.2233\n",
      "Epoch 478/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4838 - acc: 0.3929 - val_loss: 2.0062 - val_acc: 0.2333\n",
      "Epoch 479/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4833 - acc: 0.3914 - val_loss: 2.0022 - val_acc: 0.2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4826 - acc: 0.3986 - val_loss: 2.0114 - val_acc: 0.2367\n",
      "Epoch 481/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4821 - acc: 0.3886 - val_loss: 2.0179 - val_acc: 0.2400\n",
      "Epoch 482/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4810 - acc: 0.3986 - val_loss: 2.0161 - val_acc: 0.2300\n",
      "Epoch 483/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4819 - acc: 0.4000 - val_loss: 2.0168 - val_acc: 0.2367\n",
      "Epoch 484/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4815 - acc: 0.3971 - val_loss: 2.0160 - val_acc: 0.2400\n",
      "Epoch 485/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4809 - acc: 0.4000 - val_loss: 2.0086 - val_acc: 0.2300\n",
      "Epoch 486/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4809 - acc: 0.3843 - val_loss: 2.0068 - val_acc: 0.2467\n",
      "Epoch 487/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4811 - acc: 0.3914 - val_loss: 2.0073 - val_acc: 0.2500\n",
      "Epoch 488/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4808 - acc: 0.3929 - val_loss: 2.0157 - val_acc: 0.2500\n",
      "Epoch 489/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4804 - acc: 0.3886 - val_loss: 2.0027 - val_acc: 0.2267\n",
      "Epoch 490/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4810 - acc: 0.3886 - val_loss: 1.9994 - val_acc: 0.2333\n",
      "Epoch 491/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4809 - acc: 0.3871 - val_loss: 2.0215 - val_acc: 0.2300\n",
      "Epoch 492/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4800 - acc: 0.3914 - val_loss: 2.0008 - val_acc: 0.2267\n",
      "Epoch 493/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4799 - acc: 0.4014 - val_loss: 2.0078 - val_acc: 0.2333\n",
      "Epoch 494/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4803 - acc: 0.3914 - val_loss: 2.0080 - val_acc: 0.2233\n",
      "Epoch 495/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4793 - acc: 0.4029 - val_loss: 2.0265 - val_acc: 0.2333\n",
      "Epoch 496/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4787 - acc: 0.3857 - val_loss: 2.0117 - val_acc: 0.2433\n",
      "Epoch 497/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4773 - acc: 0.3929 - val_loss: 2.0126 - val_acc: 0.2467\n",
      "Epoch 498/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4763 - acc: 0.3886 - val_loss: 2.0474 - val_acc: 0.2367\n",
      "Epoch 499/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4776 - acc: 0.4014 - val_loss: 2.0284 - val_acc: 0.2367\n",
      "Epoch 500/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4780 - acc: 0.3929 - val_loss: 2.0264 - val_acc: 0.2367\n",
      "Epoch 501/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4782 - acc: 0.4014 - val_loss: 2.0249 - val_acc: 0.2300\n",
      "Epoch 502/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4760 - acc: 0.3957 - val_loss: 2.0259 - val_acc: 0.2267\n",
      "Epoch 503/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4765 - acc: 0.3957 - val_loss: 2.0205 - val_acc: 0.2267\n",
      "Epoch 504/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.4758 - acc: 0.3957 - val_loss: 2.0237 - val_acc: 0.2267\n",
      "Epoch 505/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4755 - acc: 0.3957 - val_loss: 2.0206 - val_acc: 0.2400\n",
      "Epoch 506/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4755 - acc: 0.4000 - val_loss: 2.0164 - val_acc: 0.2300\n",
      "Epoch 507/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4769 - acc: 0.3986 - val_loss: 2.0225 - val_acc: 0.2233\n",
      "Epoch 508/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4750 - acc: 0.3900 - val_loss: 2.0235 - val_acc: 0.2267\n",
      "Epoch 509/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4744 - acc: 0.3943 - val_loss: 2.0370 - val_acc: 0.2333\n",
      "Epoch 510/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4745 - acc: 0.3914 - val_loss: 2.0229 - val_acc: 0.2233\n",
      "Epoch 511/3000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 1.4737 - acc: 0.4071 - val_loss: 2.0154 - val_acc: 0.2267\n",
      "Epoch 512/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4739 - acc: 0.3986 - val_loss: 2.0109 - val_acc: 0.2467\n",
      "Epoch 513/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4733 - acc: 0.3971 - val_loss: 2.0140 - val_acc: 0.2433\n",
      "Epoch 514/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4728 - acc: 0.4000 - val_loss: 2.0277 - val_acc: 0.2267\n",
      "Epoch 515/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4734 - acc: 0.4029 - val_loss: 2.0260 - val_acc: 0.2300\n",
      "Epoch 516/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4741 - acc: 0.3929 - val_loss: 2.0279 - val_acc: 0.2267\n",
      "Epoch 517/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4706 - acc: 0.3943 - val_loss: 2.0341 - val_acc: 0.2500\n",
      "Epoch 518/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4741 - acc: 0.4014 - val_loss: 2.0341 - val_acc: 0.2267\n",
      "Epoch 519/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4727 - acc: 0.4043 - val_loss: 2.0244 - val_acc: 0.2300\n",
      "Epoch 520/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4719 - acc: 0.3943 - val_loss: 2.0308 - val_acc: 0.2400\n",
      "Epoch 521/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4714 - acc: 0.4143 - val_loss: 2.0127 - val_acc: 0.2333\n",
      "Epoch 522/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4725 - acc: 0.4000 - val_loss: 2.0338 - val_acc: 0.2267\n",
      "Epoch 523/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4721 - acc: 0.3929 - val_loss: 2.0291 - val_acc: 0.2267\n",
      "Epoch 524/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4711 - acc: 0.3986 - val_loss: 2.0227 - val_acc: 0.2333\n",
      "Epoch 525/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4696 - acc: 0.4000 - val_loss: 2.0284 - val_acc: 0.2467\n",
      "Epoch 526/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4711 - acc: 0.3986 - val_loss: 2.0255 - val_acc: 0.2267\n",
      "Epoch 527/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4702 - acc: 0.3957 - val_loss: 2.0254 - val_acc: 0.2300\n",
      "Epoch 528/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4694 - acc: 0.4029 - val_loss: 2.0288 - val_acc: 0.2267\n",
      "Epoch 529/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4681 - acc: 0.3943 - val_loss: 2.0334 - val_acc: 0.2267\n",
      "Epoch 530/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4687 - acc: 0.4000 - val_loss: 2.0410 - val_acc: 0.2267\n",
      "Epoch 531/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4689 - acc: 0.3957 - val_loss: 2.0247 - val_acc: 0.2433\n",
      "Epoch 532/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.4691 - acc: 0.4014 - val_loss: 2.0352 - val_acc: 0.2433\n",
      "Epoch 533/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4685 - acc: 0.4000 - val_loss: 2.0311 - val_acc: 0.2300\n",
      "Epoch 534/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4689 - acc: 0.3971 - val_loss: 2.0267 - val_acc: 0.2300\n",
      "Epoch 535/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4673 - acc: 0.4043 - val_loss: 2.0499 - val_acc: 0.2433\n",
      "Epoch 536/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4670 - acc: 0.4043 - val_loss: 2.0477 - val_acc: 0.2267\n",
      "Epoch 537/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4676 - acc: 0.4029 - val_loss: 2.0295 - val_acc: 0.2300\n",
      "Epoch 538/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4672 - acc: 0.3943 - val_loss: 2.0352 - val_acc: 0.2367\n",
      "Epoch 539/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4691 - acc: 0.3943 - val_loss: 2.0314 - val_acc: 0.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4678 - acc: 0.4000 - val_loss: 2.0397 - val_acc: 0.2267\n",
      "Epoch 541/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4667 - acc: 0.4014 - val_loss: 2.0373 - val_acc: 0.2267\n",
      "Epoch 542/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4665 - acc: 0.4043 - val_loss: 2.0428 - val_acc: 0.2433\n",
      "Epoch 543/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.4671 - acc: 0.4000 - val_loss: 2.0294 - val_acc: 0.2333\n",
      "Epoch 544/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4657 - acc: 0.3943 - val_loss: 2.0247 - val_acc: 0.2367\n",
      "Epoch 545/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4665 - acc: 0.4043 - val_loss: 2.0326 - val_acc: 0.2300\n",
      "Epoch 546/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4636 - acc: 0.3986 - val_loss: 2.0467 - val_acc: 0.2500\n",
      "Epoch 547/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4658 - acc: 0.3971 - val_loss: 2.0508 - val_acc: 0.2400\n",
      "Epoch 548/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4643 - acc: 0.3971 - val_loss: 2.0291 - val_acc: 0.2300\n",
      "Epoch 549/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4647 - acc: 0.4043 - val_loss: 2.0286 - val_acc: 0.2300\n",
      "Epoch 550/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4639 - acc: 0.3986 - val_loss: 2.0411 - val_acc: 0.2300\n",
      "Epoch 551/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4647 - acc: 0.3971 - val_loss: 2.0370 - val_acc: 0.2300\n",
      "Epoch 552/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4632 - acc: 0.4086 - val_loss: 2.0368 - val_acc: 0.2333\n",
      "Epoch 553/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.4655 - acc: 0.3986 - val_loss: 2.0342 - val_acc: 0.2300\n",
      "Epoch 554/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4629 - acc: 0.4000 - val_loss: 2.0434 - val_acc: 0.2300\n",
      "Epoch 555/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4637 - acc: 0.4057 - val_loss: 2.0459 - val_acc: 0.2400\n",
      "Epoch 556/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.4621 - acc: 0.4014 - val_loss: 2.0388 - val_acc: 0.2433\n",
      "Epoch 557/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4615 - acc: 0.4129 - val_loss: 2.0545 - val_acc: 0.2500\n",
      "Epoch 558/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4631 - acc: 0.4043 - val_loss: 2.0384 - val_acc: 0.2300\n",
      "Epoch 559/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4615 - acc: 0.4029 - val_loss: 2.0415 - val_acc: 0.2500\n",
      "Epoch 560/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4613 - acc: 0.4014 - val_loss: 2.0446 - val_acc: 0.2567\n",
      "Epoch 561/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.4623 - acc: 0.4086 - val_loss: 2.0389 - val_acc: 0.2267\n",
      "Epoch 562/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4620 - acc: 0.4043 - val_loss: 2.0349 - val_acc: 0.2300\n",
      "Epoch 563/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4613 - acc: 0.4000 - val_loss: 2.0365 - val_acc: 0.2267\n",
      "Epoch 564/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4611 - acc: 0.4071 - val_loss: 2.0525 - val_acc: 0.2300\n",
      "Epoch 565/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4604 - acc: 0.4029 - val_loss: 2.0381 - val_acc: 0.2333\n",
      "Epoch 566/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4620 - acc: 0.4100 - val_loss: 2.0474 - val_acc: 0.2333\n",
      "Epoch 567/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4599 - acc: 0.4171 - val_loss: 2.0505 - val_acc: 0.2300\n",
      "Epoch 568/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4598 - acc: 0.4071 - val_loss: 2.0486 - val_acc: 0.2433\n",
      "Epoch 569/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4593 - acc: 0.4057 - val_loss: 2.0427 - val_acc: 0.2533\n",
      "Epoch 570/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4588 - acc: 0.4114 - val_loss: 2.0507 - val_acc: 0.2333\n",
      "Epoch 571/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4587 - acc: 0.4043 - val_loss: 2.0489 - val_acc: 0.2300\n",
      "Epoch 572/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4580 - acc: 0.4014 - val_loss: 2.0406 - val_acc: 0.2333\n",
      "Epoch 573/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4572 - acc: 0.4100 - val_loss: 2.0591 - val_acc: 0.2533\n",
      "Epoch 574/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4598 - acc: 0.4043 - val_loss: 2.0420 - val_acc: 0.2500\n",
      "Epoch 575/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4598 - acc: 0.4114 - val_loss: 2.0445 - val_acc: 0.2267\n",
      "Epoch 576/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4586 - acc: 0.3957 - val_loss: 2.0448 - val_acc: 0.2300\n",
      "Epoch 577/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4584 - acc: 0.4000 - val_loss: 2.0450 - val_acc: 0.2300\n",
      "Epoch 578/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4579 - acc: 0.4057 - val_loss: 2.0453 - val_acc: 0.2367\n",
      "Epoch 579/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4583 - acc: 0.4071 - val_loss: 2.0435 - val_acc: 0.2267\n",
      "Epoch 580/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4574 - acc: 0.4100 - val_loss: 2.0538 - val_acc: 0.2367\n",
      "Epoch 581/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4570 - acc: 0.4086 - val_loss: 2.0492 - val_acc: 0.2567\n",
      "Epoch 582/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4569 - acc: 0.4071 - val_loss: 2.0519 - val_acc: 0.2267\n",
      "Epoch 583/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4564 - acc: 0.4000 - val_loss: 2.0533 - val_acc: 0.2267\n",
      "Epoch 584/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4571 - acc: 0.4071 - val_loss: 2.0525 - val_acc: 0.2267\n",
      "Epoch 585/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4558 - acc: 0.4100 - val_loss: 2.0552 - val_acc: 0.2300\n",
      "Epoch 586/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4550 - acc: 0.4029 - val_loss: 2.0555 - val_acc: 0.2500\n",
      "Epoch 587/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4573 - acc: 0.4114 - val_loss: 2.0558 - val_acc: 0.2333\n",
      "Epoch 588/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4560 - acc: 0.4057 - val_loss: 2.0582 - val_acc: 0.2300\n",
      "Epoch 589/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4553 - acc: 0.4071 - val_loss: 2.0577 - val_acc: 0.2267\n",
      "Epoch 590/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4553 - acc: 0.4014 - val_loss: 2.0520 - val_acc: 0.2300\n",
      "Epoch 591/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4554 - acc: 0.4100 - val_loss: 2.0613 - val_acc: 0.2267\n",
      "Epoch 592/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4544 - acc: 0.4100 - val_loss: 2.0562 - val_acc: 0.2333\n",
      "Epoch 593/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4546 - acc: 0.4057 - val_loss: 2.0478 - val_acc: 0.2267\n",
      "Epoch 594/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4540 - acc: 0.4143 - val_loss: 2.0516 - val_acc: 0.2333\n",
      "Epoch 595/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4543 - acc: 0.4071 - val_loss: 2.0573 - val_acc: 0.2433\n",
      "Epoch 596/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4537 - acc: 0.4129 - val_loss: 2.0474 - val_acc: 0.2300\n",
      "Epoch 597/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4525 - acc: 0.4143 - val_loss: 2.0494 - val_acc: 0.2500\n",
      "Epoch 598/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.4537 - acc: 0.3957 - val_loss: 2.0565 - val_acc: 0.2267\n",
      "Epoch 599/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4541 - acc: 0.4043 - val_loss: 2.0480 - val_acc: 0.2333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4525 - acc: 0.4157 - val_loss: 2.0628 - val_acc: 0.2300\n",
      "Epoch 601/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4522 - acc: 0.4100 - val_loss: 2.0626 - val_acc: 0.2433\n",
      "Epoch 602/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4526 - acc: 0.4043 - val_loss: 2.0542 - val_acc: 0.2333\n",
      "Epoch 603/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4529 - acc: 0.4114 - val_loss: 2.0490 - val_acc: 0.2400\n",
      "Epoch 604/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4526 - acc: 0.4043 - val_loss: 2.0481 - val_acc: 0.2367\n",
      "Epoch 605/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4515 - acc: 0.4071 - val_loss: 2.0541 - val_acc: 0.2367\n",
      "Epoch 606/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4518 - acc: 0.4114 - val_loss: 2.0468 - val_acc: 0.2333\n",
      "Epoch 607/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4519 - acc: 0.4100 - val_loss: 2.0540 - val_acc: 0.2300\n",
      "Epoch 608/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4516 - acc: 0.4071 - val_loss: 2.0499 - val_acc: 0.2367\n",
      "Epoch 609/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4500 - acc: 0.4171 - val_loss: 2.0641 - val_acc: 0.2567\n",
      "Epoch 610/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.4508 - acc: 0.4114 - val_loss: 2.0652 - val_acc: 0.2333\n",
      "Epoch 611/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4508 - acc: 0.4114 - val_loss: 2.0617 - val_acc: 0.2367\n",
      "Epoch 612/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.4506 - acc: 0.4086 - val_loss: 2.0581 - val_acc: 0.2433\n",
      "Epoch 613/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4505 - acc: 0.4100 - val_loss: 2.0597 - val_acc: 0.2300\n",
      "Epoch 614/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4496 - acc: 0.4129 - val_loss: 2.0680 - val_acc: 0.2500\n",
      "Epoch 615/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4502 - acc: 0.4143 - val_loss: 2.0534 - val_acc: 0.2533\n",
      "Epoch 616/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4495 - acc: 0.4143 - val_loss: 2.0733 - val_acc: 0.2333\n",
      "Epoch 617/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.4479 - acc: 0.4157 - val_loss: 2.0656 - val_acc: 0.2533\n",
      "Epoch 618/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4491 - acc: 0.4014 - val_loss: 2.0613 - val_acc: 0.2400\n",
      "Epoch 619/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4478 - acc: 0.4129 - val_loss: 2.0704 - val_acc: 0.2333\n",
      "Epoch 620/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4485 - acc: 0.4171 - val_loss: 2.0572 - val_acc: 0.2300\n",
      "Epoch 621/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.4487 - acc: 0.4171 - val_loss: 2.0745 - val_acc: 0.2300\n",
      "Epoch 622/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4477 - acc: 0.4100 - val_loss: 2.0718 - val_acc: 0.2367\n",
      "Epoch 623/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.4472 - acc: 0.4186 - val_loss: 2.0693 - val_acc: 0.2267\n",
      "Epoch 624/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4480 - acc: 0.4157 - val_loss: 2.0687 - val_acc: 0.2333\n",
      "Epoch 625/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4478 - acc: 0.4057 - val_loss: 2.0720 - val_acc: 0.2367\n",
      "Epoch 626/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.4471 - acc: 0.4114 - val_loss: 2.0542 - val_acc: 0.2367\n",
      "Epoch 627/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4478 - acc: 0.4271 - val_loss: 2.0636 - val_acc: 0.2333\n",
      "Epoch 628/3000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.4459 - acc: 0.4143 - val_loss: 2.0511 - val_acc: 0.2400\n",
      "Epoch 629/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4475 - acc: 0.4100 - val_loss: 2.0630 - val_acc: 0.2300\n",
      "Epoch 630/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4459 - acc: 0.4114 - val_loss: 2.0545 - val_acc: 0.2333\n",
      "Epoch 631/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4468 - acc: 0.4114 - val_loss: 2.0821 - val_acc: 0.2400\n",
      "Epoch 632/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4467 - acc: 0.4086 - val_loss: 2.0752 - val_acc: 0.2400\n",
      "Epoch 633/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4456 - acc: 0.4143 - val_loss: 2.0821 - val_acc: 0.2333\n",
      "Epoch 634/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4457 - acc: 0.4157 - val_loss: 2.0710 - val_acc: 0.2333\n",
      "Epoch 635/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4444 - acc: 0.4071 - val_loss: 2.0651 - val_acc: 0.2567\n",
      "Epoch 636/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4464 - acc: 0.4143 - val_loss: 2.0670 - val_acc: 0.2333\n",
      "Epoch 637/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4451 - acc: 0.4114 - val_loss: 2.0766 - val_acc: 0.2367\n",
      "Epoch 638/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4453 - acc: 0.4114 - val_loss: 2.0820 - val_acc: 0.2300\n",
      "Epoch 639/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4449 - acc: 0.4086 - val_loss: 2.0820 - val_acc: 0.2233\n",
      "Epoch 640/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4440 - acc: 0.4171 - val_loss: 2.0588 - val_acc: 0.2367\n",
      "Epoch 641/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4438 - acc: 0.4143 - val_loss: 2.0746 - val_acc: 0.2467\n",
      "Epoch 642/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4449 - acc: 0.4100 - val_loss: 2.0820 - val_acc: 0.2433\n",
      "Epoch 643/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4439 - acc: 0.4129 - val_loss: 2.0854 - val_acc: 0.2300\n",
      "Epoch 644/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4441 - acc: 0.4129 - val_loss: 2.0723 - val_acc: 0.2367\n",
      "Epoch 645/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4433 - acc: 0.4186 - val_loss: 2.0799 - val_acc: 0.2333\n",
      "Epoch 646/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4414 - acc: 0.4114 - val_loss: 2.0734 - val_acc: 0.2567\n",
      "Epoch 647/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4424 - acc: 0.4114 - val_loss: 2.0706 - val_acc: 0.2367\n",
      "Epoch 648/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4431 - acc: 0.4100 - val_loss: 2.0859 - val_acc: 0.2333\n",
      "Epoch 649/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4415 - acc: 0.4057 - val_loss: 2.0824 - val_acc: 0.2333\n",
      "Epoch 650/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4433 - acc: 0.4157 - val_loss: 2.0760 - val_acc: 0.2333\n",
      "Epoch 651/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4419 - acc: 0.4143 - val_loss: 2.0888 - val_acc: 0.2400\n",
      "Epoch 652/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4429 - acc: 0.4129 - val_loss: 2.0739 - val_acc: 0.2333\n",
      "Epoch 653/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4417 - acc: 0.4186 - val_loss: 2.0772 - val_acc: 0.2467\n",
      "Epoch 654/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4414 - acc: 0.4157 - val_loss: 2.0644 - val_acc: 0.2500\n",
      "Epoch 655/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4406 - acc: 0.4114 - val_loss: 2.0750 - val_acc: 0.2533\n",
      "Epoch 656/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4426 - acc: 0.4100 - val_loss: 2.0893 - val_acc: 0.2433\n",
      "Epoch 657/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4410 - acc: 0.4143 - val_loss: 2.0837 - val_acc: 0.2300\n",
      "Epoch 658/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4410 - acc: 0.4114 - val_loss: 2.0793 - val_acc: 0.2333\n",
      "Epoch 659/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4405 - acc: 0.4200 - val_loss: 2.0792 - val_acc: 0.2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 660/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4408 - acc: 0.4114 - val_loss: 2.0795 - val_acc: 0.2367\n",
      "Epoch 661/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4418 - acc: 0.4100 - val_loss: 2.0760 - val_acc: 0.2333\n",
      "Epoch 662/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4411 - acc: 0.4000 - val_loss: 2.0799 - val_acc: 0.2367\n",
      "Epoch 663/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4403 - acc: 0.4186 - val_loss: 2.0938 - val_acc: 0.2400\n",
      "Epoch 664/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4394 - acc: 0.4200 - val_loss: 2.0818 - val_acc: 0.2367\n",
      "Epoch 665/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.4396 - acc: 0.4143 - val_loss: 2.0879 - val_acc: 0.2333\n",
      "Epoch 666/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4390 - acc: 0.4229 - val_loss: 2.0806 - val_acc: 0.2533\n",
      "Epoch 667/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.4405 - acc: 0.4114 - val_loss: 2.0766 - val_acc: 0.2367\n",
      "Epoch 668/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4374 - acc: 0.4171 - val_loss: 2.0962 - val_acc: 0.2567\n",
      "Epoch 669/3000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.4382 - acc: 0.4171 - val_loss: 2.0931 - val_acc: 0.2333\n",
      "Epoch 670/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4394 - acc: 0.4157 - val_loss: 2.0818 - val_acc: 0.2367\n",
      "Epoch 671/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4378 - acc: 0.4157 - val_loss: 2.0808 - val_acc: 0.2533\n",
      "Epoch 672/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4383 - acc: 0.4114 - val_loss: 2.0891 - val_acc: 0.2367\n",
      "Epoch 673/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4384 - acc: 0.4200 - val_loss: 2.0810 - val_acc: 0.2400\n",
      "Epoch 674/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4375 - acc: 0.4100 - val_loss: 2.1029 - val_acc: 0.2433\n",
      "Epoch 675/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4367 - acc: 0.4214 - val_loss: 2.1019 - val_acc: 0.2533\n",
      "Epoch 676/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4366 - acc: 0.4186 - val_loss: 2.0729 - val_acc: 0.2567\n",
      "Epoch 677/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4360 - acc: 0.4157 - val_loss: 2.0987 - val_acc: 0.2300\n",
      "Epoch 678/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4356 - acc: 0.4214 - val_loss: 2.0722 - val_acc: 0.2367\n",
      "Epoch 679/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4370 - acc: 0.4271 - val_loss: 2.0892 - val_acc: 0.2367\n",
      "Epoch 680/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4378 - acc: 0.4157 - val_loss: 2.0895 - val_acc: 0.2400\n",
      "Epoch 681/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4370 - acc: 0.4186 - val_loss: 2.0824 - val_acc: 0.2400\n",
      "Epoch 682/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4360 - acc: 0.4214 - val_loss: 2.0868 - val_acc: 0.2533\n",
      "Epoch 683/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4357 - acc: 0.4129 - val_loss: 2.0787 - val_acc: 0.2500\n",
      "Epoch 684/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4330 - acc: 0.4143 - val_loss: 2.0898 - val_acc: 0.2600\n",
      "Epoch 685/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.4356 - acc: 0.4129 - val_loss: 2.0850 - val_acc: 0.2567\n",
      "Epoch 686/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4352 - acc: 0.4186 - val_loss: 2.1071 - val_acc: 0.2533\n",
      "Epoch 687/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4354 - acc: 0.4143 - val_loss: 2.0777 - val_acc: 0.2367\n",
      "Epoch 688/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4355 - acc: 0.4157 - val_loss: 2.0832 - val_acc: 0.2400\n",
      "Epoch 689/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4348 - acc: 0.4200 - val_loss: 2.0930 - val_acc: 0.2367\n",
      "Epoch 690/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4345 - acc: 0.4143 - val_loss: 2.1000 - val_acc: 0.2300\n",
      "Epoch 691/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4338 - acc: 0.4229 - val_loss: 2.0945 - val_acc: 0.2333\n",
      "Epoch 692/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4340 - acc: 0.4200 - val_loss: 2.0830 - val_acc: 0.2400\n",
      "Epoch 693/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4346 - acc: 0.4171 - val_loss: 2.0820 - val_acc: 0.2400\n",
      "Epoch 694/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4334 - acc: 0.4171 - val_loss: 2.1089 - val_acc: 0.2467\n",
      "Epoch 695/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4349 - acc: 0.4171 - val_loss: 2.0880 - val_acc: 0.2567\n",
      "Epoch 696/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.4324 - acc: 0.4214 - val_loss: 2.0987 - val_acc: 0.2333\n",
      "Epoch 697/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4336 - acc: 0.4171 - val_loss: 2.1071 - val_acc: 0.2467\n",
      "Epoch 698/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4333 - acc: 0.4243 - val_loss: 2.0952 - val_acc: 0.2433\n",
      "Epoch 699/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4328 - acc: 0.4214 - val_loss: 2.1005 - val_acc: 0.2400\n",
      "Epoch 700/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4327 - acc: 0.4186 - val_loss: 2.0964 - val_acc: 0.2467\n",
      "Epoch 701/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.4318 - acc: 0.4200 - val_loss: 2.0916 - val_acc: 0.2433\n",
      "Epoch 702/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.4327 - acc: 0.4114 - val_loss: 2.0978 - val_acc: 0.2367\n",
      "Epoch 703/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4318 - acc: 0.4243 - val_loss: 2.1130 - val_acc: 0.2300\n",
      "Epoch 704/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.4324 - acc: 0.4186 - val_loss: 2.0941 - val_acc: 0.2467\n",
      "Epoch 705/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4320 - acc: 0.4171 - val_loss: 2.0874 - val_acc: 0.2400\n",
      "Epoch 706/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4321 - acc: 0.4214 - val_loss: 2.0804 - val_acc: 0.2400\n",
      "Epoch 707/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4316 - acc: 0.4243 - val_loss: 2.1027 - val_acc: 0.2367\n",
      "Epoch 708/3000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.4315 - acc: 0.4214 - val_loss: 2.0933 - val_acc: 0.2333\n",
      "Epoch 709/3000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 1.4296 - acc: 0.4214 - val_loss: 2.1102 - val_acc: 0.2567\n",
      "Epoch 710/3000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 1.4316 - acc: 0.4243 - val_loss: 2.0970 - val_acc: 0.2467\n",
      "Epoch 711/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4305 - acc: 0.4200 - val_loss: 2.0961 - val_acc: 0.2367\n",
      "Epoch 712/3000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4302 - acc: 0.4200 - val_loss: 2.1016 - val_acc: 0.2567\n",
      "Epoch 713/3000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4310 - acc: 0.4200 - val_loss: 2.0845 - val_acc: 0.2400\n",
      "Epoch 714/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4304 - acc: 0.4257 - val_loss: 2.0994 - val_acc: 0.2367\n",
      "Epoch 715/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4281 - acc: 0.4243 - val_loss: 2.0932 - val_acc: 0.2600\n",
      "Epoch 716/3000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4307 - acc: 0.4186 - val_loss: 2.0988 - val_acc: 0.2367\n",
      "Epoch 717/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4297 - acc: 0.4157 - val_loss: 2.1000 - val_acc: 0.2367\n",
      "Epoch 718/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4290 - acc: 0.4214 - val_loss: 2.1232 - val_acc: 0.2533\n",
      "Epoch 719/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4301 - acc: 0.4171 - val_loss: 2.1163 - val_acc: 0.2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4297 - acc: 0.4200 - val_loss: 2.1035 - val_acc: 0.2367\n",
      "Epoch 721/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4290 - acc: 0.4200 - val_loss: 2.1032 - val_acc: 0.2433\n",
      "Epoch 722/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4287 - acc: 0.4186 - val_loss: 2.1024 - val_acc: 0.2367\n",
      "Epoch 723/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4283 - acc: 0.4214 - val_loss: 2.0942 - val_acc: 0.2400\n",
      "Epoch 724/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4282 - acc: 0.4229 - val_loss: 2.1102 - val_acc: 0.2367\n",
      "Epoch 725/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4278 - acc: 0.4257 - val_loss: 2.1160 - val_acc: 0.2433\n",
      "Epoch 726/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4277 - acc: 0.4271 - val_loss: 2.0977 - val_acc: 0.2367\n",
      "Epoch 727/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4274 - acc: 0.4214 - val_loss: 2.1273 - val_acc: 0.2333\n",
      "Epoch 728/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4276 - acc: 0.4214 - val_loss: 2.0964 - val_acc: 0.2400\n",
      "Epoch 729/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4270 - acc: 0.4229 - val_loss: 2.1201 - val_acc: 0.2467\n",
      "Epoch 730/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4269 - acc: 0.4257 - val_loss: 2.1250 - val_acc: 0.2400\n",
      "Epoch 731/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4277 - acc: 0.4143 - val_loss: 2.1100 - val_acc: 0.2367\n",
      "Epoch 732/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4261 - acc: 0.4257 - val_loss: 2.1079 - val_acc: 0.2400\n",
      "Epoch 733/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4264 - acc: 0.4286 - val_loss: 2.1093 - val_acc: 0.2333\n",
      "Epoch 734/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4273 - acc: 0.4200 - val_loss: 2.1140 - val_acc: 0.2400\n",
      "Epoch 735/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4259 - acc: 0.4286 - val_loss: 2.1094 - val_acc: 0.2367\n",
      "Epoch 736/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4251 - acc: 0.4271 - val_loss: 2.1018 - val_acc: 0.2400\n",
      "Epoch 737/3000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.4265 - acc: 0.4214 - val_loss: 2.1195 - val_acc: 0.2433\n",
      "Epoch 738/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4266 - acc: 0.4214 - val_loss: 2.1078 - val_acc: 0.2433\n",
      "Epoch 739/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4251 - acc: 0.4286 - val_loss: 2.1169 - val_acc: 0.2333\n",
      "Epoch 740/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4250 - acc: 0.4286 - val_loss: 2.1055 - val_acc: 0.2400\n",
      "Epoch 741/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4248 - acc: 0.4200 - val_loss: 2.1190 - val_acc: 0.2567\n",
      "Epoch 742/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4253 - acc: 0.4157 - val_loss: 2.1011 - val_acc: 0.2533\n",
      "Epoch 743/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4240 - acc: 0.4286 - val_loss: 2.1043 - val_acc: 0.2533\n",
      "Epoch 744/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4258 - acc: 0.4186 - val_loss: 2.1044 - val_acc: 0.2433\n",
      "Epoch 745/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4222 - acc: 0.4329 - val_loss: 2.1159 - val_acc: 0.2533\n",
      "Epoch 746/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4255 - acc: 0.4286 - val_loss: 2.1046 - val_acc: 0.2400\n",
      "Epoch 747/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4250 - acc: 0.4157 - val_loss: 2.1136 - val_acc: 0.2433\n",
      "Epoch 748/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.4233 - acc: 0.4257 - val_loss: 2.1298 - val_acc: 0.2600\n",
      "Epoch 749/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4223 - acc: 0.4257 - val_loss: 2.0965 - val_acc: 0.2333\n",
      "Epoch 750/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4239 - acc: 0.4300 - val_loss: 2.1021 - val_acc: 0.2333\n",
      "Epoch 751/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4225 - acc: 0.4157 - val_loss: 2.1127 - val_acc: 0.2400\n",
      "Epoch 752/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4235 - acc: 0.4243 - val_loss: 2.1164 - val_acc: 0.2367\n",
      "Epoch 753/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4222 - acc: 0.4257 - val_loss: 2.1332 - val_acc: 0.2333\n",
      "Epoch 754/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4236 - acc: 0.4271 - val_loss: 2.1230 - val_acc: 0.2400\n",
      "Epoch 755/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4222 - acc: 0.4400 - val_loss: 2.1174 - val_acc: 0.2467\n",
      "Epoch 756/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4223 - acc: 0.4143 - val_loss: 2.1143 - val_acc: 0.2400\n",
      "Epoch 757/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4231 - acc: 0.4200 - val_loss: 2.1238 - val_acc: 0.2433\n",
      "Epoch 758/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4220 - acc: 0.4286 - val_loss: 2.1189 - val_acc: 0.2433\n",
      "Epoch 759/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4223 - acc: 0.4271 - val_loss: 2.1158 - val_acc: 0.2400\n",
      "Epoch 760/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4218 - acc: 0.4343 - val_loss: 2.1125 - val_acc: 0.2400\n",
      "Epoch 761/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4215 - acc: 0.4243 - val_loss: 2.1350 - val_acc: 0.2500\n",
      "Epoch 762/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4225 - acc: 0.4257 - val_loss: 2.1274 - val_acc: 0.2400\n",
      "Epoch 763/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4217 - acc: 0.4186 - val_loss: 2.1157 - val_acc: 0.2400\n",
      "Epoch 764/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4227 - acc: 0.4271 - val_loss: 2.1319 - val_acc: 0.2433\n",
      "Epoch 765/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4203 - acc: 0.4186 - val_loss: 2.1428 - val_acc: 0.2367\n",
      "Epoch 766/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4218 - acc: 0.4200 - val_loss: 2.1165 - val_acc: 0.2400\n",
      "Epoch 767/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4217 - acc: 0.4243 - val_loss: 2.1161 - val_acc: 0.2367\n",
      "Epoch 768/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4205 - acc: 0.4271 - val_loss: 2.1066 - val_acc: 0.2400\n",
      "Epoch 769/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4207 - acc: 0.4243 - val_loss: 2.1184 - val_acc: 0.2367\n",
      "Epoch 770/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4201 - acc: 0.4229 - val_loss: 2.1090 - val_acc: 0.2333\n",
      "Epoch 771/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4195 - acc: 0.4200 - val_loss: 2.1241 - val_acc: 0.2367\n",
      "Epoch 772/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4202 - acc: 0.4243 - val_loss: 2.1256 - val_acc: 0.2433\n",
      "Epoch 773/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4201 - acc: 0.4229 - val_loss: 2.1320 - val_acc: 0.2500\n",
      "Epoch 774/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4191 - acc: 0.4243 - val_loss: 2.1292 - val_acc: 0.2400\n",
      "Epoch 775/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4182 - acc: 0.4271 - val_loss: 2.1291 - val_acc: 0.2533\n",
      "Epoch 776/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4194 - acc: 0.4271 - val_loss: 2.1248 - val_acc: 0.2467\n",
      "Epoch 777/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4179 - acc: 0.4314 - val_loss: 2.1357 - val_acc: 0.2333\n",
      "Epoch 778/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4190 - acc: 0.4214 - val_loss: 2.1274 - val_acc: 0.2367\n",
      "Epoch 779/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4191 - acc: 0.4286 - val_loss: 2.1244 - val_acc: 0.2333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4190 - acc: 0.4243 - val_loss: 2.1175 - val_acc: 0.2400\n",
      "Epoch 781/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4197 - acc: 0.4200 - val_loss: 2.1245 - val_acc: 0.2467\n",
      "Epoch 782/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4185 - acc: 0.4243 - val_loss: 2.1081 - val_acc: 0.2433\n",
      "Epoch 783/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4186 - acc: 0.4329 - val_loss: 2.1299 - val_acc: 0.2433\n",
      "Epoch 784/3000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4182 - acc: 0.4314 - val_loss: 2.1324 - val_acc: 0.2433\n",
      "Epoch 785/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4181 - acc: 0.4271 - val_loss: 2.1421 - val_acc: 0.2367\n",
      "Epoch 786/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4180 - acc: 0.4243 - val_loss: 2.1255 - val_acc: 0.2467\n",
      "Epoch 787/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4184 - acc: 0.4243 - val_loss: 2.1173 - val_acc: 0.2500\n",
      "Epoch 788/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4178 - acc: 0.4271 - val_loss: 2.1248 - val_acc: 0.2433\n",
      "Epoch 789/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4173 - acc: 0.4229 - val_loss: 2.1264 - val_acc: 0.2433\n",
      "Epoch 790/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4175 - acc: 0.4300 - val_loss: 2.1287 - val_acc: 0.2400\n",
      "Epoch 791/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4165 - acc: 0.4286 - val_loss: 2.1302 - val_acc: 0.2500\n",
      "Epoch 792/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4171 - acc: 0.4214 - val_loss: 2.1205 - val_acc: 0.2367\n",
      "Epoch 793/3000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.4166 - acc: 0.4257 - val_loss: 2.1364 - val_acc: 0.2467\n",
      "Epoch 794/3000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4168 - acc: 0.4286 - val_loss: 2.1315 - val_acc: 0.2367\n",
      "Epoch 795/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.4165 - acc: 0.4329 - val_loss: 2.1280 - val_acc: 0.2400\n",
      "Epoch 796/3000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.4160 - acc: 0.4314 - val_loss: 2.1292 - val_acc: 0.2367\n",
      "Epoch 797/3000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4164 - acc: 0.4200 - val_loss: 2.1358 - val_acc: 0.2367\n",
      "Epoch 798/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4163 - acc: 0.4371 - val_loss: 2.1364 - val_acc: 0.2400\n",
      "Epoch 799/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4151 - acc: 0.4329 - val_loss: 2.1308 - val_acc: 0.2567\n",
      "Epoch 800/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4159 - acc: 0.4214 - val_loss: 2.1383 - val_acc: 0.2333\n",
      "Epoch 801/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4159 - acc: 0.4314 - val_loss: 2.1231 - val_acc: 0.2367\n",
      "Epoch 802/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4159 - acc: 0.4314 - val_loss: 2.1722 - val_acc: 0.2400\n",
      "Epoch 803/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4145 - acc: 0.4300 - val_loss: 2.1335 - val_acc: 0.2567\n",
      "Epoch 804/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4147 - acc: 0.4243 - val_loss: 2.1283 - val_acc: 0.2433\n",
      "Epoch 805/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4145 - acc: 0.4314 - val_loss: 2.1292 - val_acc: 0.2467\n",
      "Epoch 806/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4150 - acc: 0.4300 - val_loss: 2.1312 - val_acc: 0.2400\n",
      "Epoch 807/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4148 - acc: 0.4400 - val_loss: 2.1291 - val_acc: 0.2400\n",
      "Epoch 808/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4144 - acc: 0.4329 - val_loss: 2.1369 - val_acc: 0.2400\n",
      "Epoch 809/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4151 - acc: 0.4214 - val_loss: 2.1255 - val_acc: 0.2367\n",
      "Epoch 810/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4141 - acc: 0.4371 - val_loss: 2.1354 - val_acc: 0.2367\n",
      "Epoch 811/3000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.4142 - acc: 0.4343 - val_loss: 2.1345 - val_acc: 0.2400\n",
      "Epoch 812/3000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.4141 - acc: 0.4229 - val_loss: 2.1262 - val_acc: 0.2400\n",
      "Epoch 813/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4139 - acc: 0.4329 - val_loss: 2.1426 - val_acc: 0.2400\n",
      "Epoch 814/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4130 - acc: 0.4286 - val_loss: 2.1351 - val_acc: 0.2533\n",
      "Epoch 815/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4139 - acc: 0.4286 - val_loss: 2.1405 - val_acc: 0.2467\n",
      "Epoch 816/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4135 - acc: 0.4286 - val_loss: 2.1292 - val_acc: 0.2367\n",
      "Epoch 817/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4118 - acc: 0.4257 - val_loss: 2.1349 - val_acc: 0.2367\n",
      "Epoch 818/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4123 - acc: 0.4286 - val_loss: 2.1434 - val_acc: 0.2367\n",
      "Epoch 819/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4110 - acc: 0.4386 - val_loss: 2.1515 - val_acc: 0.2600\n",
      "Epoch 820/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4132 - acc: 0.4300 - val_loss: 2.1402 - val_acc: 0.2567\n",
      "Epoch 821/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4131 - acc: 0.4314 - val_loss: 2.1451 - val_acc: 0.2467\n",
      "Epoch 822/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4128 - acc: 0.4314 - val_loss: 2.1378 - val_acc: 0.2367\n",
      "Epoch 823/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4115 - acc: 0.4257 - val_loss: 2.1453 - val_acc: 0.2433\n",
      "Epoch 824/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4109 - acc: 0.4286 - val_loss: 2.1449 - val_acc: 0.2433\n",
      "Epoch 825/3000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.4113 - acc: 0.4314 - val_loss: 2.1572 - val_acc: 0.2467\n",
      "Epoch 826/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4122 - acc: 0.4243 - val_loss: 2.1482 - val_acc: 0.2467\n",
      "Epoch 827/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4112 - acc: 0.4286 - val_loss: 2.1479 - val_acc: 0.2400\n",
      "Epoch 828/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4118 - acc: 0.4329 - val_loss: 2.1373 - val_acc: 0.2367\n",
      "Epoch 829/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4112 - acc: 0.4343 - val_loss: 2.1405 - val_acc: 0.2433\n",
      "Epoch 830/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4103 - acc: 0.4271 - val_loss: 2.1462 - val_acc: 0.2367\n",
      "Epoch 831/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4105 - acc: 0.4443 - val_loss: 2.1579 - val_acc: 0.2467\n",
      "Epoch 832/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4111 - acc: 0.4314 - val_loss: 2.1608 - val_acc: 0.2500\n",
      "Epoch 833/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4110 - acc: 0.4257 - val_loss: 2.1643 - val_acc: 0.2467\n",
      "Epoch 834/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4107 - acc: 0.4329 - val_loss: 2.1742 - val_acc: 0.2433\n",
      "Epoch 835/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4096 - acc: 0.4286 - val_loss: 2.1432 - val_acc: 0.2367\n",
      "Epoch 836/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4098 - acc: 0.4329 - val_loss: 2.1514 - val_acc: 0.2500\n",
      "Epoch 837/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4101 - acc: 0.4314 - val_loss: 2.1368 - val_acc: 0.2433\n",
      "Epoch 838/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4107 - acc: 0.4329 - val_loss: 2.1494 - val_acc: 0.2367\n",
      "Epoch 839/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4088 - acc: 0.4300 - val_loss: 2.1488 - val_acc: 0.2367\n",
      "Epoch 840/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4082 - acc: 0.4357 - val_loss: 2.1414 - val_acc: 0.2433\n",
      "Epoch 841/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4093 - acc: 0.4371 - val_loss: 2.1466 - val_acc: 0.2367\n",
      "Epoch 842/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4098 - acc: 0.4271 - val_loss: 2.1587 - val_acc: 0.2500\n",
      "Epoch 843/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4090 - acc: 0.4314 - val_loss: 2.1464 - val_acc: 0.2367\n",
      "Epoch 844/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4083 - acc: 0.4314 - val_loss: 2.1608 - val_acc: 0.2367\n",
      "Epoch 845/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4087 - acc: 0.4329 - val_loss: 2.1400 - val_acc: 0.2367\n",
      "Epoch 846/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4090 - acc: 0.4357 - val_loss: 2.1481 - val_acc: 0.2400\n",
      "Epoch 847/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.4075 - acc: 0.4229 - val_loss: 2.1584 - val_acc: 0.2433\n",
      "Epoch 848/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4080 - acc: 0.4371 - val_loss: 2.1536 - val_acc: 0.2533\n",
      "Epoch 849/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4085 - acc: 0.4314 - val_loss: 2.1555 - val_acc: 0.2433\n",
      "Epoch 850/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.4071 - acc: 0.4314 - val_loss: 2.1478 - val_acc: 0.2367\n",
      "Epoch 851/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4071 - acc: 0.4257 - val_loss: 2.1474 - val_acc: 0.2367\n",
      "Epoch 852/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4088 - acc: 0.4371 - val_loss: 2.1503 - val_acc: 0.2467\n",
      "Epoch 853/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4066 - acc: 0.4314 - val_loss: 2.1435 - val_acc: 0.2333\n",
      "Epoch 854/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4048 - acc: 0.4357 - val_loss: 2.1748 - val_acc: 0.2600\n",
      "Epoch 855/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4073 - acc: 0.4271 - val_loss: 2.1513 - val_acc: 0.2333\n",
      "Epoch 856/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4075 - acc: 0.4357 - val_loss: 2.1609 - val_acc: 0.2500\n",
      "Epoch 857/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4068 - acc: 0.4271 - val_loss: 2.1581 - val_acc: 0.2467\n",
      "Epoch 858/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4070 - acc: 0.4357 - val_loss: 2.1544 - val_acc: 0.2367\n",
      "Epoch 859/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4051 - acc: 0.4371 - val_loss: 2.1551 - val_acc: 0.2367\n",
      "Epoch 860/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4059 - acc: 0.4357 - val_loss: 2.1795 - val_acc: 0.2533\n",
      "Epoch 861/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4064 - acc: 0.4357 - val_loss: 2.1619 - val_acc: 0.2433\n",
      "Epoch 862/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4072 - acc: 0.4286 - val_loss: 2.1692 - val_acc: 0.2533\n",
      "Epoch 863/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4056 - acc: 0.4329 - val_loss: 2.1665 - val_acc: 0.2500\n",
      "Epoch 864/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4053 - acc: 0.4329 - val_loss: 2.1633 - val_acc: 0.2500\n",
      "Epoch 865/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4044 - acc: 0.4371 - val_loss: 2.1708 - val_acc: 0.2567\n",
      "Epoch 866/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4049 - acc: 0.4343 - val_loss: 2.1382 - val_acc: 0.2433\n",
      "Epoch 867/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4052 - acc: 0.4357 - val_loss: 2.1695 - val_acc: 0.2433\n",
      "Epoch 868/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4056 - acc: 0.4343 - val_loss: 2.1603 - val_acc: 0.2467\n",
      "Epoch 869/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4050 - acc: 0.4371 - val_loss: 2.1582 - val_acc: 0.2400\n",
      "Epoch 870/3000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.4034 - acc: 0.4343 - val_loss: 2.1698 - val_acc: 0.2467\n",
      "Epoch 871/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4050 - acc: 0.4314 - val_loss: 2.1736 - val_acc: 0.2467\n",
      "Epoch 872/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4038 - acc: 0.4371 - val_loss: 2.1615 - val_acc: 0.2533\n",
      "Epoch 873/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4043 - acc: 0.4329 - val_loss: 2.1412 - val_acc: 0.2367\n",
      "Epoch 874/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4048 - acc: 0.4314 - val_loss: 2.1528 - val_acc: 0.2367\n",
      "Epoch 875/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4039 - acc: 0.4329 - val_loss: 2.1759 - val_acc: 0.2500\n",
      "Epoch 876/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4037 - acc: 0.4329 - val_loss: 2.1525 - val_acc: 0.2433\n",
      "Epoch 877/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4036 - acc: 0.4271 - val_loss: 2.1726 - val_acc: 0.2367\n",
      "Epoch 878/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4042 - acc: 0.4343 - val_loss: 2.1690 - val_acc: 0.2400\n",
      "Epoch 879/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4013 - acc: 0.4371 - val_loss: 2.1686 - val_acc: 0.2400\n",
      "Epoch 880/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4051 - acc: 0.4329 - val_loss: 2.1573 - val_acc: 0.2400\n",
      "Epoch 881/3000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.4033 - acc: 0.4443 - val_loss: 2.1837 - val_acc: 0.2500\n",
      "Epoch 882/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4035 - acc: 0.4357 - val_loss: 2.1722 - val_acc: 0.2433\n",
      "Epoch 883/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4043 - acc: 0.4286 - val_loss: 2.1476 - val_acc: 0.2433\n",
      "Epoch 884/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.4027 - acc: 0.4314 - val_loss: 2.1795 - val_acc: 0.2533\n",
      "Epoch 885/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4031 - acc: 0.4314 - val_loss: 2.1441 - val_acc: 0.2433\n",
      "Epoch 886/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.4034 - acc: 0.4386 - val_loss: 2.1683 - val_acc: 0.2433\n",
      "Epoch 887/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4027 - acc: 0.4357 - val_loss: 2.1615 - val_acc: 0.2400\n",
      "Epoch 888/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4026 - acc: 0.4329 - val_loss: 2.1656 - val_acc: 0.2400\n",
      "Epoch 889/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4009 - acc: 0.4457 - val_loss: 2.1789 - val_acc: 0.2600\n",
      "Epoch 890/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.4028 - acc: 0.4343 - val_loss: 2.1654 - val_acc: 0.2567\n",
      "Epoch 891/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.0510 - acc: 0.600 - 0s 61us/step - loss: 1.4025 - acc: 0.4271 - val_loss: 2.1690 - val_acc: 0.2467\n",
      "Epoch 892/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.4024 - acc: 0.4357 - val_loss: 2.1745 - val_acc: 0.2433\n",
      "Epoch 893/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4019 - acc: 0.4357 - val_loss: 2.1779 - val_acc: 0.2467\n",
      "Epoch 894/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4021 - acc: 0.4414 - val_loss: 2.1656 - val_acc: 0.2400\n",
      "Epoch 895/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4014 - acc: 0.4371 - val_loss: 2.1707 - val_acc: 0.2467\n",
      "Epoch 896/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.4014 - acc: 0.4357 - val_loss: 2.1733 - val_acc: 0.2600\n",
      "Epoch 897/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4018 - acc: 0.4371 - val_loss: 2.1677 - val_acc: 0.2533\n",
      "Epoch 898/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 149us/step - loss: 1.4012 - acc: 0.4371 - val_loss: 2.1826 - val_acc: 0.2433\n",
      "Epoch 899/3000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4015 - acc: 0.4329 - val_loss: 2.1623 - val_acc: 0.2467\n",
      "Epoch 900/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4001 - acc: 0.4471 - val_loss: 2.1643 - val_acc: 0.2467\n",
      "Epoch 901/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.4000 - acc: 0.4400 - val_loss: 2.1774 - val_acc: 0.2533\n",
      "Epoch 902/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4002 - acc: 0.4343 - val_loss: 2.1673 - val_acc: 0.2433\n",
      "Epoch 903/3000\n",
      "700/700 [==============================] - 0s 172us/step - loss: 1.3993 - acc: 0.4400 - val_loss: 2.1851 - val_acc: 0.2633\n",
      "Epoch 904/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3990 - acc: 0.4371 - val_loss: 2.1638 - val_acc: 0.2400\n",
      "Epoch 905/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4010 - acc: 0.4414 - val_loss: 2.1601 - val_acc: 0.2367\n",
      "Epoch 906/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3999 - acc: 0.4371 - val_loss: 2.1564 - val_acc: 0.2367\n",
      "Epoch 907/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4002 - acc: 0.4371 - val_loss: 2.1823 - val_acc: 0.2467\n",
      "Epoch 908/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3999 - acc: 0.4429 - val_loss: 2.1682 - val_acc: 0.2433\n",
      "Epoch 909/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3994 - acc: 0.4343 - val_loss: 2.1767 - val_acc: 0.2500\n",
      "Epoch 910/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4004 - acc: 0.4357 - val_loss: 2.1616 - val_acc: 0.2400\n",
      "Epoch 911/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3991 - acc: 0.4386 - val_loss: 2.1794 - val_acc: 0.2367\n",
      "Epoch 912/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3995 - acc: 0.4414 - val_loss: 2.1685 - val_acc: 0.2367\n",
      "Epoch 913/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4001 - acc: 0.4386 - val_loss: 2.1880 - val_acc: 0.2433\n",
      "Epoch 914/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3985 - acc: 0.4386 - val_loss: 2.1860 - val_acc: 0.2567\n",
      "Epoch 915/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3990 - acc: 0.4343 - val_loss: 2.1748 - val_acc: 0.2467\n",
      "Epoch 916/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3988 - acc: 0.4386 - val_loss: 2.1805 - val_acc: 0.2400\n",
      "Epoch 917/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3979 - acc: 0.4400 - val_loss: 2.1795 - val_acc: 0.2367\n",
      "Epoch 918/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3970 - acc: 0.4371 - val_loss: 2.1789 - val_acc: 0.2533\n",
      "Epoch 919/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3986 - acc: 0.4343 - val_loss: 2.1864 - val_acc: 0.2433\n",
      "Epoch 920/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3988 - acc: 0.4343 - val_loss: 2.1697 - val_acc: 0.2500\n",
      "Epoch 921/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3983 - acc: 0.4371 - val_loss: 2.1721 - val_acc: 0.2400\n",
      "Epoch 922/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3967 - acc: 0.4414 - val_loss: 2.1866 - val_acc: 0.2500\n",
      "Epoch 923/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3966 - acc: 0.4400 - val_loss: 2.1706 - val_acc: 0.2533\n",
      "Epoch 924/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3988 - acc: 0.4400 - val_loss: 2.1777 - val_acc: 0.2467\n",
      "Epoch 925/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3971 - acc: 0.4343 - val_loss: 2.1816 - val_acc: 0.2367\n",
      "Epoch 926/3000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.3973 - acc: 0.4443 - val_loss: 2.1733 - val_acc: 0.2467\n",
      "Epoch 927/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3975 - acc: 0.4371 - val_loss: 2.1863 - val_acc: 0.2433\n",
      "Epoch 928/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3970 - acc: 0.4386 - val_loss: 2.1882 - val_acc: 0.2467\n",
      "Epoch 929/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3971 - acc: 0.4414 - val_loss: 2.1918 - val_acc: 0.2400\n",
      "Epoch 930/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3973 - acc: 0.4357 - val_loss: 2.1868 - val_acc: 0.2500\n",
      "Epoch 931/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3967 - acc: 0.4343 - val_loss: 2.1794 - val_acc: 0.2467\n",
      "Epoch 932/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3963 - acc: 0.4386 - val_loss: 2.1713 - val_acc: 0.2500\n",
      "Epoch 933/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3966 - acc: 0.4343 - val_loss: 2.1812 - val_acc: 0.2500\n",
      "Epoch 934/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3956 - acc: 0.4429 - val_loss: 2.1870 - val_acc: 0.2500\n",
      "Epoch 935/3000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.3967 - acc: 0.4429 - val_loss: 2.1833 - val_acc: 0.2467\n",
      "Epoch 936/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3964 - acc: 0.4414 - val_loss: 2.1904 - val_acc: 0.2500\n",
      "Epoch 937/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3961 - acc: 0.4429 - val_loss: 2.1827 - val_acc: 0.2367\n",
      "Epoch 938/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3954 - acc: 0.4457 - val_loss: 2.1920 - val_acc: 0.2500\n",
      "Epoch 939/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3953 - acc: 0.4386 - val_loss: 2.1970 - val_acc: 0.2500\n",
      "Epoch 940/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3960 - acc: 0.4357 - val_loss: 2.1784 - val_acc: 0.2400\n",
      "Epoch 941/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3957 - acc: 0.4357 - val_loss: 2.1833 - val_acc: 0.2400\n",
      "Epoch 942/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3948 - acc: 0.4357 - val_loss: 2.1688 - val_acc: 0.2333\n",
      "Epoch 943/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3955 - acc: 0.4414 - val_loss: 2.1916 - val_acc: 0.2433\n",
      "Epoch 944/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3944 - acc: 0.4371 - val_loss: 2.1941 - val_acc: 0.2433\n",
      "Epoch 945/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.3947 - acc: 0.4329 - val_loss: 2.1907 - val_acc: 0.2467\n",
      "Epoch 946/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3945 - acc: 0.4329 - val_loss: 2.1819 - val_acc: 0.2467\n",
      "Epoch 947/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3939 - acc: 0.4400 - val_loss: 2.1955 - val_acc: 0.2533\n",
      "Epoch 948/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3942 - acc: 0.4286 - val_loss: 2.1768 - val_acc: 0.2400\n",
      "Epoch 949/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3938 - acc: 0.4457 - val_loss: 2.1838 - val_acc: 0.2400\n",
      "Epoch 950/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3928 - acc: 0.4386 - val_loss: 2.1852 - val_acc: 0.2367\n",
      "Epoch 951/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3941 - acc: 0.4429 - val_loss: 2.1896 - val_acc: 0.2500\n",
      "Epoch 952/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3939 - acc: 0.4414 - val_loss: 2.1859 - val_acc: 0.2467\n",
      "Epoch 953/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3937 - acc: 0.4371 - val_loss: 2.1984 - val_acc: 0.2533\n",
      "Epoch 954/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3940 - acc: 0.4457 - val_loss: 2.1876 - val_acc: 0.2500\n",
      "Epoch 955/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3936 - acc: 0.4457 - val_loss: 2.1970 - val_acc: 0.2500\n",
      "Epoch 956/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3930 - acc: 0.4386 - val_loss: 2.2013 - val_acc: 0.2433\n",
      "Epoch 957/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3925 - acc: 0.4414 - val_loss: 2.1845 - val_acc: 0.2433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 958/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3938 - acc: 0.4343 - val_loss: 2.2129 - val_acc: 0.2467\n",
      "Epoch 959/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3936 - acc: 0.4400 - val_loss: 2.1800 - val_acc: 0.2467\n",
      "Epoch 960/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3929 - acc: 0.4371 - val_loss: 2.1919 - val_acc: 0.2467\n",
      "Epoch 961/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3924 - acc: 0.4429 - val_loss: 2.1688 - val_acc: 0.2467\n",
      "Epoch 962/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3932 - acc: 0.4414 - val_loss: 2.1904 - val_acc: 0.2467\n",
      "Epoch 963/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3925 - acc: 0.4386 - val_loss: 2.1852 - val_acc: 0.2500\n",
      "Epoch 964/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3920 - acc: 0.4400 - val_loss: 2.1876 - val_acc: 0.2500\n",
      "Epoch 965/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3911 - acc: 0.4414 - val_loss: 2.1862 - val_acc: 0.2500\n",
      "Epoch 966/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3925 - acc: 0.4414 - val_loss: 2.1953 - val_acc: 0.2533\n",
      "Epoch 967/3000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.3922 - acc: 0.4414 - val_loss: 2.1966 - val_acc: 0.2467\n",
      "Epoch 968/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3913 - acc: 0.4400 - val_loss: 2.1872 - val_acc: 0.2433\n",
      "Epoch 969/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3918 - acc: 0.4400 - val_loss: 2.1926 - val_acc: 0.2433\n",
      "Epoch 970/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3915 - acc: 0.4386 - val_loss: 2.2013 - val_acc: 0.2400\n",
      "Epoch 971/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3916 - acc: 0.4414 - val_loss: 2.1872 - val_acc: 0.2467\n",
      "Epoch 972/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3913 - acc: 0.4386 - val_loss: 2.1936 - val_acc: 0.2367\n",
      "Epoch 973/3000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 1.3903 - acc: 0.4429 - val_loss: 2.1885 - val_acc: 0.2500\n",
      "Epoch 974/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3909 - acc: 0.4357 - val_loss: 2.1959 - val_acc: 0.2500\n",
      "Epoch 975/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3908 - acc: 0.4414 - val_loss: 2.2045 - val_acc: 0.2500\n",
      "Epoch 976/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3905 - acc: 0.4429 - val_loss: 2.1920 - val_acc: 0.2533\n",
      "Epoch 977/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3907 - acc: 0.4357 - val_loss: 2.1897 - val_acc: 0.2400\n",
      "Epoch 978/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3900 - acc: 0.4471 - val_loss: 2.1955 - val_acc: 0.2533\n",
      "Epoch 979/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3907 - acc: 0.4429 - val_loss: 2.1931 - val_acc: 0.2467\n",
      "Epoch 980/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3906 - acc: 0.4429 - val_loss: 2.2050 - val_acc: 0.2500\n",
      "Epoch 981/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3895 - acc: 0.4400 - val_loss: 2.2125 - val_acc: 0.2500\n",
      "Epoch 982/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3903 - acc: 0.4400 - val_loss: 2.1966 - val_acc: 0.2533\n",
      "Epoch 983/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3899 - acc: 0.4343 - val_loss: 2.2015 - val_acc: 0.2500\n",
      "Epoch 984/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3898 - acc: 0.4414 - val_loss: 2.1944 - val_acc: 0.2500\n",
      "Epoch 985/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3892 - acc: 0.4414 - val_loss: 2.2077 - val_acc: 0.2367\n",
      "Epoch 986/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3893 - acc: 0.4414 - val_loss: 2.2004 - val_acc: 0.2500\n",
      "Epoch 987/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3888 - acc: 0.4429 - val_loss: 2.1920 - val_acc: 0.2400\n",
      "Epoch 988/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3888 - acc: 0.4443 - val_loss: 2.2148 - val_acc: 0.2633\n",
      "Epoch 989/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3902 - acc: 0.4329 - val_loss: 2.2100 - val_acc: 0.2533\n",
      "Epoch 990/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3888 - acc: 0.4457 - val_loss: 2.2189 - val_acc: 0.2533\n",
      "Epoch 991/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3890 - acc: 0.4471 - val_loss: 2.1936 - val_acc: 0.2433\n",
      "Epoch 992/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3888 - acc: 0.4371 - val_loss: 2.2059 - val_acc: 0.2400\n",
      "Epoch 993/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3884 - acc: 0.4457 - val_loss: 2.2083 - val_acc: 0.2533\n",
      "Epoch 994/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3884 - acc: 0.4357 - val_loss: 2.1854 - val_acc: 0.2333\n",
      "Epoch 995/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3892 - acc: 0.4414 - val_loss: 2.2038 - val_acc: 0.2500\n",
      "Epoch 996/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3877 - acc: 0.4457 - val_loss: 2.2022 - val_acc: 0.2500\n",
      "Epoch 997/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3880 - acc: 0.4443 - val_loss: 2.1997 - val_acc: 0.2467\n",
      "Epoch 998/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3887 - acc: 0.4400 - val_loss: 2.2123 - val_acc: 0.2533\n",
      "Epoch 999/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3881 - acc: 0.4386 - val_loss: 2.2005 - val_acc: 0.2500\n",
      "Epoch 1000/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3880 - acc: 0.4414 - val_loss: 2.2130 - val_acc: 0.2500\n",
      "Epoch 1001/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3866 - acc: 0.4443 - val_loss: 2.2002 - val_acc: 0.2567\n",
      "Epoch 1002/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3884 - acc: 0.4371 - val_loss: 2.2016 - val_acc: 0.2500\n",
      "Epoch 1003/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3860 - acc: 0.4429 - val_loss: 2.2110 - val_acc: 0.2567\n",
      "Epoch 1004/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3887 - acc: 0.4457 - val_loss: 2.2177 - val_acc: 0.2500\n",
      "Epoch 1005/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3872 - acc: 0.4357 - val_loss: 2.2016 - val_acc: 0.2467\n",
      "Epoch 1006/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3868 - acc: 0.4371 - val_loss: 2.2208 - val_acc: 0.2533\n",
      "Epoch 1007/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3864 - acc: 0.4414 - val_loss: 2.2166 - val_acc: 0.2567\n",
      "Epoch 1008/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3869 - acc: 0.4371 - val_loss: 2.1981 - val_acc: 0.2500\n",
      "Epoch 1009/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3865 - acc: 0.4443 - val_loss: 2.2228 - val_acc: 0.2500\n",
      "Epoch 1010/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3865 - acc: 0.4471 - val_loss: 2.2003 - val_acc: 0.2500\n",
      "Epoch 1011/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3858 - acc: 0.4429 - val_loss: 2.2104 - val_acc: 0.2533\n",
      "Epoch 1012/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3853 - acc: 0.4429 - val_loss: 2.2123 - val_acc: 0.2533\n",
      "Epoch 1013/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3852 - acc: 0.4471 - val_loss: 2.2000 - val_acc: 0.2400\n",
      "Epoch 1014/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3852 - acc: 0.4414 - val_loss: 2.2000 - val_acc: 0.2567\n",
      "Epoch 1015/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3843 - acc: 0.4457 - val_loss: 2.2069 - val_acc: 0.2400\n",
      "Epoch 1016/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3867 - acc: 0.4400 - val_loss: 2.2084 - val_acc: 0.2467\n",
      "Epoch 1017/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3863 - acc: 0.4343 - val_loss: 2.2079 - val_acc: 0.2500\n",
      "Epoch 1018/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3860 - acc: 0.4486 - val_loss: 2.2030 - val_acc: 0.2500\n",
      "Epoch 1019/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3849 - acc: 0.4386 - val_loss: 2.2079 - val_acc: 0.2467\n",
      "Epoch 1020/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3849 - acc: 0.4543 - val_loss: 2.1974 - val_acc: 0.2500\n",
      "Epoch 1021/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3855 - acc: 0.4457 - val_loss: 2.2068 - val_acc: 0.2500\n",
      "Epoch 1022/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.3619 - acc: 0.464 - 0s 110us/step - loss: 1.3843 - acc: 0.4514 - val_loss: 2.2102 - val_acc: 0.2400\n",
      "Epoch 1023/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3855 - acc: 0.4414 - val_loss: 2.2017 - val_acc: 0.2500\n",
      "Epoch 1024/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3850 - acc: 0.4529 - val_loss: 2.2025 - val_acc: 0.2433\n",
      "Epoch 1025/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3844 - acc: 0.4429 - val_loss: 2.2053 - val_acc: 0.2533\n",
      "Epoch 1026/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3849 - acc: 0.4457 - val_loss: 2.1894 - val_acc: 0.2433\n",
      "Epoch 1027/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3840 - acc: 0.4457 - val_loss: 2.2129 - val_acc: 0.2500\n",
      "Epoch 1028/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3842 - acc: 0.4400 - val_loss: 2.2033 - val_acc: 0.2467\n",
      "Epoch 1029/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3844 - acc: 0.4443 - val_loss: 2.2034 - val_acc: 0.2500\n",
      "Epoch 1030/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3835 - acc: 0.4529 - val_loss: 2.2148 - val_acc: 0.2500\n",
      "Epoch 1031/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3835 - acc: 0.4457 - val_loss: 2.2181 - val_acc: 0.2533\n",
      "Epoch 1032/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3846 - acc: 0.4443 - val_loss: 2.2189 - val_acc: 0.2433\n",
      "Epoch 1033/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3843 - acc: 0.4429 - val_loss: 2.2272 - val_acc: 0.2467\n",
      "Epoch 1034/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3822 - acc: 0.4457 - val_loss: 2.2086 - val_acc: 0.2333\n",
      "Epoch 1035/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3842 - acc: 0.4443 - val_loss: 2.2116 - val_acc: 0.2533\n",
      "Epoch 1036/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3837 - acc: 0.4486 - val_loss: 2.2096 - val_acc: 0.2500\n",
      "Epoch 1037/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3832 - acc: 0.4429 - val_loss: 2.2092 - val_acc: 0.2400\n",
      "Epoch 1038/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3838 - acc: 0.4443 - val_loss: 2.2300 - val_acc: 0.2567\n",
      "Epoch 1039/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3834 - acc: 0.4457 - val_loss: 2.2165 - val_acc: 0.2467\n",
      "Epoch 1040/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3832 - acc: 0.4400 - val_loss: 2.2157 - val_acc: 0.2467\n",
      "Epoch 1041/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3825 - acc: 0.4443 - val_loss: 2.2251 - val_acc: 0.2500\n",
      "Epoch 1042/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3816 - acc: 0.4429 - val_loss: 2.2030 - val_acc: 0.2467\n",
      "Epoch 1043/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.3835 - acc: 0.4400 - val_loss: 2.2228 - val_acc: 0.2567\n",
      "Epoch 1044/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3826 - acc: 0.4429 - val_loss: 2.2154 - val_acc: 0.2467\n",
      "Epoch 1045/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3801 - acc: 0.4386 - val_loss: 2.2117 - val_acc: 0.2333\n",
      "Epoch 1046/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3832 - acc: 0.4514 - val_loss: 2.2172 - val_acc: 0.2433\n",
      "Epoch 1047/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3809 - acc: 0.4486 - val_loss: 2.2113 - val_acc: 0.2333\n",
      "Epoch 1048/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3825 - acc: 0.4386 - val_loss: 2.2074 - val_acc: 0.2433\n",
      "Epoch 1049/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3818 - acc: 0.4429 - val_loss: 2.2125 - val_acc: 0.2500\n",
      "Epoch 1050/3000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.3809 - acc: 0.4471 - val_loss: 2.2219 - val_acc: 0.2433\n",
      "Epoch 1051/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3822 - acc: 0.4471 - val_loss: 2.2119 - val_acc: 0.2500\n",
      "Epoch 1052/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3810 - acc: 0.4371 - val_loss: 2.2236 - val_acc: 0.2433\n",
      "Epoch 1053/3000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.3813 - acc: 0.4429 - val_loss: 2.2185 - val_acc: 0.2467\n",
      "Epoch 1054/3000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 1.3808 - acc: 0.4500 - val_loss: 2.2116 - val_acc: 0.2533\n",
      "Epoch 1055/3000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.3807 - acc: 0.4457 - val_loss: 2.2088 - val_acc: 0.2500\n",
      "Epoch 1056/3000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3805 - acc: 0.4386 - val_loss: 2.2250 - val_acc: 0.2500\n",
      "Epoch 1057/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3799 - acc: 0.4343 - val_loss: 2.2336 - val_acc: 0.2433\n",
      "Epoch 1058/3000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.3814 - acc: 0.4429 - val_loss: 2.2202 - val_acc: 0.2533\n",
      "Epoch 1059/3000\n",
      "700/700 [==============================] - 0s 184us/step - loss: 1.3797 - acc: 0.4514 - val_loss: 2.2243 - val_acc: 0.2500\n",
      "Epoch 1060/3000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.3803 - acc: 0.4443 - val_loss: 2.2173 - val_acc: 0.2533\n",
      "Epoch 1061/3000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3805 - acc: 0.4457 - val_loss: 2.2335 - val_acc: 0.2533\n",
      "Epoch 1062/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3811 - acc: 0.4386 - val_loss: 2.2129 - val_acc: 0.2500\n",
      "Epoch 1063/3000\n",
      "700/700 [==============================] - 0s 235us/step - loss: 1.3796 - acc: 0.4429 - val_loss: 2.2131 - val_acc: 0.2533\n",
      "Epoch 1064/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.3800 - acc: 0.4429 - val_loss: 2.2233 - val_acc: 0.2500\n",
      "Epoch 1065/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3801 - acc: 0.4400 - val_loss: 2.2129 - val_acc: 0.2433\n",
      "Epoch 1066/3000\n",
      "700/700 [==============================] - 0s 211us/step - loss: 1.3800 - acc: 0.4400 - val_loss: 2.2140 - val_acc: 0.2367\n",
      "Epoch 1067/3000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.3797 - acc: 0.4500 - val_loss: 2.2370 - val_acc: 0.2567\n",
      "Epoch 1068/3000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 1.3794 - acc: 0.4443 - val_loss: 2.2347 - val_acc: 0.2467\n",
      "Epoch 1069/3000\n",
      "700/700 [==============================] - 0s 193us/step - loss: 1.3795 - acc: 0.4386 - val_loss: 2.2327 - val_acc: 0.2500\n",
      "Epoch 1070/3000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.3787 - acc: 0.4457 - val_loss: 2.2222 - val_acc: 0.2367\n",
      "Epoch 1071/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3783 - acc: 0.4471 - val_loss: 2.2406 - val_acc: 0.2267\n",
      "Epoch 1072/3000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.3788 - acc: 0.4529 - val_loss: 2.2228 - val_acc: 0.2533\n",
      "Epoch 1073/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.3734 - acc: 0.446 - 0s 180us/step - loss: 1.3785 - acc: 0.4443 - val_loss: 2.2139 - val_acc: 0.2500\n",
      "Epoch 1074/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.3788 - acc: 0.4514 - val_loss: 2.2084 - val_acc: 0.2500\n",
      "Epoch 1075/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 113us/step - loss: 1.3786 - acc: 0.4500 - val_loss: 2.2183 - val_acc: 0.2400\n",
      "Epoch 1076/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3790 - acc: 0.4443 - val_loss: 2.2176 - val_acc: 0.2533\n",
      "Epoch 1077/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3785 - acc: 0.4457 - val_loss: 2.2121 - val_acc: 0.2367\n",
      "Epoch 1078/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3785 - acc: 0.4471 - val_loss: 2.2268 - val_acc: 0.2433\n",
      "Epoch 1079/3000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3779 - acc: 0.4443 - val_loss: 2.2219 - val_acc: 0.2400\n",
      "Epoch 1080/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3780 - acc: 0.4400 - val_loss: 2.2192 - val_acc: 0.2533\n",
      "Epoch 1081/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3782 - acc: 0.4486 - val_loss: 2.2230 - val_acc: 0.2400\n",
      "Epoch 1082/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3771 - acc: 0.4486 - val_loss: 2.2306 - val_acc: 0.2533\n",
      "Epoch 1083/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3782 - acc: 0.4400 - val_loss: 2.2209 - val_acc: 0.2333\n",
      "Epoch 1084/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3783 - acc: 0.4471 - val_loss: 2.2385 - val_acc: 0.2433\n",
      "Epoch 1085/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3774 - acc: 0.4414 - val_loss: 2.2278 - val_acc: 0.2533\n",
      "Epoch 1086/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3777 - acc: 0.4457 - val_loss: 2.2377 - val_acc: 0.2400\n",
      "Epoch 1087/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3768 - acc: 0.4514 - val_loss: 2.2275 - val_acc: 0.2367\n",
      "Epoch 1088/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3769 - acc: 0.4529 - val_loss: 2.2207 - val_acc: 0.2500\n",
      "Epoch 1089/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3780 - acc: 0.4443 - val_loss: 2.2308 - val_acc: 0.2500\n",
      "Epoch 1090/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3767 - acc: 0.4457 - val_loss: 2.2325 - val_acc: 0.2533\n",
      "Epoch 1091/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3766 - acc: 0.4486 - val_loss: 2.2212 - val_acc: 0.2400\n",
      "Epoch 1092/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3766 - acc: 0.4543 - val_loss: 2.2321 - val_acc: 0.2500\n",
      "Epoch 1093/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3769 - acc: 0.4457 - val_loss: 2.2306 - val_acc: 0.2467\n",
      "Epoch 1094/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3752 - acc: 0.4557 - val_loss: 2.2183 - val_acc: 0.2433\n",
      "Epoch 1095/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3779 - acc: 0.4414 - val_loss: 2.2291 - val_acc: 0.2533\n",
      "Epoch 1096/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3759 - acc: 0.4443 - val_loss: 2.2288 - val_acc: 0.2367\n",
      "Epoch 1097/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3763 - acc: 0.4571 - val_loss: 2.2290 - val_acc: 0.2533\n",
      "Epoch 1098/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3767 - acc: 0.4429 - val_loss: 2.2500 - val_acc: 0.2500\n",
      "Epoch 1099/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3766 - acc: 0.4457 - val_loss: 2.2523 - val_acc: 0.2533\n",
      "Epoch 1100/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3761 - acc: 0.4471 - val_loss: 2.2298 - val_acc: 0.2467\n",
      "Epoch 1101/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3759 - acc: 0.4500 - val_loss: 2.2316 - val_acc: 0.2500\n",
      "Epoch 1102/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3749 - acc: 0.4400 - val_loss: 2.2353 - val_acc: 0.2367\n",
      "Epoch 1103/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3754 - acc: 0.4414 - val_loss: 2.2394 - val_acc: 0.2533\n",
      "Epoch 1104/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3759 - acc: 0.4400 - val_loss: 2.2233 - val_acc: 0.2533\n",
      "Epoch 1105/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3752 - acc: 0.4486 - val_loss: 2.2256 - val_acc: 0.2533\n",
      "Epoch 1106/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3748 - acc: 0.4514 - val_loss: 2.2391 - val_acc: 0.2533\n",
      "Epoch 1107/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3759 - acc: 0.4471 - val_loss: 2.2132 - val_acc: 0.2500\n",
      "Epoch 1108/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3755 - acc: 0.4471 - val_loss: 2.2381 - val_acc: 0.2467\n",
      "Epoch 1109/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3756 - acc: 0.4500 - val_loss: 2.2463 - val_acc: 0.2500\n",
      "Epoch 1110/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3746 - acc: 0.4429 - val_loss: 2.2139 - val_acc: 0.2433\n",
      "Epoch 1111/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3742 - acc: 0.4529 - val_loss: 2.2407 - val_acc: 0.2500\n",
      "Epoch 1112/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3745 - acc: 0.4443 - val_loss: 2.2397 - val_acc: 0.2400\n",
      "Epoch 1113/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3738 - acc: 0.4443 - val_loss: 2.2408 - val_acc: 0.2533\n",
      "Epoch 1114/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3744 - acc: 0.4486 - val_loss: 2.2327 - val_acc: 0.2533\n",
      "Epoch 1115/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3752 - acc: 0.4429 - val_loss: 2.2302 - val_acc: 0.2533\n",
      "Epoch 1116/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3739 - acc: 0.4500 - val_loss: 2.2360 - val_acc: 0.2533\n",
      "Epoch 1117/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3736 - acc: 0.4500 - val_loss: 2.2357 - val_acc: 0.2433\n",
      "Epoch 1118/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3741 - acc: 0.4543 - val_loss: 2.2358 - val_acc: 0.2467\n",
      "Epoch 1119/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3731 - acc: 0.4400 - val_loss: 2.2331 - val_acc: 0.2300\n",
      "Epoch 1120/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3734 - acc: 0.4543 - val_loss: 2.2522 - val_acc: 0.2500\n",
      "Epoch 1121/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3745 - acc: 0.4471 - val_loss: 2.2234 - val_acc: 0.2433\n",
      "Epoch 1122/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3736 - acc: 0.4471 - val_loss: 2.2385 - val_acc: 0.2533\n",
      "Epoch 1123/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3729 - acc: 0.4500 - val_loss: 2.2300 - val_acc: 0.2467\n",
      "Epoch 1124/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3740 - acc: 0.4500 - val_loss: 2.2342 - val_acc: 0.2433\n",
      "Epoch 1125/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3736 - acc: 0.4486 - val_loss: 2.2298 - val_acc: 0.2500\n",
      "Epoch 1126/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3723 - acc: 0.4529 - val_loss: 2.2363 - val_acc: 0.2533\n",
      "Epoch 1127/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3729 - acc: 0.4586 - val_loss: 2.2424 - val_acc: 0.2500\n",
      "Epoch 1128/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3737 - acc: 0.4457 - val_loss: 2.2583 - val_acc: 0.2500\n",
      "Epoch 1129/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3720 - acc: 0.4457 - val_loss: 2.2459 - val_acc: 0.2333\n",
      "Epoch 1130/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3727 - acc: 0.4443 - val_loss: 2.2403 - val_acc: 0.2500\n",
      "Epoch 1131/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3712 - acc: 0.4457 - val_loss: 2.2510 - val_acc: 0.2533\n",
      "Epoch 1132/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3737 - acc: 0.4457 - val_loss: 2.2418 - val_acc: 0.2467\n",
      "Epoch 1133/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3716 - acc: 0.4529 - val_loss: 2.2493 - val_acc: 0.2467\n",
      "Epoch 1134/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3718 - acc: 0.4443 - val_loss: 2.2420 - val_acc: 0.2333\n",
      "Epoch 1135/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3728 - acc: 0.4514 - val_loss: 2.2411 - val_acc: 0.2500\n",
      "Epoch 1136/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3720 - acc: 0.4500 - val_loss: 2.2320 - val_acc: 0.2467\n",
      "Epoch 1137/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3726 - acc: 0.4486 - val_loss: 2.2377 - val_acc: 0.2467\n",
      "Epoch 1138/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3716 - acc: 0.4514 - val_loss: 2.2393 - val_acc: 0.2433\n",
      "Epoch 1139/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3722 - acc: 0.4514 - val_loss: 2.2321 - val_acc: 0.2500\n",
      "Epoch 1140/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3702 - acc: 0.4529 - val_loss: 2.2342 - val_acc: 0.2333\n",
      "Epoch 1141/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.3714 - acc: 0.4529 - val_loss: 2.2588 - val_acc: 0.2500\n",
      "Epoch 1142/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3718 - acc: 0.4543 - val_loss: 2.2537 - val_acc: 0.2500\n",
      "Epoch 1143/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3708 - acc: 0.4457 - val_loss: 2.2486 - val_acc: 0.2433\n",
      "Epoch 1144/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3688 - acc: 0.4457 - val_loss: 2.2592 - val_acc: 0.2367\n",
      "Epoch 1145/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.3717 - acc: 0.4514 - val_loss: 2.2456 - val_acc: 0.2467\n",
      "Epoch 1146/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3706 - acc: 0.4514 - val_loss: 2.2489 - val_acc: 0.2333\n",
      "Epoch 1147/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3703 - acc: 0.4557 - val_loss: 2.2364 - val_acc: 0.2333\n",
      "Epoch 1148/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3714 - acc: 0.4543 - val_loss: 2.2565 - val_acc: 0.2467\n",
      "Epoch 1149/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3712 - acc: 0.4457 - val_loss: 2.2405 - val_acc: 0.2367\n",
      "Epoch 1150/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3714 - acc: 0.4500 - val_loss: 2.2260 - val_acc: 0.2400\n",
      "Epoch 1151/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.3713 - acc: 0.4486 - val_loss: 2.2326 - val_acc: 0.2400\n",
      "Epoch 1152/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3698 - acc: 0.4500 - val_loss: 2.2437 - val_acc: 0.2500\n",
      "Epoch 1153/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3711 - acc: 0.4457 - val_loss: 2.2493 - val_acc: 0.2467\n",
      "Epoch 1154/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3698 - acc: 0.4529 - val_loss: 2.2222 - val_acc: 0.2367\n",
      "Epoch 1155/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3698 - acc: 0.4514 - val_loss: 2.2427 - val_acc: 0.2433\n",
      "Epoch 1156/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3706 - acc: 0.4471 - val_loss: 2.2376 - val_acc: 0.2300\n",
      "Epoch 1157/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3706 - acc: 0.4529 - val_loss: 2.2445 - val_acc: 0.2433\n",
      "Epoch 1158/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3695 - acc: 0.4543 - val_loss: 2.2635 - val_acc: 0.2533\n",
      "Epoch 1159/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3698 - acc: 0.4457 - val_loss: 2.2452 - val_acc: 0.2500\n",
      "Epoch 1160/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3710 - acc: 0.4543 - val_loss: 2.2605 - val_acc: 0.2433\n",
      "Epoch 1161/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3694 - acc: 0.4571 - val_loss: 2.2509 - val_acc: 0.2467\n",
      "Epoch 1162/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3696 - acc: 0.4586 - val_loss: 2.2533 - val_acc: 0.2467\n",
      "Epoch 1163/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3694 - acc: 0.4557 - val_loss: 2.2546 - val_acc: 0.2467\n",
      "Epoch 1164/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3688 - acc: 0.4557 - val_loss: 2.2570 - val_acc: 0.2300\n",
      "Epoch 1165/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3701 - acc: 0.4529 - val_loss: 2.2260 - val_acc: 0.2367\n",
      "Epoch 1166/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3688 - acc: 0.4543 - val_loss: 2.2367 - val_acc: 0.2433\n",
      "Epoch 1167/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3688 - acc: 0.4557 - val_loss: 2.2458 - val_acc: 0.2433\n",
      "Epoch 1168/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3689 - acc: 0.4500 - val_loss: 2.2415 - val_acc: 0.2333\n",
      "Epoch 1169/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3682 - acc: 0.4500 - val_loss: 2.2496 - val_acc: 0.2467\n",
      "Epoch 1170/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3682 - acc: 0.4529 - val_loss: 2.2417 - val_acc: 0.2467\n",
      "Epoch 1171/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3677 - acc: 0.4514 - val_loss: 2.2384 - val_acc: 0.2433\n",
      "Epoch 1172/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3681 - acc: 0.4543 - val_loss: 2.2563 - val_acc: 0.2433\n",
      "Epoch 1173/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3680 - acc: 0.4529 - val_loss: 2.2483 - val_acc: 0.2300\n",
      "Epoch 1174/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3689 - acc: 0.4486 - val_loss: 2.2401 - val_acc: 0.2433\n",
      "Epoch 1175/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3672 - acc: 0.4529 - val_loss: 2.2478 - val_acc: 0.2433\n",
      "Epoch 1176/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3680 - acc: 0.4514 - val_loss: 2.2520 - val_acc: 0.2400\n",
      "Epoch 1177/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3680 - acc: 0.4500 - val_loss: 2.2580 - val_acc: 0.2467\n",
      "Epoch 1178/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3672 - acc: 0.4486 - val_loss: 2.2526 - val_acc: 0.2300\n",
      "Epoch 1179/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3678 - acc: 0.4557 - val_loss: 2.2525 - val_acc: 0.2300\n",
      "Epoch 1180/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3681 - acc: 0.4500 - val_loss: 2.2550 - val_acc: 0.2433\n",
      "Epoch 1181/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3671 - acc: 0.4571 - val_loss: 2.2626 - val_acc: 0.2500\n",
      "Epoch 1182/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3680 - acc: 0.4543 - val_loss: 2.2465 - val_acc: 0.2400\n",
      "Epoch 1183/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3673 - acc: 0.4529 - val_loss: 2.2485 - val_acc: 0.2400\n",
      "Epoch 1184/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3663 - acc: 0.4557 - val_loss: 2.2434 - val_acc: 0.2467\n",
      "Epoch 1185/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3673 - acc: 0.4543 - val_loss: 2.2452 - val_acc: 0.2400\n",
      "Epoch 1186/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3673 - acc: 0.4486 - val_loss: 2.2612 - val_acc: 0.2467\n",
      "Epoch 1187/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3664 - acc: 0.4529 - val_loss: 2.2483 - val_acc: 0.2333\n",
      "Epoch 1188/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3668 - acc: 0.4557 - val_loss: 2.2635 - val_acc: 0.2467\n",
      "Epoch 1189/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3656 - acc: 0.4600 - val_loss: 2.2548 - val_acc: 0.2467\n",
      "Epoch 1190/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3662 - acc: 0.4486 - val_loss: 2.2674 - val_acc: 0.2533\n",
      "Epoch 1191/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3669 - acc: 0.4443 - val_loss: 2.2576 - val_acc: 0.2333\n",
      "Epoch 1192/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.3593 - acc: 0.461 - 0s 98us/step - loss: 1.3665 - acc: 0.4586 - val_loss: 2.2413 - val_acc: 0.2433\n",
      "Epoch 1193/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 80us/step - loss: 1.3665 - acc: 0.4586 - val_loss: 2.2576 - val_acc: 0.2433\n",
      "Epoch 1194/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3661 - acc: 0.4514 - val_loss: 2.2480 - val_acc: 0.2300\n",
      "Epoch 1195/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.3666 - acc: 0.4529 - val_loss: 2.2450 - val_acc: 0.2300\n",
      "Epoch 1196/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3656 - acc: 0.4614 - val_loss: 2.2561 - val_acc: 0.2467\n",
      "Epoch 1197/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3658 - acc: 0.4543 - val_loss: 2.2537 - val_acc: 0.2400\n",
      "Epoch 1198/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3653 - acc: 0.4557 - val_loss: 2.2535 - val_acc: 0.2500\n",
      "Epoch 1199/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3655 - acc: 0.4514 - val_loss: 2.2523 - val_acc: 0.2333\n",
      "Epoch 1200/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3662 - acc: 0.4500 - val_loss: 2.2612 - val_acc: 0.2400\n",
      "Epoch 1201/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3654 - acc: 0.4571 - val_loss: 2.2531 - val_acc: 0.2433\n",
      "Epoch 1202/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3661 - acc: 0.4543 - val_loss: 2.2637 - val_acc: 0.2467\n",
      "Epoch 1203/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3653 - acc: 0.4586 - val_loss: 2.2394 - val_acc: 0.2433\n",
      "Epoch 1204/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3653 - acc: 0.4600 - val_loss: 2.2422 - val_acc: 0.2467\n",
      "Epoch 1205/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3641 - acc: 0.4629 - val_loss: 2.2487 - val_acc: 0.2467\n",
      "Epoch 1206/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3651 - acc: 0.4586 - val_loss: 2.2565 - val_acc: 0.2433\n",
      "Epoch 1207/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3637 - acc: 0.4600 - val_loss: 2.2587 - val_acc: 0.2233\n",
      "Epoch 1208/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3635 - acc: 0.4500 - val_loss: 2.2573 - val_acc: 0.2267\n",
      "Epoch 1209/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3630 - acc: 0.4571 - val_loss: 2.2517 - val_acc: 0.2433\n",
      "Epoch 1210/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3648 - acc: 0.4543 - val_loss: 2.2557 - val_acc: 0.2433\n",
      "Epoch 1211/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3646 - acc: 0.4586 - val_loss: 2.2612 - val_acc: 0.2433\n",
      "Epoch 1212/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3631 - acc: 0.4514 - val_loss: 2.2613 - val_acc: 0.2467\n",
      "Epoch 1213/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3656 - acc: 0.4557 - val_loss: 2.2533 - val_acc: 0.2467\n",
      "Epoch 1214/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3635 - acc: 0.4557 - val_loss: 2.2658 - val_acc: 0.2467\n",
      "Epoch 1215/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3633 - acc: 0.4514 - val_loss: 2.2607 - val_acc: 0.2467\n",
      "Epoch 1216/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3637 - acc: 0.4600 - val_loss: 2.2528 - val_acc: 0.2433\n",
      "Epoch 1217/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3637 - acc: 0.4543 - val_loss: 2.2661 - val_acc: 0.2467\n",
      "Epoch 1218/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3635 - acc: 0.4571 - val_loss: 2.2584 - val_acc: 0.2400\n",
      "Epoch 1219/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3633 - acc: 0.4571 - val_loss: 2.2605 - val_acc: 0.2433\n",
      "Epoch 1220/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3642 - acc: 0.4543 - val_loss: 2.2448 - val_acc: 0.2433\n",
      "Epoch 1221/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3631 - acc: 0.4557 - val_loss: 2.2667 - val_acc: 0.2300\n",
      "Epoch 1222/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3635 - acc: 0.4600 - val_loss: 2.2702 - val_acc: 0.2433\n",
      "Epoch 1223/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3635 - acc: 0.4571 - val_loss: 2.2685 - val_acc: 0.2467\n",
      "Epoch 1224/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3624 - acc: 0.4586 - val_loss: 2.2692 - val_acc: 0.2500\n",
      "Epoch 1225/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3621 - acc: 0.4529 - val_loss: 2.2663 - val_acc: 0.2300\n",
      "Epoch 1226/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3636 - acc: 0.4629 - val_loss: 2.2588 - val_acc: 0.2433\n",
      "Epoch 1227/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3609 - acc: 0.4557 - val_loss: 2.2543 - val_acc: 0.2433\n",
      "Epoch 1228/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3627 - acc: 0.4614 - val_loss: 2.2694 - val_acc: 0.2433\n",
      "Epoch 1229/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3630 - acc: 0.4543 - val_loss: 2.2638 - val_acc: 0.2433\n",
      "Epoch 1230/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3624 - acc: 0.4586 - val_loss: 2.2534 - val_acc: 0.2467\n",
      "Epoch 1231/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3629 - acc: 0.4571 - val_loss: 2.2440 - val_acc: 0.2333\n",
      "Epoch 1232/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3626 - acc: 0.4543 - val_loss: 2.2726 - val_acc: 0.2500\n",
      "Epoch 1233/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3632 - acc: 0.4586 - val_loss: 2.2520 - val_acc: 0.2433\n",
      "Epoch 1234/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3617 - acc: 0.4686 - val_loss: 2.2470 - val_acc: 0.2467\n",
      "Epoch 1235/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3618 - acc: 0.4557 - val_loss: 2.2517 - val_acc: 0.2400\n",
      "Epoch 1236/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3620 - acc: 0.4543 - val_loss: 2.2510 - val_acc: 0.2367\n",
      "Epoch 1237/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3621 - acc: 0.4486 - val_loss: 2.2508 - val_acc: 0.2433\n",
      "Epoch 1238/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3610 - acc: 0.4571 - val_loss: 2.2672 - val_acc: 0.2500\n",
      "Epoch 1239/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.1056 - acc: 0.400 - 0s 69us/step - loss: 1.3619 - acc: 0.4514 - val_loss: 2.2601 - val_acc: 0.2467\n",
      "Epoch 1240/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3614 - acc: 0.4586 - val_loss: 2.2578 - val_acc: 0.2467\n",
      "Epoch 1241/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3615 - acc: 0.4543 - val_loss: 2.2630 - val_acc: 0.2400\n",
      "Epoch 1242/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3607 - acc: 0.4500 - val_loss: 2.2601 - val_acc: 0.2433\n",
      "Epoch 1243/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3612 - acc: 0.4614 - val_loss: 2.2731 - val_acc: 0.2467\n",
      "Epoch 1244/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3612 - acc: 0.4514 - val_loss: 2.2489 - val_acc: 0.2500\n",
      "Epoch 1245/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3608 - acc: 0.4629 - val_loss: 2.2524 - val_acc: 0.2433\n",
      "Epoch 1246/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3603 - acc: 0.4600 - val_loss: 2.2748 - val_acc: 0.2433\n",
      "Epoch 1247/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3601 - acc: 0.4614 - val_loss: 2.2673 - val_acc: 0.2433\n",
      "Epoch 1248/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3608 - acc: 0.4543 - val_loss: 2.2694 - val_acc: 0.2433\n",
      "Epoch 1249/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3612 - acc: 0.4571 - val_loss: 2.2617 - val_acc: 0.2400\n",
      "Epoch 1250/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3598 - acc: 0.4586 - val_loss: 2.2898 - val_acc: 0.2300\n",
      "Epoch 1251/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3607 - acc: 0.4600 - val_loss: 2.2661 - val_acc: 0.2400\n",
      "Epoch 1252/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3596 - acc: 0.4629 - val_loss: 2.2762 - val_acc: 0.2400\n",
      "Epoch 1253/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3607 - acc: 0.4500 - val_loss: 2.2630 - val_acc: 0.2400\n",
      "Epoch 1254/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3600 - acc: 0.4600 - val_loss: 2.2566 - val_acc: 0.2467\n",
      "Epoch 1255/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3603 - acc: 0.4586 - val_loss: 2.2600 - val_acc: 0.2433\n",
      "Epoch 1256/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3592 - acc: 0.4586 - val_loss: 2.2745 - val_acc: 0.2333\n",
      "Epoch 1257/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3599 - acc: 0.4586 - val_loss: 2.2791 - val_acc: 0.2467\n",
      "Epoch 1258/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3600 - acc: 0.4686 - val_loss: 2.2549 - val_acc: 0.2433\n",
      "Epoch 1259/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3598 - acc: 0.4629 - val_loss: 2.2520 - val_acc: 0.2400\n",
      "Epoch 1260/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3591 - acc: 0.4657 - val_loss: 2.2702 - val_acc: 0.2433\n",
      "Epoch 1261/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3598 - acc: 0.4557 - val_loss: 2.2645 - val_acc: 0.2400\n",
      "Epoch 1262/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3599 - acc: 0.4571 - val_loss: 2.2668 - val_acc: 0.2400\n",
      "Epoch 1263/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3589 - acc: 0.4671 - val_loss: 2.2715 - val_acc: 0.2400\n",
      "Epoch 1264/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3593 - acc: 0.4586 - val_loss: 2.2585 - val_acc: 0.2367\n",
      "Epoch 1265/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.3593 - acc: 0.4586 - val_loss: 2.2629 - val_acc: 0.2400\n",
      "Epoch 1266/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3593 - acc: 0.4600 - val_loss: 2.2526 - val_acc: 0.2467\n",
      "Epoch 1267/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.3585 - acc: 0.4600 - val_loss: 2.2561 - val_acc: 0.2400\n",
      "Epoch 1268/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3595 - acc: 0.4614 - val_loss: 2.2665 - val_acc: 0.2433\n",
      "Epoch 1269/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3586 - acc: 0.4671 - val_loss: 2.2819 - val_acc: 0.2467\n",
      "Epoch 1270/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3583 - acc: 0.4643 - val_loss: 2.2682 - val_acc: 0.2433\n",
      "Epoch 1271/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3588 - acc: 0.4586 - val_loss: 2.2614 - val_acc: 0.2400\n",
      "Epoch 1272/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3584 - acc: 0.4643 - val_loss: 2.2642 - val_acc: 0.2433\n",
      "Epoch 1273/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3583 - acc: 0.4614 - val_loss: 2.2662 - val_acc: 0.2400\n",
      "Epoch 1274/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3587 - acc: 0.4600 - val_loss: 2.2640 - val_acc: 0.2433\n",
      "Epoch 1275/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3577 - acc: 0.4629 - val_loss: 2.2733 - val_acc: 0.2433\n",
      "Epoch 1276/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3588 - acc: 0.4586 - val_loss: 2.2726 - val_acc: 0.2400\n",
      "Epoch 1277/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3580 - acc: 0.4557 - val_loss: 2.2731 - val_acc: 0.2467\n",
      "Epoch 1278/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3576 - acc: 0.4586 - val_loss: 2.2776 - val_acc: 0.2467\n",
      "Epoch 1279/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.3578 - acc: 0.4529 - val_loss: 2.2664 - val_acc: 0.2400\n",
      "Epoch 1280/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3572 - acc: 0.4614 - val_loss: 2.2770 - val_acc: 0.2433\n",
      "Epoch 1281/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3574 - acc: 0.4514 - val_loss: 2.2549 - val_acc: 0.2433\n",
      "Epoch 1282/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3577 - acc: 0.4600 - val_loss: 2.2748 - val_acc: 0.2433\n",
      "Epoch 1283/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3572 - acc: 0.4657 - val_loss: 2.2926 - val_acc: 0.2500\n",
      "Epoch 1284/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3575 - acc: 0.4629 - val_loss: 2.2852 - val_acc: 0.2533\n",
      "Epoch 1285/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3549 - acc: 0.4586 - val_loss: 2.2607 - val_acc: 0.2333\n",
      "Epoch 1286/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3547 - acc: 0.4614 - val_loss: 2.2798 - val_acc: 0.2500\n",
      "Epoch 1287/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3573 - acc: 0.4614 - val_loss: 2.2845 - val_acc: 0.2500\n",
      "Epoch 1288/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3566 - acc: 0.4571 - val_loss: 2.2772 - val_acc: 0.2500\n",
      "Epoch 1289/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3569 - acc: 0.4700 - val_loss: 2.2725 - val_acc: 0.2533\n",
      "Epoch 1290/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3570 - acc: 0.4643 - val_loss: 2.2702 - val_acc: 0.2400\n",
      "Epoch 1291/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3572 - acc: 0.4629 - val_loss: 2.2808 - val_acc: 0.2400\n",
      "Epoch 1292/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3566 - acc: 0.4600 - val_loss: 2.2848 - val_acc: 0.2533\n",
      "Epoch 1293/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3561 - acc: 0.4571 - val_loss: 2.2709 - val_acc: 0.2400\n",
      "Epoch 1294/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3565 - acc: 0.4643 - val_loss: 2.2790 - val_acc: 0.2367\n",
      "Epoch 1295/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3557 - acc: 0.4643 - val_loss: 2.2692 - val_acc: 0.2433\n",
      "Epoch 1296/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3568 - acc: 0.4643 - val_loss: 2.2749 - val_acc: 0.2433\n",
      "Epoch 1297/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3560 - acc: 0.4700 - val_loss: 2.2689 - val_acc: 0.2433\n",
      "Epoch 1298/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3566 - acc: 0.4657 - val_loss: 2.2702 - val_acc: 0.2400\n",
      "Epoch 1299/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3552 - acc: 0.4671 - val_loss: 2.2847 - val_acc: 0.2400\n",
      "Epoch 1300/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3547 - acc: 0.4643 - val_loss: 2.2666 - val_acc: 0.2333\n",
      "Epoch 1301/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3543 - acc: 0.4557 - val_loss: 2.2612 - val_acc: 0.2433\n",
      "Epoch 1302/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3560 - acc: 0.4657 - val_loss: 2.2762 - val_acc: 0.2467\n",
      "Epoch 1303/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3559 - acc: 0.4643 - val_loss: 2.2775 - val_acc: 0.2433\n",
      "Epoch 1304/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3557 - acc: 0.4700 - val_loss: 2.2815 - val_acc: 0.2433\n",
      "Epoch 1305/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3548 - acc: 0.4643 - val_loss: 2.2850 - val_acc: 0.2500\n",
      "Epoch 1306/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3550 - acc: 0.4600 - val_loss: 2.2742 - val_acc: 0.2467\n",
      "Epoch 1307/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3555 - acc: 0.4643 - val_loss: 2.2712 - val_acc: 0.2433\n",
      "Epoch 1308/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3541 - acc: 0.4614 - val_loss: 2.2638 - val_acc: 0.2433\n",
      "Epoch 1309/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3539 - acc: 0.4629 - val_loss: 2.2766 - val_acc: 0.2300\n",
      "Epoch 1310/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3550 - acc: 0.4629 - val_loss: 2.2825 - val_acc: 0.2467\n",
      "Epoch 1311/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 95us/step - loss: 1.3556 - acc: 0.4671 - val_loss: 2.2779 - val_acc: 0.2433\n",
      "Epoch 1312/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3546 - acc: 0.4629 - val_loss: 2.2745 - val_acc: 0.2467\n",
      "Epoch 1313/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3543 - acc: 0.4614 - val_loss: 2.2674 - val_acc: 0.2400\n",
      "Epoch 1314/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3541 - acc: 0.4557 - val_loss: 2.2843 - val_acc: 0.2400\n",
      "Epoch 1315/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.3535 - acc: 0.4671 - val_loss: 2.2683 - val_acc: 0.2433\n",
      "Epoch 1316/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3546 - acc: 0.4643 - val_loss: 2.2887 - val_acc: 0.2500\n",
      "Epoch 1317/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3538 - acc: 0.4614 - val_loss: 2.2732 - val_acc: 0.2300\n",
      "Epoch 1318/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3547 - acc: 0.4657 - val_loss: 2.2650 - val_acc: 0.2433\n",
      "Epoch 1319/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3546 - acc: 0.4686 - val_loss: 2.2882 - val_acc: 0.2533\n",
      "Epoch 1320/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3540 - acc: 0.4600 - val_loss: 2.2718 - val_acc: 0.2433\n",
      "Epoch 1321/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3535 - acc: 0.4643 - val_loss: 2.2747 - val_acc: 0.2467\n",
      "Epoch 1322/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.3536 - acc: 0.4629 - val_loss: 2.2668 - val_acc: 0.2400\n",
      "Epoch 1323/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3532 - acc: 0.4629 - val_loss: 2.3081 - val_acc: 0.2467\n",
      "Epoch 1324/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3538 - acc: 0.4643 - val_loss: 2.2783 - val_acc: 0.2400\n",
      "Epoch 1325/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3524 - acc: 0.4657 - val_loss: 2.2934 - val_acc: 0.2367\n",
      "Epoch 1326/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3540 - acc: 0.4671 - val_loss: 2.2791 - val_acc: 0.2433\n",
      "Epoch 1327/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3531 - acc: 0.4643 - val_loss: 2.2746 - val_acc: 0.2400\n",
      "Epoch 1328/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3530 - acc: 0.4657 - val_loss: 2.3043 - val_acc: 0.2467\n",
      "Epoch 1329/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3531 - acc: 0.4657 - val_loss: 2.2821 - val_acc: 0.2500\n",
      "Epoch 1330/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3533 - acc: 0.4600 - val_loss: 2.2987 - val_acc: 0.2400\n",
      "Epoch 1331/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3534 - acc: 0.4643 - val_loss: 2.2872 - val_acc: 0.2500\n",
      "Epoch 1332/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3527 - acc: 0.4671 - val_loss: 2.2893 - val_acc: 0.2433\n",
      "Epoch 1333/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3523 - acc: 0.4671 - val_loss: 2.2753 - val_acc: 0.2433\n",
      "Epoch 1334/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3520 - acc: 0.4657 - val_loss: 2.3006 - val_acc: 0.2500\n",
      "Epoch 1335/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3531 - acc: 0.4586 - val_loss: 2.2703 - val_acc: 0.2400\n",
      "Epoch 1336/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3532 - acc: 0.4714 - val_loss: 2.2912 - val_acc: 0.2433\n",
      "Epoch 1337/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3526 - acc: 0.4600 - val_loss: 2.2798 - val_acc: 0.2433\n",
      "Epoch 1338/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3521 - acc: 0.4629 - val_loss: 2.2798 - val_acc: 0.2400\n",
      "Epoch 1339/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3521 - acc: 0.4657 - val_loss: 2.3092 - val_acc: 0.2467\n",
      "Epoch 1340/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3526 - acc: 0.4643 - val_loss: 2.2758 - val_acc: 0.2433\n",
      "Epoch 1341/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3522 - acc: 0.4729 - val_loss: 2.2847 - val_acc: 0.2467\n",
      "Epoch 1342/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.3403 - acc: 0.459 - 0s 100us/step - loss: 1.3523 - acc: 0.4686 - val_loss: 2.2835 - val_acc: 0.2433\n",
      "Epoch 1343/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3514 - acc: 0.4643 - val_loss: 2.2876 - val_acc: 0.2433\n",
      "Epoch 1344/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3518 - acc: 0.4600 - val_loss: 2.2903 - val_acc: 0.2500\n",
      "Epoch 1345/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3513 - acc: 0.4729 - val_loss: 2.3015 - val_acc: 0.2500\n",
      "Epoch 1346/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3514 - acc: 0.4614 - val_loss: 2.2687 - val_acc: 0.2400\n",
      "Epoch 1347/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3521 - acc: 0.4700 - val_loss: 2.2881 - val_acc: 0.2467\n",
      "Epoch 1348/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3505 - acc: 0.4671 - val_loss: 2.2758 - val_acc: 0.2500\n",
      "Epoch 1349/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3510 - acc: 0.4643 - val_loss: 2.2881 - val_acc: 0.2467\n",
      "Epoch 1350/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3515 - acc: 0.4643 - val_loss: 2.2928 - val_acc: 0.2400\n",
      "Epoch 1351/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3514 - acc: 0.4671 - val_loss: 2.2934 - val_acc: 0.2467\n",
      "Epoch 1352/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3512 - acc: 0.4686 - val_loss: 2.2734 - val_acc: 0.2433\n",
      "Epoch 1353/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3507 - acc: 0.4686 - val_loss: 2.2759 - val_acc: 0.2367\n",
      "Epoch 1354/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3511 - acc: 0.4657 - val_loss: 2.2744 - val_acc: 0.2367\n",
      "Epoch 1355/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3502 - acc: 0.4700 - val_loss: 2.3052 - val_acc: 0.2433\n",
      "Epoch 1356/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3515 - acc: 0.4657 - val_loss: 2.2884 - val_acc: 0.2400\n",
      "Epoch 1357/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3514 - acc: 0.4700 - val_loss: 2.2975 - val_acc: 0.2433\n",
      "Epoch 1358/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3507 - acc: 0.4614 - val_loss: 2.2824 - val_acc: 0.2500\n",
      "Epoch 1359/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3499 - acc: 0.4686 - val_loss: 2.2905 - val_acc: 0.2400\n",
      "Epoch 1360/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.3505 - acc: 0.4671 - val_loss: 2.2754 - val_acc: 0.2467\n",
      "Epoch 1361/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3509 - acc: 0.4657 - val_loss: 2.2970 - val_acc: 0.2467\n",
      "Epoch 1362/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3499 - acc: 0.4629 - val_loss: 2.2768 - val_acc: 0.2467\n",
      "Epoch 1363/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3503 - acc: 0.4700 - val_loss: 2.2848 - val_acc: 0.2433\n",
      "Epoch 1364/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3499 - acc: 0.4614 - val_loss: 2.2972 - val_acc: 0.2467\n",
      "Epoch 1365/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3504 - acc: 0.4714 - val_loss: 2.2741 - val_acc: 0.2400\n",
      "Epoch 1366/3000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.3500 - acc: 0.4657 - val_loss: 2.2881 - val_acc: 0.2433\n",
      "Epoch 1367/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3497 - acc: 0.4757 - val_loss: 2.2777 - val_acc: 0.2433\n",
      "Epoch 1368/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3505 - acc: 0.4671 - val_loss: 2.2966 - val_acc: 0.2433\n",
      "Epoch 1369/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3505 - acc: 0.4700 - val_loss: 2.3069 - val_acc: 0.2467\n",
      "Epoch 1370/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 100us/step - loss: 1.3492 - acc: 0.4657 - val_loss: 2.3077 - val_acc: 0.2467\n",
      "Epoch 1371/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3502 - acc: 0.4714 - val_loss: 2.2957 - val_acc: 0.2400\n",
      "Epoch 1372/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3496 - acc: 0.4671 - val_loss: 2.2967 - val_acc: 0.2400\n",
      "Epoch 1373/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3493 - acc: 0.4714 - val_loss: 2.2989 - val_acc: 0.2533\n",
      "Epoch 1374/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3495 - acc: 0.4643 - val_loss: 2.3007 - val_acc: 0.2500\n",
      "Epoch 1375/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3496 - acc: 0.4743 - val_loss: 2.2859 - val_acc: 0.2433\n",
      "Epoch 1376/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.3490 - acc: 0.4700 - val_loss: 2.2878 - val_acc: 0.2500\n",
      "Epoch 1377/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3495 - acc: 0.4671 - val_loss: 2.2878 - val_acc: 0.2433\n",
      "Epoch 1378/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3490 - acc: 0.4700 - val_loss: 2.3026 - val_acc: 0.2467\n",
      "Epoch 1379/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3488 - acc: 0.4629 - val_loss: 2.3071 - val_acc: 0.2433\n",
      "Epoch 1380/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3481 - acc: 0.4671 - val_loss: 2.2887 - val_acc: 0.2433\n",
      "Epoch 1381/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3485 - acc: 0.4700 - val_loss: 2.3011 - val_acc: 0.2467\n",
      "Epoch 1382/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3471 - acc: 0.4714 - val_loss: 2.3073 - val_acc: 0.2467\n",
      "Epoch 1383/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3481 - acc: 0.4657 - val_loss: 2.3010 - val_acc: 0.2433\n",
      "Epoch 1384/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3485 - acc: 0.4700 - val_loss: 2.2920 - val_acc: 0.2433\n",
      "Epoch 1385/3000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 1.3476 - acc: 0.4729 - val_loss: 2.2999 - val_acc: 0.2467\n",
      "Epoch 1386/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.3478 - acc: 0.4614 - val_loss: 2.3018 - val_acc: 0.2300\n",
      "Epoch 1387/3000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.3478 - acc: 0.4686 - val_loss: 2.3055 - val_acc: 0.2300\n",
      "Epoch 1388/3000\n",
      "700/700 [==============================] - 0s 176us/step - loss: 1.3480 - acc: 0.4657 - val_loss: 2.3040 - val_acc: 0.2400\n",
      "Epoch 1389/3000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.3472 - acc: 0.4671 - val_loss: 2.3077 - val_acc: 0.2467\n",
      "Epoch 1390/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3484 - acc: 0.4643 - val_loss: 2.2834 - val_acc: 0.2400\n",
      "Epoch 1391/3000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.3483 - acc: 0.4700 - val_loss: 2.3013 - val_acc: 0.2467\n",
      "Epoch 1392/3000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 1.3486 - acc: 0.4657 - val_loss: 2.3069 - val_acc: 0.2400\n",
      "Epoch 1393/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3475 - acc: 0.4686 - val_loss: 2.3099 - val_acc: 0.2467\n",
      "Epoch 1394/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3463 - acc: 0.4614 - val_loss: 2.3007 - val_acc: 0.2267\n",
      "Epoch 1395/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3472 - acc: 0.4657 - val_loss: 2.3000 - val_acc: 0.2267\n",
      "Epoch 1396/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3485 - acc: 0.4671 - val_loss: 2.2897 - val_acc: 0.2500\n",
      "Epoch 1397/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3466 - acc: 0.4686 - val_loss: 2.2984 - val_acc: 0.2467\n",
      "Epoch 1398/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3472 - acc: 0.4614 - val_loss: 2.3152 - val_acc: 0.2500\n",
      "Epoch 1399/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3465 - acc: 0.4729 - val_loss: 2.3284 - val_acc: 0.2500\n",
      "Epoch 1400/3000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.3464 - acc: 0.4643 - val_loss: 2.3322 - val_acc: 0.2467\n",
      "Epoch 1401/3000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.3470 - acc: 0.4729 - val_loss: 2.3059 - val_acc: 0.2533\n",
      "Epoch 1402/3000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 1.3465 - acc: 0.4743 - val_loss: 2.2985 - val_acc: 0.2433\n",
      "Epoch 1403/3000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.3447 - acc: 0.4671 - val_loss: 2.2952 - val_acc: 0.2467\n",
      "Epoch 1404/3000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.3471 - acc: 0.4586 - val_loss: 2.3120 - val_acc: 0.2467\n",
      "Epoch 1405/3000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 1.3464 - acc: 0.4657 - val_loss: 2.3043 - val_acc: 0.2433\n",
      "Epoch 1406/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3468 - acc: 0.4657 - val_loss: 2.2928 - val_acc: 0.2400\n",
      "Epoch 1407/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3464 - acc: 0.4700 - val_loss: 2.2998 - val_acc: 0.2433\n",
      "Epoch 1408/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3459 - acc: 0.4686 - val_loss: 2.2961 - val_acc: 0.2500\n",
      "Epoch 1409/3000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 1.3456 - acc: 0.4686 - val_loss: 2.2880 - val_acc: 0.2467\n",
      "Epoch 1410/3000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 1.3465 - acc: 0.4657 - val_loss: 2.3045 - val_acc: 0.2467\n",
      "Epoch 1411/3000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.3455 - acc: 0.4671 - val_loss: 2.3293 - val_acc: 0.2467\n",
      "Epoch 1412/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3467 - acc: 0.4686 - val_loss: 2.2967 - val_acc: 0.2467\n",
      "Epoch 1413/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3460 - acc: 0.4629 - val_loss: 2.3183 - val_acc: 0.2400\n",
      "Epoch 1414/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3468 - acc: 0.4686 - val_loss: 2.2909 - val_acc: 0.2467\n",
      "Epoch 1415/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3458 - acc: 0.4743 - val_loss: 2.3056 - val_acc: 0.2500\n",
      "Epoch 1416/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3456 - acc: 0.4671 - val_loss: 2.3044 - val_acc: 0.2500\n",
      "Epoch 1417/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3462 - acc: 0.4714 - val_loss: 2.3003 - val_acc: 0.2500\n",
      "Epoch 1418/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3449 - acc: 0.4657 - val_loss: 2.2972 - val_acc: 0.2467\n",
      "Epoch 1419/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3457 - acc: 0.4686 - val_loss: 2.2807 - val_acc: 0.2433\n",
      "Epoch 1420/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3456 - acc: 0.4700 - val_loss: 2.3200 - val_acc: 0.2433\n",
      "Epoch 1421/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3456 - acc: 0.4643 - val_loss: 2.3068 - val_acc: 0.2433\n",
      "Epoch 1422/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3438 - acc: 0.4686 - val_loss: 2.3002 - val_acc: 0.2467\n",
      "Epoch 1423/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3448 - acc: 0.4657 - val_loss: 2.3053 - val_acc: 0.2400\n",
      "Epoch 1424/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3455 - acc: 0.4643 - val_loss: 2.3072 - val_acc: 0.2433\n",
      "Epoch 1425/3000\n",
      "700/700 [==============================] - 0s 166us/step - loss: 1.3439 - acc: 0.4629 - val_loss: 2.3094 - val_acc: 0.2333\n",
      "Epoch 1426/3000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 1.3446 - acc: 0.4714 - val_loss: 2.3117 - val_acc: 0.2467\n",
      "Epoch 1427/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.3488 - acc: 0.456 - 0s 110us/step - loss: 1.3442 - acc: 0.4700 - val_loss: 2.3131 - val_acc: 0.2500\n",
      "Epoch 1428/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3445 - acc: 0.4757 - val_loss: 2.3037 - val_acc: 0.2467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1429/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3445 - acc: 0.4657 - val_loss: 2.2874 - val_acc: 0.2433\n",
      "Epoch 1430/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3445 - acc: 0.4671 - val_loss: 2.3203 - val_acc: 0.2467\n",
      "Epoch 1431/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3437 - acc: 0.4786 - val_loss: 2.2901 - val_acc: 0.2367\n",
      "Epoch 1432/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.3445 - acc: 0.4714 - val_loss: 2.3161 - val_acc: 0.2433\n",
      "Epoch 1433/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3450 - acc: 0.4686 - val_loss: 2.3078 - val_acc: 0.2467\n",
      "Epoch 1434/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3447 - acc: 0.4671 - val_loss: 2.2994 - val_acc: 0.2467\n",
      "Epoch 1435/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3448 - acc: 0.4657 - val_loss: 2.3083 - val_acc: 0.2467\n",
      "Epoch 1436/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.3424 - acc: 0.4643 - val_loss: 2.3186 - val_acc: 0.2467\n",
      "Epoch 1437/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3444 - acc: 0.4729 - val_loss: 2.3111 - val_acc: 0.2467\n",
      "Epoch 1438/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3443 - acc: 0.4643 - val_loss: 2.2996 - val_acc: 0.2433\n",
      "Epoch 1439/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3440 - acc: 0.4729 - val_loss: 2.2987 - val_acc: 0.2500\n",
      "Epoch 1440/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3441 - acc: 0.4714 - val_loss: 2.3065 - val_acc: 0.2433\n",
      "Epoch 1441/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3437 - acc: 0.4743 - val_loss: 2.3049 - val_acc: 0.2400\n",
      "Epoch 1442/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3440 - acc: 0.4729 - val_loss: 2.3169 - val_acc: 0.2433\n",
      "Epoch 1443/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3434 - acc: 0.4700 - val_loss: 2.3123 - val_acc: 0.2467\n",
      "Epoch 1444/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3437 - acc: 0.4714 - val_loss: 2.3054 - val_acc: 0.2500\n",
      "Epoch 1445/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3426 - acc: 0.4614 - val_loss: 2.3060 - val_acc: 0.2367\n",
      "Epoch 1446/3000\n",
      "700/700 [==============================] - 0s 179us/step - loss: 1.3431 - acc: 0.4714 - val_loss: 2.3238 - val_acc: 0.2500\n",
      "Epoch 1447/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.3437 - acc: 0.4643 - val_loss: 2.3112 - val_acc: 0.2433\n",
      "Epoch 1448/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3422 - acc: 0.4686 - val_loss: 2.3105 - val_acc: 0.2367\n",
      "Epoch 1449/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3428 - acc: 0.4657 - val_loss: 2.2990 - val_acc: 0.2500\n",
      "Epoch 1450/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3431 - acc: 0.4800 - val_loss: 2.2937 - val_acc: 0.2433\n",
      "Epoch 1451/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3425 - acc: 0.4729 - val_loss: 2.3167 - val_acc: 0.2500\n",
      "Epoch 1452/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3428 - acc: 0.4657 - val_loss: 2.3064 - val_acc: 0.2433\n",
      "Epoch 1453/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3424 - acc: 0.4657 - val_loss: 2.3061 - val_acc: 0.2433\n",
      "Epoch 1454/3000\n",
      "700/700 [==============================] - 0s 180us/step - loss: 1.3430 - acc: 0.4714 - val_loss: 2.3040 - val_acc: 0.2433\n",
      "Epoch 1455/3000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.3426 - acc: 0.4743 - val_loss: 2.3204 - val_acc: 0.2467\n",
      "Epoch 1456/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3431 - acc: 0.4771 - val_loss: 2.3073 - val_acc: 0.2400\n",
      "Epoch 1457/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3425 - acc: 0.4643 - val_loss: 2.3224 - val_acc: 0.2500\n",
      "Epoch 1458/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3428 - acc: 0.4629 - val_loss: 2.3163 - val_acc: 0.2400\n",
      "Epoch 1459/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3423 - acc: 0.4686 - val_loss: 2.3066 - val_acc: 0.2500\n",
      "Epoch 1460/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3415 - acc: 0.4729 - val_loss: 2.3127 - val_acc: 0.2367\n",
      "Epoch 1461/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3414 - acc: 0.4671 - val_loss: 2.3018 - val_acc: 0.2500\n",
      "Epoch 1462/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3419 - acc: 0.4714 - val_loss: 2.3348 - val_acc: 0.2433\n",
      "Epoch 1463/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3423 - acc: 0.4643 - val_loss: 2.3288 - val_acc: 0.2467\n",
      "Epoch 1464/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3418 - acc: 0.4629 - val_loss: 2.3181 - val_acc: 0.2467\n",
      "Epoch 1465/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3420 - acc: 0.4686 - val_loss: 2.3266 - val_acc: 0.2433\n",
      "Epoch 1466/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3418 - acc: 0.4686 - val_loss: 2.3064 - val_acc: 0.2433\n",
      "Epoch 1467/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.3394 - acc: 0.4743 - val_loss: 2.3133 - val_acc: 0.2433\n",
      "Epoch 1468/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3429 - acc: 0.4729 - val_loss: 2.3181 - val_acc: 0.2467\n",
      "Epoch 1469/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.3422 - acc: 0.4700 - val_loss: 2.3217 - val_acc: 0.2467\n",
      "Epoch 1470/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.3412 - acc: 0.4757 - val_loss: 2.3182 - val_acc: 0.2500\n",
      "Epoch 1471/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3403 - acc: 0.4714 - val_loss: 2.3238 - val_acc: 0.2500\n",
      "Epoch 1472/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3416 - acc: 0.4657 - val_loss: 2.3151 - val_acc: 0.2400\n",
      "Epoch 1473/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.3407 - acc: 0.4700 - val_loss: 2.3059 - val_acc: 0.2467\n",
      "Epoch 1474/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3404 - acc: 0.4729 - val_loss: 2.3154 - val_acc: 0.2500\n",
      "Epoch 1475/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3403 - acc: 0.4700 - val_loss: 2.3264 - val_acc: 0.2467\n",
      "Epoch 1476/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3412 - acc: 0.4686 - val_loss: 2.3172 - val_acc: 0.2433\n",
      "Epoch 1477/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3409 - acc: 0.4657 - val_loss: 2.3222 - val_acc: 0.2400\n",
      "Epoch 1478/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3402 - acc: 0.4729 - val_loss: 2.3011 - val_acc: 0.2500\n",
      "Epoch 1479/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3402 - acc: 0.4586 - val_loss: 2.3122 - val_acc: 0.2433\n",
      "Epoch 1480/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3409 - acc: 0.4714 - val_loss: 2.3194 - val_acc: 0.2400\n",
      "Epoch 1481/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3400 - acc: 0.4686 - val_loss: 2.3191 - val_acc: 0.2367\n",
      "Epoch 1482/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3401 - acc: 0.4714 - val_loss: 2.3387 - val_acc: 0.2467\n",
      "Epoch 1483/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3409 - acc: 0.4714 - val_loss: 2.3237 - val_acc: 0.2433\n",
      "Epoch 1484/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3398 - acc: 0.4686 - val_loss: 2.3145 - val_acc: 0.2367\n",
      "Epoch 1485/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3397 - acc: 0.4657 - val_loss: 2.3305 - val_acc: 0.2267\n",
      "Epoch 1486/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3401 - acc: 0.4700 - val_loss: 2.3169 - val_acc: 0.2500\n",
      "Epoch 1487/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3396 - acc: 0.4657 - val_loss: 2.3281 - val_acc: 0.2433\n",
      "Epoch 1488/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3395 - acc: 0.4600 - val_loss: 2.3046 - val_acc: 0.2400\n",
      "Epoch 1489/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3398 - acc: 0.4657 - val_loss: 2.3338 - val_acc: 0.2400\n",
      "Epoch 1490/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3389 - acc: 0.4671 - val_loss: 2.3389 - val_acc: 0.2467\n",
      "Epoch 1491/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3395 - acc: 0.4714 - val_loss: 2.3334 - val_acc: 0.2433\n",
      "Epoch 1492/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.3378 - acc: 0.4714 - val_loss: 2.3276 - val_acc: 0.2400\n",
      "Epoch 1493/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3413 - acc: 0.4643 - val_loss: 2.3192 - val_acc: 0.2500\n",
      "Epoch 1494/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3398 - acc: 0.4757 - val_loss: 2.3200 - val_acc: 0.2500\n",
      "Epoch 1495/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3383 - acc: 0.4700 - val_loss: 2.3188 - val_acc: 0.2433\n",
      "Epoch 1496/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.3393 - acc: 0.4714 - val_loss: 2.3180 - val_acc: 0.2467\n",
      "Epoch 1497/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3384 - acc: 0.4657 - val_loss: 2.3287 - val_acc: 0.2433\n",
      "Epoch 1498/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3389 - acc: 0.4729 - val_loss: 2.3437 - val_acc: 0.2467\n",
      "Epoch 1499/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3395 - acc: 0.4686 - val_loss: 2.3220 - val_acc: 0.2500\n",
      "Epoch 1500/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3389 - acc: 0.4743 - val_loss: 2.3187 - val_acc: 0.2433\n",
      "Epoch 1501/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3389 - acc: 0.4743 - val_loss: 2.3222 - val_acc: 0.2467\n",
      "Epoch 1502/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3389 - acc: 0.4729 - val_loss: 2.3424 - val_acc: 0.2467\n",
      "Epoch 1503/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3392 - acc: 0.4657 - val_loss: 2.3231 - val_acc: 0.2433\n",
      "Epoch 1504/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3382 - acc: 0.4714 - val_loss: 2.3310 - val_acc: 0.2467\n",
      "Epoch 1505/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3385 - acc: 0.4700 - val_loss: 2.3257 - val_acc: 0.2400\n",
      "Epoch 1506/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3390 - acc: 0.4786 - val_loss: 2.3184 - val_acc: 0.2433\n",
      "Epoch 1507/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3383 - acc: 0.4714 - val_loss: 2.3234 - val_acc: 0.2367\n",
      "Epoch 1508/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3383 - acc: 0.4643 - val_loss: 2.3402 - val_acc: 0.2467\n",
      "Epoch 1509/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3384 - acc: 0.4757 - val_loss: 2.3216 - val_acc: 0.2433\n",
      "Epoch 1510/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3384 - acc: 0.4757 - val_loss: 2.3471 - val_acc: 0.2467\n",
      "Epoch 1511/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3380 - acc: 0.4771 - val_loss: 2.3530 - val_acc: 0.2500\n",
      "Epoch 1512/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3371 - acc: 0.4714 - val_loss: 2.3158 - val_acc: 0.2400\n",
      "Epoch 1513/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3384 - acc: 0.4686 - val_loss: 2.3097 - val_acc: 0.2433\n",
      "Epoch 1514/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3382 - acc: 0.4686 - val_loss: 2.3187 - val_acc: 0.2433\n",
      "Epoch 1515/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3376 - acc: 0.4729 - val_loss: 2.3476 - val_acc: 0.2500\n",
      "Epoch 1516/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3395 - acc: 0.4729 - val_loss: 2.3370 - val_acc: 0.2433\n",
      "Epoch 1517/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3372 - acc: 0.4771 - val_loss: 2.3192 - val_acc: 0.2467\n",
      "Epoch 1518/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3372 - acc: 0.4743 - val_loss: 2.3129 - val_acc: 0.2533\n",
      "Epoch 1519/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3371 - acc: 0.4757 - val_loss: 2.3158 - val_acc: 0.2367\n",
      "Epoch 1520/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3375 - acc: 0.4700 - val_loss: 2.3375 - val_acc: 0.2467\n",
      "Epoch 1521/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3368 - acc: 0.4786 - val_loss: 2.3144 - val_acc: 0.2433\n",
      "Epoch 1522/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3378 - acc: 0.4714 - val_loss: 2.3243 - val_acc: 0.2467\n",
      "Epoch 1523/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3371 - acc: 0.4714 - val_loss: 2.3200 - val_acc: 0.2467\n",
      "Epoch 1524/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3376 - acc: 0.4714 - val_loss: 2.3307 - val_acc: 0.2400\n",
      "Epoch 1525/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3369 - acc: 0.4743 - val_loss: 2.3324 - val_acc: 0.2433\n",
      "Epoch 1526/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3369 - acc: 0.4743 - val_loss: 2.3498 - val_acc: 0.2467\n",
      "Epoch 1527/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3352 - acc: 0.4700 - val_loss: 2.3246 - val_acc: 0.2333\n",
      "Epoch 1528/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.3372 - acc: 0.4786 - val_loss: 2.3250 - val_acc: 0.2433\n",
      "Epoch 1529/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3376 - acc: 0.4657 - val_loss: 2.3329 - val_acc: 0.2433\n",
      "Epoch 1530/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3369 - acc: 0.4643 - val_loss: 2.3267 - val_acc: 0.2433\n",
      "Epoch 1531/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3365 - acc: 0.4729 - val_loss: 2.3328 - val_acc: 0.2400\n",
      "Epoch 1532/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3364 - acc: 0.4786 - val_loss: 2.3120 - val_acc: 0.2500\n",
      "Epoch 1533/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3365 - acc: 0.4757 - val_loss: 2.3310 - val_acc: 0.2400\n",
      "Epoch 1534/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3371 - acc: 0.4700 - val_loss: 2.3172 - val_acc: 0.2500\n",
      "Epoch 1535/3000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.3369 - acc: 0.4757 - val_loss: 2.3401 - val_acc: 0.2467\n",
      "Epoch 1536/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3361 - acc: 0.4743 - val_loss: 2.3286 - val_acc: 0.2400\n",
      "Epoch 1537/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3359 - acc: 0.4757 - val_loss: 2.3318 - val_acc: 0.2467\n",
      "Epoch 1538/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3354 - acc: 0.4743 - val_loss: 2.3206 - val_acc: 0.2433\n",
      "Epoch 1539/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3355 - acc: 0.4671 - val_loss: 2.3119 - val_acc: 0.2500\n",
      "Epoch 1540/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.3358 - acc: 0.4743 - val_loss: 2.3155 - val_acc: 0.2500\n",
      "Epoch 1541/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3362 - acc: 0.4714 - val_loss: 2.3320 - val_acc: 0.2433\n",
      "Epoch 1542/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3358 - acc: 0.4729 - val_loss: 2.3309 - val_acc: 0.2367\n",
      "Epoch 1543/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3358 - acc: 0.4757 - val_loss: 2.3256 - val_acc: 0.2433\n",
      "Epoch 1544/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3362 - acc: 0.4800 - val_loss: 2.3315 - val_acc: 0.2467\n",
      "Epoch 1545/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3351 - acc: 0.4700 - val_loss: 2.3209 - val_acc: 0.2433\n",
      "Epoch 1546/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3358 - acc: 0.4843 - val_loss: 2.3399 - val_acc: 0.2433\n",
      "Epoch 1547/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 119us/step - loss: 1.3356 - acc: 0.4700 - val_loss: 2.3444 - val_acc: 0.2433\n",
      "Epoch 1548/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3361 - acc: 0.4714 - val_loss: 2.3357 - val_acc: 0.2500\n",
      "Epoch 1549/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3343 - acc: 0.4714 - val_loss: 2.3483 - val_acc: 0.2467\n",
      "Epoch 1550/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3355 - acc: 0.4743 - val_loss: 2.3514 - val_acc: 0.2433\n",
      "Epoch 1551/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3352 - acc: 0.4757 - val_loss: 2.3259 - val_acc: 0.2333\n",
      "Epoch 1552/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3347 - acc: 0.4714 - val_loss: 2.3443 - val_acc: 0.2500\n",
      "Epoch 1553/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3344 - acc: 0.4743 - val_loss: 2.3335 - val_acc: 0.2367\n",
      "Epoch 1554/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3353 - acc: 0.4700 - val_loss: 2.3340 - val_acc: 0.2367\n",
      "Epoch 1555/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3350 - acc: 0.4700 - val_loss: 2.3363 - val_acc: 0.2400\n",
      "Epoch 1556/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3341 - acc: 0.4714 - val_loss: 2.3308 - val_acc: 0.2467\n",
      "Epoch 1557/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3342 - acc: 0.4757 - val_loss: 2.3344 - val_acc: 0.2433\n",
      "Epoch 1558/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3343 - acc: 0.4743 - val_loss: 2.3134 - val_acc: 0.2533\n",
      "Epoch 1559/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3344 - acc: 0.4771 - val_loss: 2.3448 - val_acc: 0.2500\n",
      "Epoch 1560/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3348 - acc: 0.4729 - val_loss: 2.3315 - val_acc: 0.2433\n",
      "Epoch 1561/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3336 - acc: 0.4700 - val_loss: 2.3412 - val_acc: 0.2467\n",
      "Epoch 1562/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3347 - acc: 0.4657 - val_loss: 2.3618 - val_acc: 0.2467\n",
      "Epoch 1563/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3350 - acc: 0.4729 - val_loss: 2.3389 - val_acc: 0.2433\n",
      "Epoch 1564/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3329 - acc: 0.4743 - val_loss: 2.3328 - val_acc: 0.2400\n",
      "Epoch 1565/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3349 - acc: 0.4757 - val_loss: 2.3333 - val_acc: 0.2467\n",
      "Epoch 1566/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3337 - acc: 0.4771 - val_loss: 2.3316 - val_acc: 0.2367\n",
      "Epoch 1567/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3342 - acc: 0.4743 - val_loss: 2.3388 - val_acc: 0.2433\n",
      "Epoch 1568/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3337 - acc: 0.4700 - val_loss: 2.3336 - val_acc: 0.2433\n",
      "Epoch 1569/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3343 - acc: 0.4786 - val_loss: 2.3558 - val_acc: 0.2467\n",
      "Epoch 1570/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3329 - acc: 0.4814 - val_loss: 2.3600 - val_acc: 0.2433\n",
      "Epoch 1571/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3349 - acc: 0.4729 - val_loss: 2.3445 - val_acc: 0.2433\n",
      "Epoch 1572/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3336 - acc: 0.4786 - val_loss: 2.3269 - val_acc: 0.2400\n",
      "Epoch 1573/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3334 - acc: 0.4743 - val_loss: 2.3653 - val_acc: 0.2400\n",
      "Epoch 1574/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3338 - acc: 0.4714 - val_loss: 2.3434 - val_acc: 0.2433\n",
      "Epoch 1575/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3331 - acc: 0.4729 - val_loss: 2.3339 - val_acc: 0.2467\n",
      "Epoch 1576/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3331 - acc: 0.4700 - val_loss: 2.3542 - val_acc: 0.2467\n",
      "Epoch 1577/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3339 - acc: 0.4686 - val_loss: 2.3343 - val_acc: 0.2400\n",
      "Epoch 1578/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3321 - acc: 0.4786 - val_loss: 2.3409 - val_acc: 0.2467\n",
      "Epoch 1579/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3332 - acc: 0.4714 - val_loss: 2.3401 - val_acc: 0.2467\n",
      "Epoch 1580/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3321 - acc: 0.4800 - val_loss: 2.3483 - val_acc: 0.2467\n",
      "Epoch 1581/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3333 - acc: 0.4657 - val_loss: 2.3517 - val_acc: 0.2433\n",
      "Epoch 1582/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3333 - acc: 0.4771 - val_loss: 2.3338 - val_acc: 0.2433\n",
      "Epoch 1583/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3319 - acc: 0.4714 - val_loss: 2.3412 - val_acc: 0.2433\n",
      "Epoch 1584/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3334 - acc: 0.4743 - val_loss: 2.3555 - val_acc: 0.2433\n",
      "Epoch 1585/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3331 - acc: 0.4714 - val_loss: 2.3413 - val_acc: 0.2467\n",
      "Epoch 1586/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3316 - acc: 0.4714 - val_loss: 2.3538 - val_acc: 0.2367\n",
      "Epoch 1587/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3321 - acc: 0.4729 - val_loss: 2.3580 - val_acc: 0.2467\n",
      "Epoch 1588/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3321 - acc: 0.4829 - val_loss: 2.3275 - val_acc: 0.2500\n",
      "Epoch 1589/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3323 - acc: 0.4771 - val_loss: 2.3539 - val_acc: 0.2400\n",
      "Epoch 1590/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3318 - acc: 0.4729 - val_loss: 2.3314 - val_acc: 0.2500\n",
      "Epoch 1591/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.3324 - acc: 0.4800 - val_loss: 2.3398 - val_acc: 0.2467\n",
      "Epoch 1592/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3321 - acc: 0.4729 - val_loss: 2.3499 - val_acc: 0.2467\n",
      "Epoch 1593/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3310 - acc: 0.4700 - val_loss: 2.3598 - val_acc: 0.2400\n",
      "Epoch 1594/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3322 - acc: 0.4729 - val_loss: 2.3478 - val_acc: 0.2433\n",
      "Epoch 1595/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3311 - acc: 0.4757 - val_loss: 2.3475 - val_acc: 0.2467\n",
      "Epoch 1596/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3317 - acc: 0.4743 - val_loss: 2.3393 - val_acc: 0.2500\n",
      "Epoch 1597/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3315 - acc: 0.4714 - val_loss: 2.3406 - val_acc: 0.2433\n",
      "Epoch 1598/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3322 - acc: 0.4771 - val_loss: 2.3447 - val_acc: 0.2400\n",
      "Epoch 1599/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3313 - acc: 0.4714 - val_loss: 2.3426 - val_acc: 0.2367\n",
      "Epoch 1600/3000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.3314 - acc: 0.4743 - val_loss: 2.3523 - val_acc: 0.2333\n",
      "Epoch 1601/3000\n",
      "700/700 [==============================] - 0s 202us/step - loss: 1.3319 - acc: 0.4800 - val_loss: 2.3359 - val_acc: 0.2500\n",
      "Epoch 1602/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3309 - acc: 0.4743 - val_loss: 2.3588 - val_acc: 0.2467\n",
      "Epoch 1603/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3314 - acc: 0.4714 - val_loss: 2.3567 - val_acc: 0.2500\n",
      "Epoch 1604/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3309 - acc: 0.4714 - val_loss: 2.3519 - val_acc: 0.2467\n",
      "Epoch 1605/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3312 - acc: 0.4800 - val_loss: 2.3654 - val_acc: 0.2467\n",
      "Epoch 1606/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3310 - acc: 0.4757 - val_loss: 2.3402 - val_acc: 0.2333\n",
      "Epoch 1607/3000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.3320 - acc: 0.4771 - val_loss: 2.3414 - val_acc: 0.2400\n",
      "Epoch 1608/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.3291 - acc: 0.4771 - val_loss: 2.3511 - val_acc: 0.2433\n",
      "Epoch 1609/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3311 - acc: 0.4786 - val_loss: 2.3724 - val_acc: 0.2500\n",
      "Epoch 1610/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3314 - acc: 0.4714 - val_loss: 2.3456 - val_acc: 0.2433\n",
      "Epoch 1611/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3301 - acc: 0.4757 - val_loss: 2.3638 - val_acc: 0.2433\n",
      "Epoch 1612/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3307 - acc: 0.4729 - val_loss: 2.3522 - val_acc: 0.2400\n",
      "Epoch 1613/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3300 - acc: 0.4729 - val_loss: 2.3527 - val_acc: 0.2333\n",
      "Epoch 1614/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3306 - acc: 0.4700 - val_loss: 2.3480 - val_acc: 0.2400\n",
      "Epoch 1615/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3309 - acc: 0.4786 - val_loss: 2.3671 - val_acc: 0.2433\n",
      "Epoch 1616/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3306 - acc: 0.4771 - val_loss: 2.3545 - val_acc: 0.2433\n",
      "Epoch 1617/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3293 - acc: 0.4743 - val_loss: 2.3368 - val_acc: 0.2467\n",
      "Epoch 1618/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3311 - acc: 0.4729 - val_loss: 2.3501 - val_acc: 0.2400\n",
      "Epoch 1619/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3299 - acc: 0.4729 - val_loss: 2.3600 - val_acc: 0.2467\n",
      "Epoch 1620/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.3296 - acc: 0.4714 - val_loss: 2.3659 - val_acc: 0.2467\n",
      "Epoch 1621/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3300 - acc: 0.4786 - val_loss: 2.3756 - val_acc: 0.2467\n",
      "Epoch 1622/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3299 - acc: 0.4743 - val_loss: 2.3374 - val_acc: 0.2467\n",
      "Epoch 1623/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3293 - acc: 0.4729 - val_loss: 2.3478 - val_acc: 0.2433\n",
      "Epoch 1624/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3284 - acc: 0.4786 - val_loss: 2.3580 - val_acc: 0.2467\n",
      "Epoch 1625/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3300 - acc: 0.4729 - val_loss: 2.3552 - val_acc: 0.2400\n",
      "Epoch 1626/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3294 - acc: 0.4657 - val_loss: 2.3682 - val_acc: 0.2467\n",
      "Epoch 1627/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3299 - acc: 0.4771 - val_loss: 2.3786 - val_acc: 0.2500\n",
      "Epoch 1628/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3293 - acc: 0.4771 - val_loss: 2.3641 - val_acc: 0.2467\n",
      "Epoch 1629/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3295 - acc: 0.4786 - val_loss: 2.3364 - val_acc: 0.2433\n",
      "Epoch 1630/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3297 - acc: 0.4757 - val_loss: 2.3598 - val_acc: 0.2467\n",
      "Epoch 1631/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3304 - acc: 0.4757 - val_loss: 2.3577 - val_acc: 0.2433\n",
      "Epoch 1632/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3290 - acc: 0.4771 - val_loss: 2.3765 - val_acc: 0.2467\n",
      "Epoch 1633/3000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.3299 - acc: 0.4671 - val_loss: 2.3564 - val_acc: 0.2433\n",
      "Epoch 1634/3000\n",
      "700/700 [==============================] - 0s 166us/step - loss: 1.3289 - acc: 0.4729 - val_loss: 2.3690 - val_acc: 0.2500\n",
      "Epoch 1635/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3284 - acc: 0.4686 - val_loss: 2.3552 - val_acc: 0.2400\n",
      "Epoch 1636/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3294 - acc: 0.4800 - val_loss: 2.3716 - val_acc: 0.2500\n",
      "Epoch 1637/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3267 - acc: 0.4743 - val_loss: 2.3738 - val_acc: 0.2467\n",
      "Epoch 1638/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.3284 - acc: 0.4800 - val_loss: 2.3741 - val_acc: 0.2467\n",
      "Epoch 1639/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3282 - acc: 0.4686 - val_loss: 2.3730 - val_acc: 0.2400\n",
      "Epoch 1640/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3280 - acc: 0.4714 - val_loss: 2.3912 - val_acc: 0.2500\n",
      "Epoch 1641/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3287 - acc: 0.4800 - val_loss: 2.3643 - val_acc: 0.2400\n",
      "Epoch 1642/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3283 - acc: 0.4786 - val_loss: 2.3753 - val_acc: 0.2400\n",
      "Epoch 1643/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3279 - acc: 0.4814 - val_loss: 2.3752 - val_acc: 0.2467\n",
      "Epoch 1644/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3277 - acc: 0.4757 - val_loss: 2.3720 - val_acc: 0.2400\n",
      "Epoch 1645/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3258 - acc: 0.4814 - val_loss: 2.3683 - val_acc: 0.2433\n",
      "Epoch 1646/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3268 - acc: 0.4700 - val_loss: 2.3504 - val_acc: 0.2333\n",
      "Epoch 1647/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3269 - acc: 0.4814 - val_loss: 2.3866 - val_acc: 0.2433\n",
      "Epoch 1648/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3274 - acc: 0.4814 - val_loss: 2.3771 - val_acc: 0.2400\n",
      "Epoch 1649/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3267 - acc: 0.4757 - val_loss: 2.3740 - val_acc: 0.2433\n",
      "Epoch 1650/3000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.3267 - acc: 0.4800 - val_loss: 2.3656 - val_acc: 0.2433\n",
      "Epoch 1651/3000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3279 - acc: 0.4729 - val_loss: 2.3618 - val_acc: 0.2433\n",
      "Epoch 1652/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3270 - acc: 0.4743 - val_loss: 2.3686 - val_acc: 0.2400\n",
      "Epoch 1653/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3262 - acc: 0.4714 - val_loss: 2.3798 - val_acc: 0.2500\n",
      "Epoch 1654/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3281 - acc: 0.4743 - val_loss: 2.3631 - val_acc: 0.2433\n",
      "Epoch 1655/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3258 - acc: 0.4771 - val_loss: 2.3677 - val_acc: 0.2400\n",
      "Epoch 1656/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3275 - acc: 0.4800 - val_loss: 2.3660 - val_acc: 0.2400\n",
      "Epoch 1657/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3270 - acc: 0.4800 - val_loss: 2.3627 - val_acc: 0.2467\n",
      "Epoch 1658/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3266 - acc: 0.4786 - val_loss: 2.3750 - val_acc: 0.2433\n",
      "Epoch 1659/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3265 - acc: 0.4857 - val_loss: 2.3607 - val_acc: 0.2400\n",
      "Epoch 1660/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3265 - acc: 0.4786 - val_loss: 2.3725 - val_acc: 0.2400\n",
      "Epoch 1661/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3259 - acc: 0.4814 - val_loss: 2.3614 - val_acc: 0.2400\n",
      "Epoch 1662/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3262 - acc: 0.4743 - val_loss: 2.3666 - val_acc: 0.2400\n",
      "Epoch 1663/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3263 - acc: 0.4814 - val_loss: 2.3750 - val_acc: 0.2433\n",
      "Epoch 1664/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3267 - acc: 0.4786 - val_loss: 2.3687 - val_acc: 0.2400\n",
      "Epoch 1665/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 72us/step - loss: 1.3259 - acc: 0.4629 - val_loss: 2.3631 - val_acc: 0.2467\n",
      "Epoch 1666/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3259 - acc: 0.4814 - val_loss: 2.3692 - val_acc: 0.2467\n",
      "Epoch 1667/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3254 - acc: 0.4786 - val_loss: 2.3617 - val_acc: 0.2400\n",
      "Epoch 1668/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3256 - acc: 0.4743 - val_loss: 2.3632 - val_acc: 0.2467\n",
      "Epoch 1669/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3258 - acc: 0.4814 - val_loss: 2.3774 - val_acc: 0.2400\n",
      "Epoch 1670/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3249 - acc: 0.4800 - val_loss: 2.3857 - val_acc: 0.2433\n",
      "Epoch 1671/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3257 - acc: 0.4771 - val_loss: 2.3796 - val_acc: 0.2400\n",
      "Epoch 1672/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3251 - acc: 0.4829 - val_loss: 2.3777 - val_acc: 0.2433\n",
      "Epoch 1673/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3248 - acc: 0.4771 - val_loss: 2.3998 - val_acc: 0.2533\n",
      "Epoch 1674/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3242 - acc: 0.4857 - val_loss: 2.3877 - val_acc: 0.2433\n",
      "Epoch 1675/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3251 - acc: 0.4786 - val_loss: 2.3648 - val_acc: 0.2400\n",
      "Epoch 1676/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3256 - acc: 0.4757 - val_loss: 2.3776 - val_acc: 0.2433\n",
      "Epoch 1677/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3237 - acc: 0.4786 - val_loss: 2.3623 - val_acc: 0.2467\n",
      "Epoch 1678/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3251 - acc: 0.4743 - val_loss: 2.3742 - val_acc: 0.2433\n",
      "Epoch 1679/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3247 - acc: 0.4743 - val_loss: 2.3790 - val_acc: 0.2400\n",
      "Epoch 1680/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3247 - acc: 0.4771 - val_loss: 2.3719 - val_acc: 0.2433\n",
      "Epoch 1681/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3247 - acc: 0.4786 - val_loss: 2.3828 - val_acc: 0.2400\n",
      "Epoch 1682/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.3250 - acc: 0.4786 - val_loss: 2.3757 - val_acc: 0.2433\n",
      "Epoch 1683/3000\n",
      "700/700 [==============================] - 0s 231us/step - loss: 1.3247 - acc: 0.4800 - val_loss: 2.3747 - val_acc: 0.2400\n",
      "Epoch 1684/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3236 - acc: 0.4857 - val_loss: 2.3943 - val_acc: 0.2433\n",
      "Epoch 1685/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3248 - acc: 0.4814 - val_loss: 2.3725 - val_acc: 0.2400\n",
      "Epoch 1686/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3240 - acc: 0.4743 - val_loss: 2.4036 - val_acc: 0.2500\n",
      "Epoch 1687/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3247 - acc: 0.4857 - val_loss: 2.3828 - val_acc: 0.2400\n",
      "Epoch 1688/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.3243 - acc: 0.4829 - val_loss: 2.3719 - val_acc: 0.2400\n",
      "Epoch 1689/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3251 - acc: 0.4771 - val_loss: 2.3810 - val_acc: 0.2467\n",
      "Epoch 1690/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3248 - acc: 0.4771 - val_loss: 2.3736 - val_acc: 0.2367\n",
      "Epoch 1691/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3233 - acc: 0.4814 - val_loss: 2.3713 - val_acc: 0.2433\n",
      "Epoch 1692/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3241 - acc: 0.4829 - val_loss: 2.3783 - val_acc: 0.2400\n",
      "Epoch 1693/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3239 - acc: 0.4757 - val_loss: 2.3922 - val_acc: 0.2433\n",
      "Epoch 1694/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3241 - acc: 0.4814 - val_loss: 2.3944 - val_acc: 0.2467\n",
      "Epoch 1695/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3238 - acc: 0.4743 - val_loss: 2.3817 - val_acc: 0.2433\n",
      "Epoch 1696/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3237 - acc: 0.4800 - val_loss: 2.3514 - val_acc: 0.2500\n",
      "Epoch 1697/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3234 - acc: 0.4857 - val_loss: 2.3856 - val_acc: 0.2467\n",
      "Epoch 1698/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3231 - acc: 0.4771 - val_loss: 2.3852 - val_acc: 0.2400\n",
      "Epoch 1699/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3239 - acc: 0.4786 - val_loss: 2.3941 - val_acc: 0.2467\n",
      "Epoch 1700/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3230 - acc: 0.4771 - val_loss: 2.3920 - val_acc: 0.2500\n",
      "Epoch 1701/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3228 - acc: 0.4814 - val_loss: 2.3845 - val_acc: 0.2433\n",
      "Epoch 1702/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3235 - acc: 0.4743 - val_loss: 2.3715 - val_acc: 0.2433\n",
      "Epoch 1703/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3228 - acc: 0.4743 - val_loss: 2.3745 - val_acc: 0.2400\n",
      "Epoch 1704/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3225 - acc: 0.4814 - val_loss: 2.3808 - val_acc: 0.2400\n",
      "Epoch 1705/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3232 - acc: 0.4814 - val_loss: 2.3900 - val_acc: 0.2467\n",
      "Epoch 1706/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3224 - acc: 0.4829 - val_loss: 2.3716 - val_acc: 0.2433\n",
      "Epoch 1707/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3232 - acc: 0.4757 - val_loss: 2.3871 - val_acc: 0.2433\n",
      "Epoch 1708/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.3218 - acc: 0.4800 - val_loss: 2.3759 - val_acc: 0.2433\n",
      "Epoch 1709/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3216 - acc: 0.4771 - val_loss: 2.3861 - val_acc: 0.2467\n",
      "Epoch 1710/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3224 - acc: 0.4786 - val_loss: 2.3665 - val_acc: 0.2433\n",
      "Epoch 1711/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3220 - acc: 0.4814 - val_loss: 2.3768 - val_acc: 0.2400\n",
      "Epoch 1712/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3230 - acc: 0.4829 - val_loss: 2.3793 - val_acc: 0.2433\n",
      "Epoch 1713/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3218 - acc: 0.4743 - val_loss: 2.4014 - val_acc: 0.2500\n",
      "Epoch 1714/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3234 - acc: 0.4857 - val_loss: 2.3636 - val_acc: 0.2433\n",
      "Epoch 1715/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3225 - acc: 0.4857 - val_loss: 2.3978 - val_acc: 0.2533\n",
      "Epoch 1716/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3221 - acc: 0.4800 - val_loss: 2.4017 - val_acc: 0.2533\n",
      "Epoch 1717/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3222 - acc: 0.4757 - val_loss: 2.3774 - val_acc: 0.2400\n",
      "Epoch 1718/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3226 - acc: 0.4857 - val_loss: 2.3910 - val_acc: 0.2467\n",
      "Epoch 1719/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3222 - acc: 0.4871 - val_loss: 2.3533 - val_acc: 0.2433\n",
      "Epoch 1720/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3213 - acc: 0.4800 - val_loss: 2.3812 - val_acc: 0.2433\n",
      "Epoch 1721/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3223 - acc: 0.4786 - val_loss: 2.3680 - val_acc: 0.2467\n",
      "Epoch 1722/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3226 - acc: 0.4786 - val_loss: 2.3673 - val_acc: 0.2367\n",
      "Epoch 1723/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3221 - acc: 0.4814 - val_loss: 2.3670 - val_acc: 0.2367\n",
      "Epoch 1724/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3210 - acc: 0.4857 - val_loss: 2.3813 - val_acc: 0.2367\n",
      "Epoch 1725/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3219 - acc: 0.4829 - val_loss: 2.3887 - val_acc: 0.2433\n",
      "Epoch 1726/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3212 - acc: 0.4829 - val_loss: 2.3883 - val_acc: 0.2467\n",
      "Epoch 1727/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3222 - acc: 0.4800 - val_loss: 2.3897 - val_acc: 0.2500\n",
      "Epoch 1728/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3214 - acc: 0.4757 - val_loss: 2.3862 - val_acc: 0.2433\n",
      "Epoch 1729/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3220 - acc: 0.4771 - val_loss: 2.3836 - val_acc: 0.2400\n",
      "Epoch 1730/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3213 - acc: 0.4771 - val_loss: 2.3716 - val_acc: 0.2400\n",
      "Epoch 1731/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3213 - acc: 0.4829 - val_loss: 2.3968 - val_acc: 0.2500\n",
      "Epoch 1732/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3211 - acc: 0.4829 - val_loss: 2.3886 - val_acc: 0.2467\n",
      "Epoch 1733/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3202 - acc: 0.4786 - val_loss: 2.3981 - val_acc: 0.2467\n",
      "Epoch 1734/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3213 - acc: 0.4771 - val_loss: 2.3888 - val_acc: 0.2433\n",
      "Epoch 1735/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3214 - acc: 0.4800 - val_loss: 2.3858 - val_acc: 0.2433\n",
      "Epoch 1736/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3210 - acc: 0.4800 - val_loss: 2.3885 - val_acc: 0.2433\n",
      "Epoch 1737/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3192 - acc: 0.4857 - val_loss: 2.3923 - val_acc: 0.2433\n",
      "Epoch 1738/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3207 - acc: 0.4786 - val_loss: 2.4064 - val_acc: 0.2533\n",
      "Epoch 1739/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3208 - acc: 0.4771 - val_loss: 2.3828 - val_acc: 0.2400\n",
      "Epoch 1740/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3208 - acc: 0.4829 - val_loss: 2.4014 - val_acc: 0.2500\n",
      "Epoch 1741/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3207 - acc: 0.4857 - val_loss: 2.3639 - val_acc: 0.2400\n",
      "Epoch 1742/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3200 - acc: 0.4843 - val_loss: 2.3985 - val_acc: 0.2500\n",
      "Epoch 1743/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3208 - acc: 0.4786 - val_loss: 2.4031 - val_acc: 0.2467\n",
      "Epoch 1744/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3206 - acc: 0.4814 - val_loss: 2.3928 - val_acc: 0.2433\n",
      "Epoch 1745/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3204 - acc: 0.4829 - val_loss: 2.3802 - val_acc: 0.2400\n",
      "Epoch 1746/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3209 - acc: 0.4814 - val_loss: 2.4056 - val_acc: 0.2500\n",
      "Epoch 1747/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3200 - acc: 0.4800 - val_loss: 2.3989 - val_acc: 0.2400\n",
      "Epoch 1748/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3195 - acc: 0.4771 - val_loss: 2.3938 - val_acc: 0.2400\n",
      "Epoch 1749/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.3202 - acc: 0.4814 - val_loss: 2.3972 - val_acc: 0.2467\n",
      "Epoch 1750/3000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.3194 - acc: 0.4829 - val_loss: 2.3649 - val_acc: 0.2433\n",
      "Epoch 1751/3000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.3200 - acc: 0.4843 - val_loss: 2.3679 - val_acc: 0.2433\n",
      "Epoch 1752/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3188 - acc: 0.4800 - val_loss: 2.3738 - val_acc: 0.2433\n",
      "Epoch 1753/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3200 - acc: 0.4771 - val_loss: 2.3986 - val_acc: 0.2433\n",
      "Epoch 1754/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3200 - acc: 0.4857 - val_loss: 2.4033 - val_acc: 0.2500\n",
      "Epoch 1755/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3184 - acc: 0.4814 - val_loss: 2.3983 - val_acc: 0.2467\n",
      "Epoch 1756/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.3195 - acc: 0.4800 - val_loss: 2.3748 - val_acc: 0.2433\n",
      "Epoch 1757/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3193 - acc: 0.4857 - val_loss: 2.4097 - val_acc: 0.2500\n",
      "Epoch 1758/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3192 - acc: 0.4814 - val_loss: 2.3815 - val_acc: 0.2433\n",
      "Epoch 1759/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3192 - acc: 0.4814 - val_loss: 2.4270 - val_acc: 0.2500\n",
      "Epoch 1760/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3199 - acc: 0.4829 - val_loss: 2.3860 - val_acc: 0.2433\n",
      "Epoch 1761/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3202 - acc: 0.4886 - val_loss: 2.3842 - val_acc: 0.2400\n",
      "Epoch 1762/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3190 - acc: 0.4800 - val_loss: 2.4085 - val_acc: 0.2467\n",
      "Epoch 1763/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3189 - acc: 0.4786 - val_loss: 2.3887 - val_acc: 0.2400\n",
      "Epoch 1764/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3180 - acc: 0.4871 - val_loss: 2.3902 - val_acc: 0.2433\n",
      "Epoch 1765/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3195 - acc: 0.4800 - val_loss: 2.3875 - val_acc: 0.2467\n",
      "Epoch 1766/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3187 - acc: 0.4771 - val_loss: 2.3786 - val_acc: 0.2433\n",
      "Epoch 1767/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3190 - acc: 0.4829 - val_loss: 2.3835 - val_acc: 0.2433\n",
      "Epoch 1768/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3190 - acc: 0.4843 - val_loss: 2.3910 - val_acc: 0.2400\n",
      "Epoch 1769/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3185 - acc: 0.4843 - val_loss: 2.3914 - val_acc: 0.2433\n",
      "Epoch 1770/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3191 - acc: 0.4971 - val_loss: 2.4014 - val_acc: 0.2467\n",
      "Epoch 1771/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3189 - acc: 0.4843 - val_loss: 2.3822 - val_acc: 0.2433\n",
      "Epoch 1772/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3185 - acc: 0.4800 - val_loss: 2.4014 - val_acc: 0.2500\n",
      "Epoch 1773/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3183 - acc: 0.4857 - val_loss: 2.3943 - val_acc: 0.2433\n",
      "Epoch 1774/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3188 - acc: 0.4900 - val_loss: 2.3895 - val_acc: 0.2467\n",
      "Epoch 1775/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3184 - acc: 0.4843 - val_loss: 2.4081 - val_acc: 0.2500\n",
      "Epoch 1776/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3194 - acc: 0.4757 - val_loss: 2.3768 - val_acc: 0.2433\n",
      "Epoch 1777/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3177 - acc: 0.4786 - val_loss: 2.3908 - val_acc: 0.2433\n",
      "Epoch 1778/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3182 - acc: 0.4786 - val_loss: 2.3804 - val_acc: 0.2400\n",
      "Epoch 1779/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3184 - acc: 0.4943 - val_loss: 2.3917 - val_acc: 0.2400\n",
      "Epoch 1780/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3187 - acc: 0.4829 - val_loss: 2.4095 - val_acc: 0.2467\n",
      "Epoch 1781/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3175 - acc: 0.4843 - val_loss: 2.4109 - val_acc: 0.2467\n",
      "Epoch 1782/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3182 - acc: 0.4786 - val_loss: 2.3716 - val_acc: 0.2400\n",
      "Epoch 1783/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 107us/step - loss: 1.3180 - acc: 0.4871 - val_loss: 2.4028 - val_acc: 0.2467\n",
      "Epoch 1784/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3173 - acc: 0.4814 - val_loss: 2.3868 - val_acc: 0.2400\n",
      "Epoch 1785/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3178 - acc: 0.4829 - val_loss: 2.3839 - val_acc: 0.2467\n",
      "Epoch 1786/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3183 - acc: 0.4914 - val_loss: 2.3953 - val_acc: 0.2500\n",
      "Epoch 1787/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3175 - acc: 0.4914 - val_loss: 2.3878 - val_acc: 0.2400\n",
      "Epoch 1788/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3180 - acc: 0.4843 - val_loss: 2.3903 - val_acc: 0.2400\n",
      "Epoch 1789/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3178 - acc: 0.4857 - val_loss: 2.3753 - val_acc: 0.2367\n",
      "Epoch 1790/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3174 - acc: 0.4871 - val_loss: 2.3952 - val_acc: 0.2400\n",
      "Epoch 1791/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3179 - acc: 0.4814 - val_loss: 2.3883 - val_acc: 0.2400\n",
      "Epoch 1792/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3167 - acc: 0.4800 - val_loss: 2.4154 - val_acc: 0.2467\n",
      "Epoch 1793/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3173 - acc: 0.4829 - val_loss: 2.4029 - val_acc: 0.2467\n",
      "Epoch 1794/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3167 - acc: 0.4871 - val_loss: 2.3961 - val_acc: 0.2467\n",
      "Epoch 1795/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3177 - acc: 0.4814 - val_loss: 2.4011 - val_acc: 0.2433\n",
      "Epoch 1796/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3169 - acc: 0.4814 - val_loss: 2.4203 - val_acc: 0.2500\n",
      "Epoch 1797/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3163 - acc: 0.4814 - val_loss: 2.4045 - val_acc: 0.2433\n",
      "Epoch 1798/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3175 - acc: 0.4871 - val_loss: 2.3905 - val_acc: 0.2433\n",
      "Epoch 1799/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3168 - acc: 0.4900 - val_loss: 2.4231 - val_acc: 0.2467\n",
      "Epoch 1800/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3172 - acc: 0.4829 - val_loss: 2.4115 - val_acc: 0.2467\n",
      "Epoch 1801/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3164 - acc: 0.4843 - val_loss: 2.3884 - val_acc: 0.2367\n",
      "Epoch 1802/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3164 - acc: 0.4871 - val_loss: 2.4159 - val_acc: 0.2467\n",
      "Epoch 1803/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3163 - acc: 0.4829 - val_loss: 2.3959 - val_acc: 0.2467\n",
      "Epoch 1804/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3168 - acc: 0.4886 - val_loss: 2.3895 - val_acc: 0.2433\n",
      "Epoch 1805/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3167 - acc: 0.4829 - val_loss: 2.3863 - val_acc: 0.2433\n",
      "Epoch 1806/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3162 - acc: 0.4800 - val_loss: 2.3884 - val_acc: 0.2400\n",
      "Epoch 1807/3000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.3162 - acc: 0.4829 - val_loss: 2.4049 - val_acc: 0.2433\n",
      "Epoch 1808/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3157 - acc: 0.4757 - val_loss: 2.4073 - val_acc: 0.2500\n",
      "Epoch 1809/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3163 - acc: 0.4814 - val_loss: 2.3810 - val_acc: 0.2400\n",
      "Epoch 1810/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3164 - acc: 0.4857 - val_loss: 2.3918 - val_acc: 0.2433\n",
      "Epoch 1811/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3154 - acc: 0.4857 - val_loss: 2.3945 - val_acc: 0.2433\n",
      "Epoch 1812/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3155 - acc: 0.4871 - val_loss: 2.4129 - val_acc: 0.2500\n",
      "Epoch 1813/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3164 - acc: 0.4829 - val_loss: 2.3932 - val_acc: 0.2400\n",
      "Epoch 1814/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3164 - acc: 0.4843 - val_loss: 2.3959 - val_acc: 0.2500\n",
      "Epoch 1815/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3159 - acc: 0.4914 - val_loss: 2.4139 - val_acc: 0.2500\n",
      "Epoch 1816/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3149 - acc: 0.4871 - val_loss: 2.3975 - val_acc: 0.2400\n",
      "Epoch 1817/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3153 - acc: 0.4871 - val_loss: 2.3917 - val_acc: 0.2400\n",
      "Epoch 1818/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3163 - acc: 0.4800 - val_loss: 2.3964 - val_acc: 0.2433\n",
      "Epoch 1819/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3157 - acc: 0.4886 - val_loss: 2.4064 - val_acc: 0.2433\n",
      "Epoch 1820/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3171 - acc: 0.4829 - val_loss: 2.3886 - val_acc: 0.2400\n",
      "Epoch 1821/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3150 - acc: 0.4786 - val_loss: 2.4300 - val_acc: 0.2467\n",
      "Epoch 1822/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3151 - acc: 0.4943 - val_loss: 2.4058 - val_acc: 0.2433\n",
      "Epoch 1823/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3145 - acc: 0.4829 - val_loss: 2.4315 - val_acc: 0.2467\n",
      "Epoch 1824/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3158 - acc: 0.4829 - val_loss: 2.4033 - val_acc: 0.2533\n",
      "Epoch 1825/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3153 - acc: 0.4857 - val_loss: 2.4155 - val_acc: 0.2500\n",
      "Epoch 1826/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3153 - acc: 0.4829 - val_loss: 2.3828 - val_acc: 0.2400\n",
      "Epoch 1827/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3155 - acc: 0.4829 - val_loss: 2.4129 - val_acc: 0.2500\n",
      "Epoch 1828/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3136 - acc: 0.4800 - val_loss: 2.3933 - val_acc: 0.2400\n",
      "Epoch 1829/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3161 - acc: 0.4800 - val_loss: 2.3980 - val_acc: 0.2400\n",
      "Epoch 1830/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3144 - acc: 0.4871 - val_loss: 2.4087 - val_acc: 0.2400\n",
      "Epoch 1831/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3147 - acc: 0.4900 - val_loss: 2.4024 - val_acc: 0.2400\n",
      "Epoch 1832/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3146 - acc: 0.4843 - val_loss: 2.4120 - val_acc: 0.2533\n",
      "Epoch 1833/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3148 - acc: 0.4829 - val_loss: 2.4204 - val_acc: 0.2467\n",
      "Epoch 1834/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3144 - acc: 0.4800 - val_loss: 2.4186 - val_acc: 0.2500\n",
      "Epoch 1835/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3143 - acc: 0.4886 - val_loss: 2.4121 - val_acc: 0.2433\n",
      "Epoch 1836/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3150 - acc: 0.4857 - val_loss: 2.3981 - val_acc: 0.2433\n",
      "Epoch 1837/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3145 - acc: 0.4871 - val_loss: 2.4005 - val_acc: 0.2467\n",
      "Epoch 1838/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3140 - acc: 0.4843 - val_loss: 2.3962 - val_acc: 0.2400\n",
      "Epoch 1839/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3134 - acc: 0.4843 - val_loss: 2.4276 - val_acc: 0.2533\n",
      "Epoch 1840/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3144 - acc: 0.4914 - val_loss: 2.4069 - val_acc: 0.2433\n",
      "Epoch 1841/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3128 - acc: 0.4886 - val_loss: 2.3914 - val_acc: 0.2400\n",
      "Epoch 1842/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3142 - acc: 0.4829 - val_loss: 2.4061 - val_acc: 0.2433\n",
      "Epoch 1843/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3136 - acc: 0.4843 - val_loss: 2.4040 - val_acc: 0.2400\n",
      "Epoch 1844/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3140 - acc: 0.4814 - val_loss: 2.4157 - val_acc: 0.2500\n",
      "Epoch 1845/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3134 - acc: 0.4843 - val_loss: 2.3881 - val_acc: 0.2433\n",
      "Epoch 1846/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3138 - acc: 0.4857 - val_loss: 2.4098 - val_acc: 0.2433\n",
      "Epoch 1847/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3150 - acc: 0.4829 - val_loss: 2.3746 - val_acc: 0.2467\n",
      "Epoch 1848/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3147 - acc: 0.4843 - val_loss: 2.4097 - val_acc: 0.2467\n",
      "Epoch 1849/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3140 - acc: 0.4871 - val_loss: 2.3958 - val_acc: 0.2400\n",
      "Epoch 1850/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.3132 - acc: 0.4786 - val_loss: 2.4126 - val_acc: 0.2467\n",
      "Epoch 1851/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3134 - acc: 0.4843 - val_loss: 2.4127 - val_acc: 0.2433\n",
      "Epoch 1852/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3133 - acc: 0.4843 - val_loss: 2.4201 - val_acc: 0.2467\n",
      "Epoch 1853/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3134 - acc: 0.4829 - val_loss: 2.3972 - val_acc: 0.2433\n",
      "Epoch 1854/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.3129 - acc: 0.4900 - val_loss: 2.4061 - val_acc: 0.2467\n",
      "Epoch 1855/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3128 - acc: 0.4814 - val_loss: 2.4030 - val_acc: 0.2400\n",
      "Epoch 1856/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3117 - acc: 0.4857 - val_loss: 2.4003 - val_acc: 0.2467\n",
      "Epoch 1857/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3131 - acc: 0.4843 - val_loss: 2.4037 - val_acc: 0.2367\n",
      "Epoch 1858/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3130 - acc: 0.4843 - val_loss: 2.4179 - val_acc: 0.2467\n",
      "Epoch 1859/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3118 - acc: 0.4843 - val_loss: 2.4058 - val_acc: 0.2433\n",
      "Epoch 1860/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.3121 - acc: 0.4771 - val_loss: 2.4207 - val_acc: 0.2500\n",
      "Epoch 1861/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3123 - acc: 0.4914 - val_loss: 2.4201 - val_acc: 0.2467\n",
      "Epoch 1862/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3128 - acc: 0.4929 - val_loss: 2.4073 - val_acc: 0.2467\n",
      "Epoch 1863/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3124 - acc: 0.4857 - val_loss: 2.4063 - val_acc: 0.2400\n",
      "Epoch 1864/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3116 - acc: 0.4900 - val_loss: 2.4092 - val_acc: 0.2433\n",
      "Epoch 1865/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3116 - acc: 0.4900 - val_loss: 2.4241 - val_acc: 0.2467\n",
      "Epoch 1866/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3118 - acc: 0.4886 - val_loss: 2.4245 - val_acc: 0.2500\n",
      "Epoch 1867/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3122 - acc: 0.4886 - val_loss: 2.4091 - val_acc: 0.2333\n",
      "Epoch 1868/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3124 - acc: 0.4843 - val_loss: 2.4165 - val_acc: 0.2400\n",
      "Epoch 1869/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3112 - acc: 0.4886 - val_loss: 2.4327 - val_acc: 0.2500\n",
      "Epoch 1870/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3119 - acc: 0.4857 - val_loss: 2.3938 - val_acc: 0.2400\n",
      "Epoch 1871/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3117 - acc: 0.4857 - val_loss: 2.4018 - val_acc: 0.2400\n",
      "Epoch 1872/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3115 - acc: 0.4843 - val_loss: 2.4011 - val_acc: 0.2400\n",
      "Epoch 1873/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3110 - acc: 0.4900 - val_loss: 2.4380 - val_acc: 0.2467\n",
      "Epoch 1874/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3114 - acc: 0.4900 - val_loss: 2.4153 - val_acc: 0.2467\n",
      "Epoch 1875/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3111 - acc: 0.4971 - val_loss: 2.4266 - val_acc: 0.2433\n",
      "Epoch 1876/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3111 - acc: 0.4771 - val_loss: 2.4062 - val_acc: 0.2400\n",
      "Epoch 1877/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3115 - acc: 0.4800 - val_loss: 2.4047 - val_acc: 0.2500\n",
      "Epoch 1878/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3111 - acc: 0.4857 - val_loss: 2.4259 - val_acc: 0.2500\n",
      "Epoch 1879/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3108 - acc: 0.4929 - val_loss: 2.4214 - val_acc: 0.2433\n",
      "Epoch 1880/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3104 - acc: 0.4886 - val_loss: 2.4198 - val_acc: 0.2433\n",
      "Epoch 1881/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3105 - acc: 0.4857 - val_loss: 2.4352 - val_acc: 0.2467\n",
      "Epoch 1882/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3105 - acc: 0.4800 - val_loss: 2.3983 - val_acc: 0.2433\n",
      "Epoch 1883/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3109 - acc: 0.4829 - val_loss: 2.4147 - val_acc: 0.2433\n",
      "Epoch 1884/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3104 - acc: 0.4886 - val_loss: 2.4061 - val_acc: 0.2433\n",
      "Epoch 1885/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3101 - acc: 0.4843 - val_loss: 2.4079 - val_acc: 0.2433\n",
      "Epoch 1886/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3111 - acc: 0.4843 - val_loss: 2.4024 - val_acc: 0.2467\n",
      "Epoch 1887/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3102 - acc: 0.4857 - val_loss: 2.4181 - val_acc: 0.2400\n",
      "Epoch 1888/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3091 - acc: 0.4900 - val_loss: 2.4410 - val_acc: 0.2500\n",
      "Epoch 1889/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3106 - acc: 0.4871 - val_loss: 2.4020 - val_acc: 0.2467\n",
      "Epoch 1890/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.3102 - acc: 0.4929 - val_loss: 2.4155 - val_acc: 0.2433\n",
      "Epoch 1891/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.3099 - acc: 0.4929 - val_loss: 2.4181 - val_acc: 0.2433\n",
      "Epoch 1892/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3101 - acc: 0.4886 - val_loss: 2.3991 - val_acc: 0.2467\n",
      "Epoch 1893/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3095 - acc: 0.4871 - val_loss: 2.4340 - val_acc: 0.2467\n",
      "Epoch 1894/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3097 - acc: 0.4886 - val_loss: 2.4117 - val_acc: 0.2467\n",
      "Epoch 1895/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.3102 - acc: 0.4914 - val_loss: 2.4058 - val_acc: 0.2433\n",
      "Epoch 1896/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3096 - acc: 0.4829 - val_loss: 2.4392 - val_acc: 0.2433\n",
      "Epoch 1897/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3098 - acc: 0.4929 - val_loss: 2.4026 - val_acc: 0.2467\n",
      "Epoch 1898/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3100 - acc: 0.4857 - val_loss: 2.3951 - val_acc: 0.2400\n",
      "Epoch 1899/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3095 - acc: 0.4857 - val_loss: 2.4153 - val_acc: 0.2467\n",
      "Epoch 1900/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3094 - acc: 0.4886 - val_loss: 2.4336 - val_acc: 0.2467\n",
      "Epoch 1901/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 79us/step - loss: 1.3097 - acc: 0.4814 - val_loss: 2.4036 - val_acc: 0.2433\n",
      "Epoch 1902/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3095 - acc: 0.4871 - val_loss: 2.4298 - val_acc: 0.2433\n",
      "Epoch 1903/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3086 - acc: 0.4914 - val_loss: 2.4093 - val_acc: 0.2433\n",
      "Epoch 1904/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3091 - acc: 0.4914 - val_loss: 2.4350 - val_acc: 0.2467\n",
      "Epoch 1905/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3097 - acc: 0.4871 - val_loss: 2.4337 - val_acc: 0.2467\n",
      "Epoch 1906/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3102 - acc: 0.4886 - val_loss: 2.4224 - val_acc: 0.2467\n",
      "Epoch 1907/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3087 - acc: 0.4857 - val_loss: 2.4256 - val_acc: 0.2533\n",
      "Epoch 1908/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3098 - acc: 0.4843 - val_loss: 2.4325 - val_acc: 0.2467\n",
      "Epoch 1909/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3087 - acc: 0.4871 - val_loss: 2.4158 - val_acc: 0.2400\n",
      "Epoch 1910/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3088 - acc: 0.4857 - val_loss: 2.4226 - val_acc: 0.2400\n",
      "Epoch 1911/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3086 - acc: 0.4943 - val_loss: 2.4095 - val_acc: 0.2367\n",
      "Epoch 1912/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3089 - acc: 0.4886 - val_loss: 2.4251 - val_acc: 0.2500\n",
      "Epoch 1913/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3083 - acc: 0.4900 - val_loss: 2.4287 - val_acc: 0.2433\n",
      "Epoch 1914/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3074 - acc: 0.4857 - val_loss: 2.4268 - val_acc: 0.2467\n",
      "Epoch 1915/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3084 - acc: 0.4843 - val_loss: 2.4136 - val_acc: 0.2433\n",
      "Epoch 1916/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3083 - acc: 0.4871 - val_loss: 2.4047 - val_acc: 0.2467\n",
      "Epoch 1917/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3088 - acc: 0.4886 - val_loss: 2.4163 - val_acc: 0.2467\n",
      "Epoch 1918/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3082 - acc: 0.4929 - val_loss: 2.4346 - val_acc: 0.2400\n",
      "Epoch 1919/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3084 - acc: 0.4900 - val_loss: 2.4224 - val_acc: 0.2400\n",
      "Epoch 1920/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3090 - acc: 0.4900 - val_loss: 2.4187 - val_acc: 0.2433\n",
      "Epoch 1921/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3080 - acc: 0.4900 - val_loss: 2.4220 - val_acc: 0.2433\n",
      "Epoch 1922/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3072 - acc: 0.4929 - val_loss: 2.4133 - val_acc: 0.2433\n",
      "Epoch 1923/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3086 - acc: 0.4957 - val_loss: 2.4278 - val_acc: 0.2467\n",
      "Epoch 1924/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3079 - acc: 0.4857 - val_loss: 2.3987 - val_acc: 0.2433\n",
      "Epoch 1925/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3076 - acc: 0.4886 - val_loss: 2.4368 - val_acc: 0.2400\n",
      "Epoch 1926/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3076 - acc: 0.4886 - val_loss: 2.4179 - val_acc: 0.2433\n",
      "Epoch 1927/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3076 - acc: 0.4843 - val_loss: 2.4146 - val_acc: 0.2433\n",
      "Epoch 1928/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3074 - acc: 0.4914 - val_loss: 2.4211 - val_acc: 0.2400\n",
      "Epoch 1929/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3075 - acc: 0.4900 - val_loss: 2.4386 - val_acc: 0.2500\n",
      "Epoch 1930/3000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3083 - acc: 0.4814 - val_loss: 2.4235 - val_acc: 0.2433\n",
      "Epoch 1931/3000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.3078 - acc: 0.4914 - val_loss: 2.4175 - val_acc: 0.2433\n",
      "Epoch 1932/3000\n",
      "700/700 [==============================] - 0s 159us/step - loss: 1.3073 - acc: 0.4900 - val_loss: 2.4322 - val_acc: 0.2467\n",
      "Epoch 1933/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3071 - acc: 0.4914 - val_loss: 2.4404 - val_acc: 0.2467\n",
      "Epoch 1934/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3077 - acc: 0.4814 - val_loss: 2.4231 - val_acc: 0.2500\n",
      "Epoch 1935/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3072 - acc: 0.4886 - val_loss: 2.4244 - val_acc: 0.2433\n",
      "Epoch 1936/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3072 - acc: 0.4886 - val_loss: 2.4454 - val_acc: 0.2467\n",
      "Epoch 1937/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3066 - acc: 0.4914 - val_loss: 2.4184 - val_acc: 0.2433\n",
      "Epoch 1938/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3072 - acc: 0.4886 - val_loss: 2.4387 - val_acc: 0.2467\n",
      "Epoch 1939/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3072 - acc: 0.4914 - val_loss: 2.4343 - val_acc: 0.2467\n",
      "Epoch 1940/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3072 - acc: 0.4943 - val_loss: 2.4316 - val_acc: 0.2467\n",
      "Epoch 1941/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3068 - acc: 0.4843 - val_loss: 2.4157 - val_acc: 0.2433\n",
      "Epoch 1942/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3067 - acc: 0.4914 - val_loss: 2.4394 - val_acc: 0.2500\n",
      "Epoch 1943/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.3065 - acc: 0.4914 - val_loss: 2.4392 - val_acc: 0.2467\n",
      "Epoch 1944/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.3063 - acc: 0.4929 - val_loss: 2.4361 - val_acc: 0.2467\n",
      "Epoch 1945/3000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.3061 - acc: 0.4914 - val_loss: 2.4216 - val_acc: 0.2400\n",
      "Epoch 1946/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3066 - acc: 0.4900 - val_loss: 2.4353 - val_acc: 0.2433\n",
      "Epoch 1947/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3073 - acc: 0.4871 - val_loss: 2.4166 - val_acc: 0.2433\n",
      "Epoch 1948/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3058 - acc: 0.4957 - val_loss: 2.4343 - val_acc: 0.2467\n",
      "Epoch 1949/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3074 - acc: 0.4914 - val_loss: 2.4165 - val_acc: 0.2433\n",
      "Epoch 1950/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3074 - acc: 0.4900 - val_loss: 2.4256 - val_acc: 0.2400\n",
      "Epoch 1951/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.3057 - acc: 0.4857 - val_loss: 2.4328 - val_acc: 0.2500\n",
      "Epoch 1952/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3065 - acc: 0.4914 - val_loss: 2.4542 - val_acc: 0.2467\n",
      "Epoch 1953/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3059 - acc: 0.4871 - val_loss: 2.4206 - val_acc: 0.2467\n",
      "Epoch 1954/3000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.3061 - acc: 0.4914 - val_loss: 2.4237 - val_acc: 0.2500\n",
      "Epoch 1955/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3062 - acc: 0.4886 - val_loss: 2.4337 - val_acc: 0.2467\n",
      "Epoch 1956/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3060 - acc: 0.4929 - val_loss: 2.4367 - val_acc: 0.2467\n",
      "Epoch 1957/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3058 - acc: 0.4886 - val_loss: 2.4071 - val_acc: 0.2433\n",
      "Epoch 1958/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3063 - acc: 0.4871 - val_loss: 2.4148 - val_acc: 0.2433\n",
      "Epoch 1959/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3058 - acc: 0.4914 - val_loss: 2.4186 - val_acc: 0.2400\n",
      "Epoch 1960/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3058 - acc: 0.4929 - val_loss: 2.4310 - val_acc: 0.2400\n",
      "Epoch 1961/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3058 - acc: 0.4914 - val_loss: 2.4494 - val_acc: 0.2467\n",
      "Epoch 1962/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3053 - acc: 0.4929 - val_loss: 2.4252 - val_acc: 0.2467\n",
      "Epoch 1963/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3050 - acc: 0.4943 - val_loss: 2.4352 - val_acc: 0.2500\n",
      "Epoch 1964/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3058 - acc: 0.4886 - val_loss: 2.4288 - val_acc: 0.2400\n",
      "Epoch 1965/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3053 - acc: 0.4843 - val_loss: 2.4381 - val_acc: 0.2467\n",
      "Epoch 1966/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3054 - acc: 0.4900 - val_loss: 2.4387 - val_acc: 0.2433\n",
      "Epoch 1967/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.3054 - acc: 0.4929 - val_loss: 2.4317 - val_acc: 0.2433\n",
      "Epoch 1968/3000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.3049 - acc: 0.4900 - val_loss: 2.4445 - val_acc: 0.2500\n",
      "Epoch 1969/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3060 - acc: 0.4943 - val_loss: 2.4462 - val_acc: 0.2467\n",
      "Epoch 1970/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.3052 - acc: 0.4857 - val_loss: 2.4413 - val_acc: 0.2500\n",
      "Epoch 1971/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3052 - acc: 0.4914 - val_loss: 2.4402 - val_acc: 0.2467\n",
      "Epoch 1972/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3041 - acc: 0.4929 - val_loss: 2.4370 - val_acc: 0.2433\n",
      "Epoch 1973/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3055 - acc: 0.5000 - val_loss: 2.4386 - val_acc: 0.2467\n",
      "Epoch 1974/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3049 - acc: 0.4943 - val_loss: 2.4124 - val_acc: 0.2433\n",
      "Epoch 1975/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3049 - acc: 0.4929 - val_loss: 2.4280 - val_acc: 0.2500\n",
      "Epoch 1976/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3058 - acc: 0.4829 - val_loss: 2.4376 - val_acc: 0.2467\n",
      "Epoch 1977/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3049 - acc: 0.4943 - val_loss: 2.4223 - val_acc: 0.2433\n",
      "Epoch 1978/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3052 - acc: 0.4914 - val_loss: 2.4341 - val_acc: 0.2467\n",
      "Epoch 1979/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.3041 - acc: 0.4857 - val_loss: 2.4568 - val_acc: 0.2467\n",
      "Epoch 1980/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3034 - acc: 0.4886 - val_loss: 2.4259 - val_acc: 0.2433\n",
      "Epoch 1981/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3045 - acc: 0.4886 - val_loss: 2.4323 - val_acc: 0.2433\n",
      "Epoch 1982/3000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3043 - acc: 0.4900 - val_loss: 2.4366 - val_acc: 0.2500\n",
      "Epoch 1983/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3045 - acc: 0.4886 - val_loss: 2.4323 - val_acc: 0.2433\n",
      "Epoch 1984/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3046 - acc: 0.4929 - val_loss: 2.4341 - val_acc: 0.2433\n",
      "Epoch 1985/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3039 - acc: 0.4957 - val_loss: 2.4501 - val_acc: 0.2500\n",
      "Epoch 1986/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3049 - acc: 0.4900 - val_loss: 2.4425 - val_acc: 0.2433\n",
      "Epoch 1987/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3044 - acc: 0.4929 - val_loss: 2.4351 - val_acc: 0.2467\n",
      "Epoch 1988/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3052 - acc: 0.4886 - val_loss: 2.4595 - val_acc: 0.2467\n",
      "Epoch 1989/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3044 - acc: 0.4986 - val_loss: 2.4387 - val_acc: 0.2433\n",
      "Epoch 1990/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3039 - acc: 0.4857 - val_loss: 2.4331 - val_acc: 0.2467\n",
      "Epoch 1991/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3036 - acc: 0.4929 - val_loss: 2.4330 - val_acc: 0.2433\n",
      "Epoch 1992/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3034 - acc: 0.4871 - val_loss: 2.4648 - val_acc: 0.2500\n",
      "Epoch 1993/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.3042 - acc: 0.4886 - val_loss: 2.4101 - val_acc: 0.2500\n",
      "Epoch 1994/3000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.3040 - acc: 0.4943 - val_loss: 2.4393 - val_acc: 0.2467\n",
      "Epoch 1995/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.3036 - acc: 0.4886 - val_loss: 2.4502 - val_acc: 0.2467\n",
      "Epoch 1996/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3033 - acc: 0.4886 - val_loss: 2.4534 - val_acc: 0.2467\n",
      "Epoch 1997/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3033 - acc: 0.4900 - val_loss: 2.4230 - val_acc: 0.2467\n",
      "Epoch 1998/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.3032 - acc: 0.4914 - val_loss: 2.4574 - val_acc: 0.2433\n",
      "Epoch 1999/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3038 - acc: 0.4900 - val_loss: 2.4586 - val_acc: 0.2467\n",
      "Epoch 2000/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3036 - acc: 0.4914 - val_loss: 2.4425 - val_acc: 0.2467\n",
      "Epoch 2001/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3033 - acc: 0.4900 - val_loss: 2.4135 - val_acc: 0.2433\n",
      "Epoch 2002/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3039 - acc: 0.4900 - val_loss: 2.4415 - val_acc: 0.2433\n",
      "Epoch 2003/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3039 - acc: 0.4871 - val_loss: 2.4618 - val_acc: 0.2433\n",
      "Epoch 2004/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3034 - acc: 0.4857 - val_loss: 2.4352 - val_acc: 0.2433\n",
      "Epoch 2005/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3030 - acc: 0.4900 - val_loss: 2.4512 - val_acc: 0.2467\n",
      "Epoch 2006/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.3027 - acc: 0.4886 - val_loss: 2.4594 - val_acc: 0.2467\n",
      "Epoch 2007/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3024 - acc: 0.4943 - val_loss: 2.4357 - val_acc: 0.2433\n",
      "Epoch 2008/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3025 - acc: 0.4943 - val_loss: 2.4684 - val_acc: 0.2533\n",
      "Epoch 2009/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3037 - acc: 0.4971 - val_loss: 2.4340 - val_acc: 0.2400\n",
      "Epoch 2010/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.3026 - acc: 0.4900 - val_loss: 2.4377 - val_acc: 0.2467\n",
      "Epoch 2011/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.3027 - acc: 0.4986 - val_loss: 2.4557 - val_acc: 0.2500\n",
      "Epoch 2012/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3027 - acc: 0.4900 - val_loss: 2.4259 - val_acc: 0.2467\n",
      "Epoch 2013/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3023 - acc: 0.4929 - val_loss: 2.4293 - val_acc: 0.2433\n",
      "Epoch 2014/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3022 - acc: 0.4986 - val_loss: 2.4844 - val_acc: 0.2433\n",
      "Epoch 2015/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3021 - acc: 0.4914 - val_loss: 2.4344 - val_acc: 0.2467\n",
      "Epoch 2016/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3023 - acc: 0.4886 - val_loss: 2.4715 - val_acc: 0.2433\n",
      "Epoch 2017/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3023 - acc: 0.4943 - val_loss: 2.4346 - val_acc: 0.2467\n",
      "Epoch 2018/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3018 - acc: 0.4886 - val_loss: 2.4518 - val_acc: 0.2467\n",
      "Epoch 2019/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 72us/step - loss: 1.3026 - acc: 0.4929 - val_loss: 2.4198 - val_acc: 0.2433\n",
      "Epoch 2020/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3024 - acc: 0.4929 - val_loss: 2.4491 - val_acc: 0.2467\n",
      "Epoch 2021/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.3022 - acc: 0.4943 - val_loss: 2.4679 - val_acc: 0.2433\n",
      "Epoch 2022/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3029 - acc: 0.4914 - val_loss: 2.4371 - val_acc: 0.2400\n",
      "Epoch 2023/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.3022 - acc: 0.4943 - val_loss: 2.4304 - val_acc: 0.2433\n",
      "Epoch 2024/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3026 - acc: 0.4900 - val_loss: 2.4665 - val_acc: 0.2433\n",
      "Epoch 2025/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3022 - acc: 0.4957 - val_loss: 2.4526 - val_acc: 0.2467\n",
      "Epoch 2026/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.3019 - acc: 0.4900 - val_loss: 2.4315 - val_acc: 0.2433\n",
      "Epoch 2027/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3022 - acc: 0.5000 - val_loss: 2.4377 - val_acc: 0.2367\n",
      "Epoch 2028/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3016 - acc: 0.4943 - val_loss: 2.4638 - val_acc: 0.2500\n",
      "Epoch 2029/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3010 - acc: 0.5000 - val_loss: 2.4381 - val_acc: 0.2433\n",
      "Epoch 2030/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.3012 - acc: 0.5000 - val_loss: 2.4651 - val_acc: 0.2467\n",
      "Epoch 2031/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3014 - acc: 0.4900 - val_loss: 2.4420 - val_acc: 0.2400\n",
      "Epoch 2032/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3021 - acc: 0.4929 - val_loss: 2.4413 - val_acc: 0.2467\n",
      "Epoch 2033/3000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.3016 - acc: 0.4929 - val_loss: 2.4542 - val_acc: 0.2467\n",
      "Epoch 2034/3000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.3022 - acc: 0.4829 - val_loss: 2.4316 - val_acc: 0.2467\n",
      "Epoch 2035/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.3012 - acc: 0.4914 - val_loss: 2.4301 - val_acc: 0.2400\n",
      "Epoch 2036/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3020 - acc: 0.4900 - val_loss: 2.4398 - val_acc: 0.2433\n",
      "Epoch 2037/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3001 - acc: 0.4929 - val_loss: 2.4433 - val_acc: 0.2467\n",
      "Epoch 2038/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3011 - acc: 0.4900 - val_loss: 2.4415 - val_acc: 0.2433\n",
      "Epoch 2039/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.3019 - acc: 0.4943 - val_loss: 2.4732 - val_acc: 0.2500\n",
      "Epoch 2040/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.3015 - acc: 0.4929 - val_loss: 2.4580 - val_acc: 0.2467\n",
      "Epoch 2041/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3006 - acc: 0.4943 - val_loss: 2.4611 - val_acc: 0.2467\n",
      "Epoch 2042/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3012 - acc: 0.4943 - val_loss: 2.4740 - val_acc: 0.2500\n",
      "Epoch 2043/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.3005 - acc: 0.4900 - val_loss: 2.4691 - val_acc: 0.2467\n",
      "Epoch 2044/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.3014 - acc: 0.4929 - val_loss: 2.4535 - val_acc: 0.2467\n",
      "Epoch 2045/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3013 - acc: 0.4957 - val_loss: 2.4759 - val_acc: 0.2433\n",
      "Epoch 2046/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3009 - acc: 0.4943 - val_loss: 2.4325 - val_acc: 0.2400\n",
      "Epoch 2047/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3002 - acc: 0.4957 - val_loss: 2.4508 - val_acc: 0.2500\n",
      "Epoch 2048/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3002 - acc: 0.4971 - val_loss: 2.4344 - val_acc: 0.2500\n",
      "Epoch 2049/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.3024 - acc: 0.4929 - val_loss: 2.4680 - val_acc: 0.2467\n",
      "Epoch 2050/3000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3007 - acc: 0.4914 - val_loss: 2.4671 - val_acc: 0.2433\n",
      "Epoch 2051/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3010 - acc: 0.4900 - val_loss: 2.4500 - val_acc: 0.2400\n",
      "Epoch 2052/3000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.3012 - acc: 0.4957 - val_loss: 2.4425 - val_acc: 0.2467\n",
      "Epoch 2053/3000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.3006 - acc: 0.4886 - val_loss: 2.4436 - val_acc: 0.2400\n",
      "Epoch 2054/3000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.3002 - acc: 0.4914 - val_loss: 2.4484 - val_acc: 0.2467\n",
      "Epoch 2055/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3013 - acc: 0.4929 - val_loss: 2.4460 - val_acc: 0.2433\n",
      "Epoch 2056/3000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.2996 - acc: 0.5000 - val_loss: 2.4650 - val_acc: 0.2467\n",
      "Epoch 2057/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.3008 - acc: 0.4914 - val_loss: 2.4569 - val_acc: 0.2433\n",
      "Epoch 2058/3000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.2993 - acc: 0.4957 - val_loss: 2.4703 - val_acc: 0.2467\n",
      "Epoch 2059/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.3001 - acc: 0.4943 - val_loss: 2.4543 - val_acc: 0.2467\n",
      "Epoch 2060/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3001 - acc: 0.4929 - val_loss: 2.4565 - val_acc: 0.2467\n",
      "Epoch 2061/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2998 - acc: 0.4929 - val_loss: 2.4545 - val_acc: 0.2500\n",
      "Epoch 2062/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.3001 - acc: 0.4943 - val_loss: 2.4605 - val_acc: 0.2467\n",
      "Epoch 2063/3000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 1.2997 - acc: 0.4900 - val_loss: 2.4583 - val_acc: 0.2433\n",
      "Epoch 2064/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.2997 - acc: 0.4943 - val_loss: 2.4595 - val_acc: 0.2467\n",
      "Epoch 2065/3000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.2998 - acc: 0.4914 - val_loss: 2.4678 - val_acc: 0.2467\n",
      "Epoch 2066/3000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 1.2999 - acc: 0.4957 - val_loss: 2.4652 - val_acc: 0.2400\n",
      "Epoch 2067/3000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.2997 - acc: 0.4900 - val_loss: 2.4582 - val_acc: 0.2400\n",
      "Epoch 2068/3000\n",
      "700/700 [==============================] - 0s 191us/step - loss: 1.2994 - acc: 0.4943 - val_loss: 2.4501 - val_acc: 0.2433\n",
      "Epoch 2069/3000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 1.2991 - acc: 0.4986 - val_loss: 2.4978 - val_acc: 0.2467\n",
      "Epoch 2070/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.2998 - acc: 0.4900 - val_loss: 2.4582 - val_acc: 0.2433\n",
      "Epoch 2071/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.2996 - acc: 0.4929 - val_loss: 2.4710 - val_acc: 0.2467\n",
      "Epoch 2072/3000\n",
      "700/700 [==============================] - 0s 159us/step - loss: 1.2994 - acc: 0.4929 - val_loss: 2.4753 - val_acc: 0.2433\n",
      "Epoch 2073/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.2996 - acc: 0.4871 - val_loss: 2.4653 - val_acc: 0.2500\n",
      "Epoch 2074/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.2992 - acc: 0.4957 - val_loss: 2.4389 - val_acc: 0.2400\n",
      "Epoch 2075/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.2995 - acc: 0.4914 - val_loss: 2.4485 - val_acc: 0.2467\n",
      "Epoch 2076/3000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.2992 - acc: 0.4871 - val_loss: 2.4531 - val_acc: 0.2433\n",
      "Epoch 2077/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.2989 - acc: 0.4943 - val_loss: 2.4680 - val_acc: 0.2500\n",
      "Epoch 2078/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2988 - acc: 0.4929 - val_loss: 2.4593 - val_acc: 0.2467\n",
      "Epoch 2079/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2988 - acc: 0.4943 - val_loss: 2.4759 - val_acc: 0.2433\n",
      "Epoch 2080/3000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.2990 - acc: 0.4971 - val_loss: 2.4728 - val_acc: 0.2433\n",
      "Epoch 2081/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.2996 - acc: 0.4886 - val_loss: 2.4845 - val_acc: 0.2433\n",
      "Epoch 2082/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2990 - acc: 0.4886 - val_loss: 2.4381 - val_acc: 0.2400\n",
      "Epoch 2083/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2994 - acc: 0.4971 - val_loss: 2.4562 - val_acc: 0.2467\n",
      "Epoch 2084/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2980 - acc: 0.4943 - val_loss: 2.4477 - val_acc: 0.2533\n",
      "Epoch 2085/3000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.2986 - acc: 0.4929 - val_loss: 2.4384 - val_acc: 0.2433\n",
      "Epoch 2086/3000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.2983 - acc: 0.4929 - val_loss: 2.4549 - val_acc: 0.2500\n",
      "Epoch 2087/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2987 - acc: 0.5000 - val_loss: 2.4869 - val_acc: 0.2500\n",
      "Epoch 2088/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2992 - acc: 0.4914 - val_loss: 2.4635 - val_acc: 0.2433\n",
      "Epoch 2089/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2990 - acc: 0.4900 - val_loss: 2.4658 - val_acc: 0.2467\n",
      "Epoch 2090/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2980 - acc: 0.4957 - val_loss: 2.4922 - val_acc: 0.2433\n",
      "Epoch 2091/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2982 - acc: 0.4929 - val_loss: 2.4613 - val_acc: 0.2467\n",
      "Epoch 2092/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2982 - acc: 0.4957 - val_loss: 2.4785 - val_acc: 0.2467\n",
      "Epoch 2093/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2984 - acc: 0.4871 - val_loss: 2.4696 - val_acc: 0.2467\n",
      "Epoch 2094/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2986 - acc: 0.4943 - val_loss: 2.4770 - val_acc: 0.2467\n",
      "Epoch 2095/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.2974 - acc: 0.4957 - val_loss: 2.4879 - val_acc: 0.2467\n",
      "Epoch 2096/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2981 - acc: 0.4914 - val_loss: 2.4695 - val_acc: 0.2467\n",
      "Epoch 2097/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2973 - acc: 0.4914 - val_loss: 2.4601 - val_acc: 0.2500\n",
      "Epoch 2098/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2971 - acc: 0.4929 - val_loss: 2.4502 - val_acc: 0.2433\n",
      "Epoch 2099/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2983 - acc: 0.4929 - val_loss: 2.4653 - val_acc: 0.2433\n",
      "Epoch 2100/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2977 - acc: 0.4957 - val_loss: 2.4570 - val_acc: 0.2400\n",
      "Epoch 2101/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2982 - acc: 0.5000 - val_loss: 2.4819 - val_acc: 0.2467\n",
      "Epoch 2102/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2985 - acc: 0.4971 - val_loss: 2.4694 - val_acc: 0.2433\n",
      "Epoch 2103/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2975 - acc: 0.4957 - val_loss: 2.4752 - val_acc: 0.2467\n",
      "Epoch 2104/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2976 - acc: 0.4957 - val_loss: 2.4504 - val_acc: 0.2433\n",
      "Epoch 2105/3000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.2966 - acc: 0.4900 - val_loss: 2.4690 - val_acc: 0.2500\n",
      "Epoch 2106/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2982 - acc: 0.4957 - val_loss: 2.4469 - val_acc: 0.2467\n",
      "Epoch 2107/3000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.2975 - acc: 0.4900 - val_loss: 2.4571 - val_acc: 0.2467\n",
      "Epoch 2108/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.2979 - acc: 0.4943 - val_loss: 2.4703 - val_acc: 0.2467\n",
      "Epoch 2109/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.2978 - acc: 0.4943 - val_loss: 2.4679 - val_acc: 0.2500\n",
      "Epoch 2110/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2981 - acc: 0.4957 - val_loss: 2.4598 - val_acc: 0.2433\n",
      "Epoch 2111/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2982 - acc: 0.4914 - val_loss: 2.4732 - val_acc: 0.2467\n",
      "Epoch 2112/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2969 - acc: 0.4900 - val_loss: 2.4870 - val_acc: 0.2467\n",
      "Epoch 2113/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.2975 - acc: 0.4943 - val_loss: 2.4681 - val_acc: 0.2467\n",
      "Epoch 2114/3000\n",
      "700/700 [==============================] - 0s 178us/step - loss: 1.2965 - acc: 0.4943 - val_loss: 2.4582 - val_acc: 0.2433\n",
      "Epoch 2115/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2971 - acc: 0.4943 - val_loss: 2.4838 - val_acc: 0.2433\n",
      "Epoch 2116/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.2976 - acc: 0.4957 - val_loss: 2.4714 - val_acc: 0.2467\n",
      "Epoch 2117/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2973 - acc: 0.4943 - val_loss: 2.4868 - val_acc: 0.2467\n",
      "Epoch 2118/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2965 - acc: 0.4943 - val_loss: 2.4680 - val_acc: 0.2467\n",
      "Epoch 2119/3000\n",
      "700/700 [==============================] - 0s 159us/step - loss: 1.2969 - acc: 0.4914 - val_loss: 2.4704 - val_acc: 0.2433\n",
      "Epoch 2120/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.2966 - acc: 0.4971 - val_loss: 2.4745 - val_acc: 0.2467\n",
      "Epoch 2121/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2965 - acc: 0.4957 - val_loss: 2.4951 - val_acc: 0.2400\n",
      "Epoch 2122/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2970 - acc: 0.5000 - val_loss: 2.4841 - val_acc: 0.2433\n",
      "Epoch 2123/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2963 - acc: 0.5000 - val_loss: 2.4582 - val_acc: 0.2467\n",
      "Epoch 2124/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2968 - acc: 0.4971 - val_loss: 2.4662 - val_acc: 0.2467\n",
      "Epoch 2125/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2961 - acc: 0.4986 - val_loss: 2.4707 - val_acc: 0.2433\n",
      "Epoch 2126/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2966 - acc: 0.4957 - val_loss: 2.4710 - val_acc: 0.2500\n",
      "Epoch 2127/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2966 - acc: 0.4929 - val_loss: 2.4647 - val_acc: 0.2467\n",
      "Epoch 2128/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2966 - acc: 0.4943 - val_loss: 2.4849 - val_acc: 0.2433\n",
      "Epoch 2129/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2965 - acc: 0.4871 - val_loss: 2.4494 - val_acc: 0.2467\n",
      "Epoch 2130/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2962 - acc: 0.5000 - val_loss: 2.4732 - val_acc: 0.2433\n",
      "Epoch 2131/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.2964 - acc: 0.4914 - val_loss: 2.4678 - val_acc: 0.2467\n",
      "Epoch 2132/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.2969 - acc: 0.4914 - val_loss: 2.4846 - val_acc: 0.2400\n",
      "Epoch 2133/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.2959 - acc: 0.4943 - val_loss: 2.4765 - val_acc: 0.2500\n",
      "Epoch 2134/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2961 - acc: 0.4957 - val_loss: 2.4712 - val_acc: 0.2467\n",
      "Epoch 2135/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2957 - acc: 0.4943 - val_loss: 2.4753 - val_acc: 0.2467\n",
      "Epoch 2136/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2963 - acc: 0.4943 - val_loss: 2.4403 - val_acc: 0.2433\n",
      "Epoch 2137/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 93us/step - loss: 1.2958 - acc: 0.4929 - val_loss: 2.4792 - val_acc: 0.2433\n",
      "Epoch 2138/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.2971 - acc: 0.4914 - val_loss: 2.4830 - val_acc: 0.2467\n",
      "Epoch 2139/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2960 - acc: 0.5000 - val_loss: 2.4665 - val_acc: 0.2433\n",
      "Epoch 2140/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2956 - acc: 0.4929 - val_loss: 2.4804 - val_acc: 0.2467\n",
      "Epoch 2141/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2966 - acc: 0.4943 - val_loss: 2.4785 - val_acc: 0.2467\n",
      "Epoch 2142/3000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 1.2956 - acc: 0.4943 - val_loss: 2.4721 - val_acc: 0.2433\n",
      "Epoch 2143/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.2961 - acc: 0.4914 - val_loss: 2.4902 - val_acc: 0.2433\n",
      "Epoch 2144/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2957 - acc: 0.4957 - val_loss: 2.4766 - val_acc: 0.2467\n",
      "Epoch 2145/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2950 - acc: 0.4914 - val_loss: 2.4620 - val_acc: 0.2500\n",
      "Epoch 2146/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2946 - acc: 0.4943 - val_loss: 2.4430 - val_acc: 0.2467\n",
      "Epoch 2147/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2954 - acc: 0.4986 - val_loss: 2.4797 - val_acc: 0.2467\n",
      "Epoch 2148/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2961 - acc: 0.4843 - val_loss: 2.4747 - val_acc: 0.2500\n",
      "Epoch 2149/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2946 - acc: 0.4986 - val_loss: 2.4497 - val_acc: 0.2467\n",
      "Epoch 2150/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2951 - acc: 0.4943 - val_loss: 2.4614 - val_acc: 0.2533\n",
      "Epoch 2151/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2953 - acc: 0.4943 - val_loss: 2.4944 - val_acc: 0.2367\n",
      "Epoch 2152/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2949 - acc: 0.4929 - val_loss: 2.4821 - val_acc: 0.2467\n",
      "Epoch 2153/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2950 - acc: 0.4957 - val_loss: 2.4751 - val_acc: 0.2467\n",
      "Epoch 2154/3000\n",
      "700/700 [==============================] - 0s 186us/step - loss: 1.2950 - acc: 0.4957 - val_loss: 2.4999 - val_acc: 0.2367\n",
      "Epoch 2155/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.2951 - acc: 0.4986 - val_loss: 2.4974 - val_acc: 0.2433\n",
      "Epoch 2156/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2944 - acc: 0.4986 - val_loss: 2.5011 - val_acc: 0.2433\n",
      "Epoch 2157/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2947 - acc: 0.4914 - val_loss: 2.4521 - val_acc: 0.2467\n",
      "Epoch 2158/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.2944 - acc: 0.5014 - val_loss: 2.5038 - val_acc: 0.2433\n",
      "Epoch 2159/3000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.2943 - acc: 0.4971 - val_loss: 2.4653 - val_acc: 0.2467\n",
      "Epoch 2160/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.2948 - acc: 0.4971 - val_loss: 2.4962 - val_acc: 0.2467\n",
      "Epoch 2161/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2951 - acc: 0.5029 - val_loss: 2.4786 - val_acc: 0.2467\n",
      "Epoch 2162/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2941 - acc: 0.4914 - val_loss: 2.4732 - val_acc: 0.2433\n",
      "Epoch 2163/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2947 - acc: 0.4900 - val_loss: 2.4641 - val_acc: 0.2467\n",
      "Epoch 2164/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2956 - acc: 0.4986 - val_loss: 2.4844 - val_acc: 0.2433\n",
      "Epoch 2165/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2943 - acc: 0.4914 - val_loss: 2.4731 - val_acc: 0.2500\n",
      "Epoch 2166/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2947 - acc: 0.4986 - val_loss: 2.4778 - val_acc: 0.2467\n",
      "Epoch 2167/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2943 - acc: 0.4929 - val_loss: 2.4759 - val_acc: 0.2467\n",
      "Epoch 2168/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2946 - acc: 0.4971 - val_loss: 2.4859 - val_acc: 0.2433\n",
      "Epoch 2169/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2941 - acc: 0.4957 - val_loss: 2.4881 - val_acc: 0.2500\n",
      "Epoch 2170/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.2940 - acc: 0.5043 - val_loss: 2.4893 - val_acc: 0.2433\n",
      "Epoch 2171/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2937 - acc: 0.4986 - val_loss: 2.4630 - val_acc: 0.2533\n",
      "Epoch 2172/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2939 - acc: 0.4957 - val_loss: 2.4976 - val_acc: 0.2467\n",
      "Epoch 2173/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2931 - acc: 0.4957 - val_loss: 2.4869 - val_acc: 0.2467\n",
      "Epoch 2174/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2938 - acc: 0.5014 - val_loss: 2.4822 - val_acc: 0.2400\n",
      "Epoch 2175/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2933 - acc: 0.4914 - val_loss: 2.4572 - val_acc: 0.2500\n",
      "Epoch 2176/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.2936 - acc: 0.4986 - val_loss: 2.4581 - val_acc: 0.2500\n",
      "Epoch 2177/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2939 - acc: 0.4943 - val_loss: 2.4846 - val_acc: 0.2533\n",
      "Epoch 2178/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2937 - acc: 0.4957 - val_loss: 2.4847 - val_acc: 0.2467\n",
      "Epoch 2179/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2930 - acc: 0.4971 - val_loss: 2.4779 - val_acc: 0.2467\n",
      "Epoch 2180/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2948 - acc: 0.4943 - val_loss: 2.4781 - val_acc: 0.2467\n",
      "Epoch 2181/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2933 - acc: 0.4986 - val_loss: 2.4771 - val_acc: 0.2400\n",
      "Epoch 2182/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2937 - acc: 0.4957 - val_loss: 2.4918 - val_acc: 0.2433\n",
      "Epoch 2183/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2931 - acc: 0.5000 - val_loss: 2.5078 - val_acc: 0.2433\n",
      "Epoch 2184/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2938 - acc: 0.4986 - val_loss: 2.4790 - val_acc: 0.2433\n",
      "Epoch 2185/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2927 - acc: 0.4929 - val_loss: 2.4786 - val_acc: 0.2433\n",
      "Epoch 2186/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2940 - acc: 0.4986 - val_loss: 2.4900 - val_acc: 0.2533\n",
      "Epoch 2187/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2931 - acc: 0.5000 - val_loss: 2.4726 - val_acc: 0.2467\n",
      "Epoch 2188/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2933 - acc: 0.5000 - val_loss: 2.5012 - val_acc: 0.2433\n",
      "Epoch 2189/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2931 - acc: 0.4929 - val_loss: 2.5124 - val_acc: 0.2433\n",
      "Epoch 2190/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2929 - acc: 0.4957 - val_loss: 2.4900 - val_acc: 0.2433\n",
      "Epoch 2191/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.2925 - acc: 0.4929 - val_loss: 2.4925 - val_acc: 0.2400\n",
      "Epoch 2192/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2927 - acc: 0.4957 - val_loss: 2.4698 - val_acc: 0.2400\n",
      "Epoch 2193/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2926 - acc: 0.4971 - val_loss: 2.4851 - val_acc: 0.2367\n",
      "Epoch 2194/3000\n",
      "700/700 [==============================] - 0s 175us/step - loss: 1.2932 - acc: 0.4971 - val_loss: 2.4971 - val_acc: 0.2433\n",
      "Epoch 2195/3000\n",
      "700/700 [==============================] - 0s 159us/step - loss: 1.2923 - acc: 0.4957 - val_loss: 2.4902 - val_acc: 0.2433\n",
      "Epoch 2196/3000\n",
      "700/700 [==============================] - 0s 195us/step - loss: 1.2929 - acc: 0.4986 - val_loss: 2.4964 - val_acc: 0.2433\n",
      "Epoch 2197/3000\n",
      "700/700 [==============================] - 0s 159us/step - loss: 1.2926 - acc: 0.4986 - val_loss: 2.4943 - val_acc: 0.2500\n",
      "Epoch 2198/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2926 - acc: 0.4943 - val_loss: 2.4800 - val_acc: 0.2433\n",
      "Epoch 2199/3000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.2931 - acc: 0.5014 - val_loss: 2.5008 - val_acc: 0.2433\n",
      "Epoch 2200/3000\n",
      "700/700 [==============================] - 0s 192us/step - loss: 1.2932 - acc: 0.4986 - val_loss: 2.4824 - val_acc: 0.2400\n",
      "Epoch 2201/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.2921 - acc: 0.4957 - val_loss: 2.5112 - val_acc: 0.2500\n",
      "Epoch 2202/3000\n",
      "700/700 [==============================] - 0s 209us/step - loss: 1.2905 - acc: 0.4986 - val_loss: 2.4925 - val_acc: 0.2467\n",
      "Epoch 2203/3000\n",
      "700/700 [==============================] - 0s 235us/step - loss: 1.2926 - acc: 0.4929 - val_loss: 2.4953 - val_acc: 0.2433\n",
      "Epoch 2204/3000\n",
      "700/700 [==============================] - 0s 215us/step - loss: 1.2917 - acc: 0.4971 - val_loss: 2.4669 - val_acc: 0.2400\n",
      "Epoch 2205/3000\n",
      "700/700 [==============================] - 0s 188us/step - loss: 1.2916 - acc: 0.4971 - val_loss: 2.5012 - val_acc: 0.2433\n",
      "Epoch 2206/3000\n",
      "700/700 [==============================] - 0s 185us/step - loss: 1.2924 - acc: 0.4943 - val_loss: 2.4834 - val_acc: 0.2467\n",
      "Epoch 2207/3000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 1.2919 - acc: 0.4957 - val_loss: 2.5011 - val_acc: 0.2433\n",
      "Epoch 2208/3000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.2917 - acc: 0.5029 - val_loss: 2.4655 - val_acc: 0.2433\n",
      "Epoch 2209/3000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.2913 - acc: 0.4943 - val_loss: 2.4558 - val_acc: 0.2533\n",
      "Epoch 2210/3000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.2920 - acc: 0.4929 - val_loss: 2.4874 - val_acc: 0.2433\n",
      "Epoch 2211/3000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.2916 - acc: 0.4929 - val_loss: 2.4916 - val_acc: 0.2500\n",
      "Epoch 2212/3000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.2914 - acc: 0.4986 - val_loss: 2.5056 - val_acc: 0.2500\n",
      "Epoch 2213/3000\n",
      "700/700 [==============================] - 0s 182us/step - loss: 1.2914 - acc: 0.4943 - val_loss: 2.4824 - val_acc: 0.2367\n",
      "Epoch 2214/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2905 - acc: 0.5000 - val_loss: 2.4963 - val_acc: 0.2433\n",
      "Epoch 2215/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.2915 - acc: 0.4986 - val_loss: 2.4801 - val_acc: 0.2433\n",
      "Epoch 2216/3000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 1.2920 - acc: 0.4943 - val_loss: 2.4794 - val_acc: 0.2433\n",
      "Epoch 2217/3000\n",
      "700/700 [==============================] - 0s 163us/step - loss: 1.2911 - acc: 0.4957 - val_loss: 2.4924 - val_acc: 0.2467\n",
      "Epoch 2218/3000\n",
      "700/700 [==============================] - 0s 189us/step - loss: 1.2909 - acc: 0.5057 - val_loss: 2.5001 - val_acc: 0.2367\n",
      "Epoch 2219/3000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.2915 - acc: 0.4971 - val_loss: 2.4863 - val_acc: 0.2433\n",
      "Epoch 2220/3000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.2902 - acc: 0.5000 - val_loss: 2.4791 - val_acc: 0.2467\n",
      "Epoch 2221/3000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.2906 - acc: 0.5029 - val_loss: 2.4838 - val_acc: 0.2533\n",
      "Epoch 2222/3000\n",
      "700/700 [==============================] - 0s 183us/step - loss: 1.2925 - acc: 0.4971 - val_loss: 2.4805 - val_acc: 0.2467\n",
      "Epoch 2223/3000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.2910 - acc: 0.4957 - val_loss: 2.4994 - val_acc: 0.2467\n",
      "Epoch 2224/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2907 - acc: 0.4929 - val_loss: 2.4961 - val_acc: 0.2533\n",
      "Epoch 2225/3000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 1.2901 - acc: 0.4986 - val_loss: 2.4869 - val_acc: 0.2500\n",
      "Epoch 2226/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.2905 - acc: 0.5000 - val_loss: 2.5068 - val_acc: 0.2433\n",
      "Epoch 2227/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.2905 - acc: 0.5000 - val_loss: 2.4848 - val_acc: 0.2433\n",
      "Epoch 2228/3000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.2907 - acc: 0.4943 - val_loss: 2.4964 - val_acc: 0.2500\n",
      "Epoch 2229/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2904 - acc: 0.5014 - val_loss: 2.4649 - val_acc: 0.2400\n",
      "Epoch 2230/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2907 - acc: 0.5029 - val_loss: 2.4854 - val_acc: 0.2433\n",
      "Epoch 2231/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2900 - acc: 0.4971 - val_loss: 2.4839 - val_acc: 0.2500\n",
      "Epoch 2232/3000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.2905 - acc: 0.4914 - val_loss: 2.4953 - val_acc: 0.2433\n",
      "Epoch 2233/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2904 - acc: 0.4929 - val_loss: 2.4960 - val_acc: 0.2500\n",
      "Epoch 2234/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2905 - acc: 0.4971 - val_loss: 2.4745 - val_acc: 0.2433\n",
      "Epoch 2235/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2900 - acc: 0.5000 - val_loss: 2.4842 - val_acc: 0.2467\n",
      "Epoch 2236/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.2898 - acc: 0.4971 - val_loss: 2.4752 - val_acc: 0.2433\n",
      "Epoch 2237/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2900 - acc: 0.4971 - val_loss: 2.5177 - val_acc: 0.2400\n",
      "Epoch 2238/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2906 - acc: 0.5014 - val_loss: 2.5247 - val_acc: 0.2400\n",
      "Epoch 2239/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2894 - acc: 0.4943 - val_loss: 2.4843 - val_acc: 0.2533\n",
      "Epoch 2240/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2901 - acc: 0.5014 - val_loss: 2.5126 - val_acc: 0.2433\n",
      "Epoch 2241/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2904 - acc: 0.4957 - val_loss: 2.4821 - val_acc: 0.2433\n",
      "Epoch 2242/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2894 - acc: 0.4971 - val_loss: 2.4934 - val_acc: 0.2400\n",
      "Epoch 2243/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2898 - acc: 0.5000 - val_loss: 2.4901 - val_acc: 0.2467\n",
      "Epoch 2244/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2899 - acc: 0.4957 - val_loss: 2.4866 - val_acc: 0.2433\n",
      "Epoch 2245/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2889 - acc: 0.5014 - val_loss: 2.5213 - val_acc: 0.2367\n",
      "Epoch 2246/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2891 - acc: 0.5014 - val_loss: 2.4945 - val_acc: 0.2467\n",
      "Epoch 2247/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2893 - acc: 0.4971 - val_loss: 2.4902 - val_acc: 0.2467\n",
      "Epoch 2248/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2896 - acc: 0.4957 - val_loss: 2.5448 - val_acc: 0.2367\n",
      "Epoch 2249/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2902 - acc: 0.4986 - val_loss: 2.4909 - val_acc: 0.2467\n",
      "Epoch 2250/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2888 - acc: 0.4971 - val_loss: 2.4907 - val_acc: 0.2433\n",
      "Epoch 2251/3000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.2904 - acc: 0.4914 - val_loss: 2.4937 - val_acc: 0.2433\n",
      "Epoch 2252/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2890 - acc: 0.4943 - val_loss: 2.4801 - val_acc: 0.2400\n",
      "Epoch 2253/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2880 - acc: 0.4971 - val_loss: 2.5159 - val_acc: 0.2467\n",
      "Epoch 2254/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2897 - acc: 0.4971 - val_loss: 2.5076 - val_acc: 0.2500\n",
      "Epoch 2255/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 96us/step - loss: 1.2887 - acc: 0.5014 - val_loss: 2.5128 - val_acc: 0.2400\n",
      "Epoch 2256/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2893 - acc: 0.5000 - val_loss: 2.4934 - val_acc: 0.2400\n",
      "Epoch 2257/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2890 - acc: 0.5000 - val_loss: 2.5230 - val_acc: 0.2367\n",
      "Epoch 2258/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2888 - acc: 0.5029 - val_loss: 2.4637 - val_acc: 0.2400\n",
      "Epoch 2259/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2877 - acc: 0.5014 - val_loss: 2.5227 - val_acc: 0.2433\n",
      "Epoch 2260/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2887 - acc: 0.4986 - val_loss: 2.5075 - val_acc: 0.2500\n",
      "Epoch 2261/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2882 - acc: 0.4986 - val_loss: 2.4968 - val_acc: 0.2433\n",
      "Epoch 2262/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2887 - acc: 0.5057 - val_loss: 2.4871 - val_acc: 0.2433\n",
      "Epoch 2263/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2883 - acc: 0.4986 - val_loss: 2.5328 - val_acc: 0.2333\n",
      "Epoch 2264/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2886 - acc: 0.4957 - val_loss: 2.5164 - val_acc: 0.2400\n",
      "Epoch 2265/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2882 - acc: 0.4943 - val_loss: 2.5005 - val_acc: 0.2433\n",
      "Epoch 2266/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2882 - acc: 0.5029 - val_loss: 2.5237 - val_acc: 0.2400\n",
      "Epoch 2267/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2888 - acc: 0.4943 - val_loss: 2.4825 - val_acc: 0.2433\n",
      "Epoch 2268/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2882 - acc: 0.4986 - val_loss: 2.5064 - val_acc: 0.2400\n",
      "Epoch 2269/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2873 - acc: 0.5000 - val_loss: 2.5248 - val_acc: 0.2500\n",
      "Epoch 2270/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2886 - acc: 0.5029 - val_loss: 2.5005 - val_acc: 0.2533\n",
      "Epoch 2271/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2882 - acc: 0.4929 - val_loss: 2.5202 - val_acc: 0.2433\n",
      "Epoch 2272/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.2873 - acc: 0.4943 - val_loss: 2.5290 - val_acc: 0.2400\n",
      "Epoch 2273/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2881 - acc: 0.4971 - val_loss: 2.4947 - val_acc: 0.2433\n",
      "Epoch 2274/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2883 - acc: 0.4943 - val_loss: 2.5103 - val_acc: 0.2533\n",
      "Epoch 2275/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2875 - acc: 0.5057 - val_loss: 2.5080 - val_acc: 0.2433\n",
      "Epoch 2276/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2885 - acc: 0.4986 - val_loss: 2.5006 - val_acc: 0.2500\n",
      "Epoch 2277/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2881 - acc: 0.4957 - val_loss: 2.5074 - val_acc: 0.2400\n",
      "Epoch 2278/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2874 - acc: 0.4914 - val_loss: 2.5045 - val_acc: 0.2467\n",
      "Epoch 2279/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2876 - acc: 0.4971 - val_loss: 2.5066 - val_acc: 0.2433\n",
      "Epoch 2280/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2872 - acc: 0.4943 - val_loss: 2.5212 - val_acc: 0.2367\n",
      "Epoch 2281/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2859 - acc: 0.4986 - val_loss: 2.5105 - val_acc: 0.2500\n",
      "Epoch 2282/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.2873 - acc: 0.4943 - val_loss: 2.5063 - val_acc: 0.2467\n",
      "Epoch 2283/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2866 - acc: 0.4943 - val_loss: 2.4704 - val_acc: 0.2500\n",
      "Epoch 2284/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2884 - acc: 0.5014 - val_loss: 2.4993 - val_acc: 0.2533\n",
      "Epoch 2285/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2886 - acc: 0.4943 - val_loss: 2.5190 - val_acc: 0.2400\n",
      "Epoch 2286/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2871 - acc: 0.4971 - val_loss: 2.5107 - val_acc: 0.2433\n",
      "Epoch 2287/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2875 - acc: 0.5000 - val_loss: 2.4919 - val_acc: 0.2367\n",
      "Epoch 2288/3000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.2874 - acc: 0.5029 - val_loss: 2.4992 - val_acc: 0.2433\n",
      "Epoch 2289/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2875 - acc: 0.5000 - val_loss: 2.5246 - val_acc: 0.2400\n",
      "Epoch 2290/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2873 - acc: 0.4914 - val_loss: 2.5087 - val_acc: 0.2400\n",
      "Epoch 2291/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2873 - acc: 0.4986 - val_loss: 2.5101 - val_acc: 0.2467\n",
      "Epoch 2292/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2862 - acc: 0.5000 - val_loss: 2.5143 - val_acc: 0.2367\n",
      "Epoch 2293/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2866 - acc: 0.5014 - val_loss: 2.5084 - val_acc: 0.2433\n",
      "Epoch 2294/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2868 - acc: 0.5029 - val_loss: 2.5195 - val_acc: 0.2500\n",
      "Epoch 2295/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2872 - acc: 0.4900 - val_loss: 2.5131 - val_acc: 0.2400\n",
      "Epoch 2296/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2868 - acc: 0.4971 - val_loss: 2.4975 - val_acc: 0.2500\n",
      "Epoch 2297/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.2860 - acc: 0.4957 - val_loss: 2.5134 - val_acc: 0.2433\n",
      "Epoch 2298/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2861 - acc: 0.5014 - val_loss: 2.5295 - val_acc: 0.2467\n",
      "Epoch 2299/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2869 - acc: 0.5057 - val_loss: 2.5216 - val_acc: 0.2500\n",
      "Epoch 2300/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2861 - acc: 0.5000 - val_loss: 2.5038 - val_acc: 0.2400\n",
      "Epoch 2301/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2873 - acc: 0.4943 - val_loss: 2.5061 - val_acc: 0.2433\n",
      "Epoch 2302/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2861 - acc: 0.4986 - val_loss: 2.5335 - val_acc: 0.2433\n",
      "Epoch 2303/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2862 - acc: 0.4971 - val_loss: 2.4964 - val_acc: 0.2367\n",
      "Epoch 2304/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2866 - acc: 0.5000 - val_loss: 2.5151 - val_acc: 0.2533\n",
      "Epoch 2305/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2859 - acc: 0.4943 - val_loss: 2.5576 - val_acc: 0.2433\n",
      "Epoch 2306/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2869 - acc: 0.5000 - val_loss: 2.4711 - val_acc: 0.2400\n",
      "Epoch 2307/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2864 - acc: 0.5014 - val_loss: 2.5010 - val_acc: 0.2433\n",
      "Epoch 2308/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2860 - acc: 0.5014 - val_loss: 2.4972 - val_acc: 0.2500\n",
      "Epoch 2309/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2861 - acc: 0.4943 - val_loss: 2.5269 - val_acc: 0.2467\n",
      "Epoch 2310/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2855 - acc: 0.4986 - val_loss: 2.5213 - val_acc: 0.2400\n",
      "Epoch 2311/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2858 - acc: 0.4900 - val_loss: 2.5092 - val_acc: 0.2433\n",
      "Epoch 2312/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2854 - acc: 0.4986 - val_loss: 2.5304 - val_acc: 0.2400\n",
      "Epoch 2313/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2855 - acc: 0.4957 - val_loss: 2.4958 - val_acc: 0.2467\n",
      "Epoch 2314/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2861 - acc: 0.4986 - val_loss: 2.5172 - val_acc: 0.2433\n",
      "Epoch 2315/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2858 - acc: 0.5029 - val_loss: 2.5058 - val_acc: 0.2433\n",
      "Epoch 2316/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2853 - acc: 0.4914 - val_loss: 2.5363 - val_acc: 0.2400\n",
      "Epoch 2317/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2840 - acc: 0.5000 - val_loss: 2.5217 - val_acc: 0.2500\n",
      "Epoch 2318/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2856 - acc: 0.4986 - val_loss: 2.5164 - val_acc: 0.2433\n",
      "Epoch 2319/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2860 - acc: 0.4986 - val_loss: 2.5227 - val_acc: 0.2400\n",
      "Epoch 2320/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2853 - acc: 0.4971 - val_loss: 2.5110 - val_acc: 0.2500\n",
      "Epoch 2321/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2854 - acc: 0.5014 - val_loss: 2.5203 - val_acc: 0.2400\n",
      "Epoch 2322/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2852 - acc: 0.4986 - val_loss: 2.5204 - val_acc: 0.2400\n",
      "Epoch 2323/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2845 - acc: 0.4986 - val_loss: 2.4983 - val_acc: 0.2500\n",
      "Epoch 2324/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2851 - acc: 0.5086 - val_loss: 2.5265 - val_acc: 0.2467\n",
      "Epoch 2325/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2854 - acc: 0.4957 - val_loss: 2.5059 - val_acc: 0.2433\n",
      "Epoch 2326/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2853 - acc: 0.5000 - val_loss: 2.5192 - val_acc: 0.2433\n",
      "Epoch 2327/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2852 - acc: 0.5057 - val_loss: 2.5081 - val_acc: 0.2367\n",
      "Epoch 2328/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2851 - acc: 0.4971 - val_loss: 2.5353 - val_acc: 0.2367\n",
      "Epoch 2329/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2854 - acc: 0.4986 - val_loss: 2.5371 - val_acc: 0.2333\n",
      "Epoch 2330/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2848 - acc: 0.5014 - val_loss: 2.5385 - val_acc: 0.2433\n",
      "Epoch 2331/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2842 - acc: 0.4986 - val_loss: 2.5186 - val_acc: 0.2500\n",
      "Epoch 2332/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2855 - acc: 0.4971 - val_loss: 2.5209 - val_acc: 0.2500\n",
      "Epoch 2333/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2847 - acc: 0.5014 - val_loss: 2.5250 - val_acc: 0.2400\n",
      "Epoch 2334/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2847 - acc: 0.4971 - val_loss: 2.5182 - val_acc: 0.2467\n",
      "Epoch 2335/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2837 - acc: 0.5029 - val_loss: 2.5220 - val_acc: 0.2367\n",
      "Epoch 2336/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2845 - acc: 0.4957 - val_loss: 2.5468 - val_acc: 0.2433\n",
      "Epoch 2337/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2861 - acc: 0.4971 - val_loss: 2.5281 - val_acc: 0.2433\n",
      "Epoch 2338/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2846 - acc: 0.5000 - val_loss: 2.5281 - val_acc: 0.2467\n",
      "Epoch 2339/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2841 - acc: 0.4929 - val_loss: 2.5326 - val_acc: 0.2433\n",
      "Epoch 2340/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2838 - acc: 0.5014 - val_loss: 2.5489 - val_acc: 0.2467\n",
      "Epoch 2341/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2843 - acc: 0.4929 - val_loss: 2.5267 - val_acc: 0.2500\n",
      "Epoch 2342/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2841 - acc: 0.4986 - val_loss: 2.5211 - val_acc: 0.2533\n",
      "Epoch 2343/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2840 - acc: 0.5029 - val_loss: 2.5290 - val_acc: 0.2500\n",
      "Epoch 2344/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2838 - acc: 0.4943 - val_loss: 2.5193 - val_acc: 0.2500\n",
      "Epoch 2345/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2840 - acc: 0.5043 - val_loss: 2.5268 - val_acc: 0.2500\n",
      "Epoch 2346/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2840 - acc: 0.5014 - val_loss: 2.5220 - val_acc: 0.2500\n",
      "Epoch 2347/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2843 - acc: 0.5014 - val_loss: 2.5230 - val_acc: 0.2467\n",
      "Epoch 2348/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2833 - acc: 0.5029 - val_loss: 2.5052 - val_acc: 0.2433\n",
      "Epoch 2349/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2830 - acc: 0.4943 - val_loss: 2.5253 - val_acc: 0.2500\n",
      "Epoch 2350/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2831 - acc: 0.4957 - val_loss: 2.5350 - val_acc: 0.2533\n",
      "Epoch 2351/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2836 - acc: 0.4986 - val_loss: 2.5305 - val_acc: 0.2433\n",
      "Epoch 2352/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2845 - acc: 0.4957 - val_loss: 2.5381 - val_acc: 0.2467\n",
      "Epoch 2353/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2830 - acc: 0.5043 - val_loss: 2.5168 - val_acc: 0.2467\n",
      "Epoch 2354/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.2834 - acc: 0.4971 - val_loss: 2.5366 - val_acc: 0.2300\n",
      "Epoch 2355/3000\n",
      "700/700 [==============================] - 0s 212us/step - loss: 1.2831 - acc: 0.4986 - val_loss: 2.5367 - val_acc: 0.2367\n",
      "Epoch 2356/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2826 - acc: 0.4957 - val_loss: 2.5194 - val_acc: 0.2433\n",
      "Epoch 2357/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2836 - acc: 0.4957 - val_loss: 2.5052 - val_acc: 0.2400\n",
      "Epoch 2358/3000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.2837 - acc: 0.4943 - val_loss: 2.5420 - val_acc: 0.2400\n",
      "Epoch 2359/3000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.2832 - acc: 0.5000 - val_loss: 2.5164 - val_acc: 0.2467\n",
      "Epoch 2360/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2830 - acc: 0.4971 - val_loss: 2.5367 - val_acc: 0.2367\n",
      "Epoch 2361/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2831 - acc: 0.5014 - val_loss: 2.5281 - val_acc: 0.2433\n",
      "Epoch 2362/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2830 - acc: 0.4943 - val_loss: 2.5147 - val_acc: 0.2467\n",
      "Epoch 2363/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2825 - acc: 0.4986 - val_loss: 2.5159 - val_acc: 0.2433\n",
      "Epoch 2364/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2826 - acc: 0.5014 - val_loss: 2.5256 - val_acc: 0.2367\n",
      "Epoch 2365/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2822 - acc: 0.5014 - val_loss: 2.5494 - val_acc: 0.2467\n",
      "Epoch 2366/3000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.2825 - acc: 0.5043 - val_loss: 2.5433 - val_acc: 0.2333\n",
      "Epoch 2367/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.2826 - acc: 0.5000 - val_loss: 2.5227 - val_acc: 0.2333\n",
      "Epoch 2368/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2832 - acc: 0.5000 - val_loss: 2.5184 - val_acc: 0.2367\n",
      "Epoch 2369/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2822 - acc: 0.5014 - val_loss: 2.5251 - val_acc: 0.2400\n",
      "Epoch 2370/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.2814 - acc: 0.5000 - val_loss: 2.5212 - val_acc: 0.2467\n",
      "Epoch 2371/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.2827 - acc: 0.5000 - val_loss: 2.5408 - val_acc: 0.2467\n",
      "Epoch 2372/3000\n",
      "700/700 [==============================] - 0s 166us/step - loss: 1.2820 - acc: 0.5000 - val_loss: 2.5276 - val_acc: 0.2467\n",
      "Epoch 2373/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 140us/step - loss: 1.2830 - acc: 0.4986 - val_loss: 2.5490 - val_acc: 0.2433\n",
      "Epoch 2374/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.2823 - acc: 0.4971 - val_loss: 2.5260 - val_acc: 0.2367\n",
      "Epoch 2375/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.2824 - acc: 0.5014 - val_loss: 2.5268 - val_acc: 0.2433\n",
      "Epoch 2376/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.2823 - acc: 0.5000 - val_loss: 2.5358 - val_acc: 0.2400\n",
      "Epoch 2377/3000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.2820 - acc: 0.4929 - val_loss: 2.5211 - val_acc: 0.2400\n",
      "Epoch 2378/3000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.2821 - acc: 0.4986 - val_loss: 2.5123 - val_acc: 0.2500\n",
      "Epoch 2379/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.2821 - acc: 0.4986 - val_loss: 2.5212 - val_acc: 0.2467\n",
      "Epoch 2380/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.2814 - acc: 0.5014 - val_loss: 2.5191 - val_acc: 0.2467\n",
      "Epoch 2381/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2821 - acc: 0.5043 - val_loss: 2.5381 - val_acc: 0.2500\n",
      "Epoch 2382/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.2816 - acc: 0.5000 - val_loss: 2.5299 - val_acc: 0.2500\n",
      "Epoch 2383/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2817 - acc: 0.5029 - val_loss: 2.5487 - val_acc: 0.2467\n",
      "Epoch 2384/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.2819 - acc: 0.4986 - val_loss: 2.5315 - val_acc: 0.2467\n",
      "Epoch 2385/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2817 - acc: 0.5029 - val_loss: 2.5444 - val_acc: 0.2433\n",
      "Epoch 2386/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2810 - acc: 0.4986 - val_loss: 2.5357 - val_acc: 0.2433\n",
      "Epoch 2387/3000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.2814 - acc: 0.5014 - val_loss: 2.5454 - val_acc: 0.2400\n",
      "Epoch 2388/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2814 - acc: 0.5029 - val_loss: 2.5427 - val_acc: 0.2400\n",
      "Epoch 2389/3000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.2814 - acc: 0.5014 - val_loss: 2.5229 - val_acc: 0.2367\n",
      "Epoch 2390/3000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.2811 - acc: 0.4957 - val_loss: 2.5565 - val_acc: 0.2433\n",
      "Epoch 2391/3000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.2810 - acc: 0.4986 - val_loss: 2.5473 - val_acc: 0.2467\n",
      "Epoch 2392/3000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.2820 - acc: 0.4971 - val_loss: 2.5447 - val_acc: 0.2400\n",
      "Epoch 2393/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.2814 - acc: 0.5029 - val_loss: 2.5294 - val_acc: 0.2500\n",
      "Epoch 2394/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2812 - acc: 0.5043 - val_loss: 2.5434 - val_acc: 0.2500\n",
      "Epoch 2395/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2809 - acc: 0.4986 - val_loss: 2.5464 - val_acc: 0.2433\n",
      "Epoch 2396/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2807 - acc: 0.5000 - val_loss: 2.5608 - val_acc: 0.2433\n",
      "Epoch 2397/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2807 - acc: 0.5014 - val_loss: 2.5434 - val_acc: 0.2433\n",
      "Epoch 2398/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2810 - acc: 0.5071 - val_loss: 2.5377 - val_acc: 0.2467\n",
      "Epoch 2399/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2809 - acc: 0.5086 - val_loss: 2.5651 - val_acc: 0.2433\n",
      "Epoch 2400/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2804 - acc: 0.5000 - val_loss: 2.5385 - val_acc: 0.2433\n",
      "Epoch 2401/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2800 - acc: 0.4943 - val_loss: 2.5626 - val_acc: 0.2400\n",
      "Epoch 2402/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2819 - acc: 0.4929 - val_loss: 2.5000 - val_acc: 0.2433\n",
      "Epoch 2403/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2811 - acc: 0.4986 - val_loss: 2.5317 - val_acc: 0.2500\n",
      "Epoch 2404/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2798 - acc: 0.5014 - val_loss: 2.5343 - val_acc: 0.2500\n",
      "Epoch 2405/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.2810 - acc: 0.5029 - val_loss: 2.5196 - val_acc: 0.2467\n",
      "Epoch 2406/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.2806 - acc: 0.5029 - val_loss: 2.5412 - val_acc: 0.2467\n",
      "Epoch 2407/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.2801 - acc: 0.5071 - val_loss: 2.5209 - val_acc: 0.2400\n",
      "Epoch 2408/3000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.2796 - acc: 0.5043 - val_loss: 2.5314 - val_acc: 0.2500\n",
      "Epoch 2409/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.2807 - acc: 0.4986 - val_loss: 2.5367 - val_acc: 0.2467\n",
      "Epoch 2410/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.2798 - acc: 0.5014 - val_loss: 2.5555 - val_acc: 0.2367\n",
      "Epoch 2411/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.2800 - acc: 0.5043 - val_loss: 2.5311 - val_acc: 0.2500\n",
      "Epoch 2412/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2800 - acc: 0.5014 - val_loss: 2.5844 - val_acc: 0.2467\n",
      "Epoch 2413/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2806 - acc: 0.4986 - val_loss: 2.5484 - val_acc: 0.2400\n",
      "Epoch 2414/3000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.2801 - acc: 0.5014 - val_loss: 2.5509 - val_acc: 0.2433\n",
      "Epoch 2415/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2802 - acc: 0.5029 - val_loss: 2.5456 - val_acc: 0.2433\n",
      "Epoch 2416/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.2796 - acc: 0.5000 - val_loss: 2.5261 - val_acc: 0.2400\n",
      "Epoch 2417/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2804 - acc: 0.4971 - val_loss: 2.5371 - val_acc: 0.2433\n",
      "Epoch 2418/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.2800 - acc: 0.5014 - val_loss: 2.5603 - val_acc: 0.2333\n",
      "Epoch 2419/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2799 - acc: 0.4971 - val_loss: 2.5339 - val_acc: 0.2500\n",
      "Epoch 2420/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2796 - acc: 0.5014 - val_loss: 2.5173 - val_acc: 0.2400\n",
      "Epoch 2421/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2799 - acc: 0.5000 - val_loss: 2.5219 - val_acc: 0.2367\n",
      "Epoch 2422/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2797 - acc: 0.5043 - val_loss: 2.5447 - val_acc: 0.2367\n",
      "Epoch 2423/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2801 - acc: 0.4986 - val_loss: 2.5589 - val_acc: 0.2400\n",
      "Epoch 2424/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2796 - acc: 0.5000 - val_loss: 2.5291 - val_acc: 0.2467\n",
      "Epoch 2425/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.2796 - acc: 0.4986 - val_loss: 2.5450 - val_acc: 0.2400\n",
      "Epoch 2426/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.2785 - acc: 0.5057 - val_loss: 2.5542 - val_acc: 0.2300\n",
      "Epoch 2427/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2795 - acc: 0.4986 - val_loss: 2.5429 - val_acc: 0.2367\n",
      "Epoch 2428/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.2794 - acc: 0.5071 - val_loss: 2.5316 - val_acc: 0.2433\n",
      "Epoch 2429/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2788 - acc: 0.5029 - val_loss: 2.5435 - val_acc: 0.2433\n",
      "Epoch 2430/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.2789 - acc: 0.4986 - val_loss: 2.5230 - val_acc: 0.2400\n",
      "Epoch 2431/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2786 - acc: 0.5071 - val_loss: 2.5409 - val_acc: 0.2400\n",
      "Epoch 2432/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2791 - acc: 0.5057 - val_loss: 2.5490 - val_acc: 0.2367\n",
      "Epoch 2433/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2789 - acc: 0.5000 - val_loss: 2.5391 - val_acc: 0.2433\n",
      "Epoch 2434/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2794 - acc: 0.4957 - val_loss: 2.5354 - val_acc: 0.2467\n",
      "Epoch 2435/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2792 - acc: 0.5086 - val_loss: 2.5618 - val_acc: 0.2367\n",
      "Epoch 2436/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2786 - acc: 0.5029 - val_loss: 2.5644 - val_acc: 0.2400\n",
      "Epoch 2437/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2797 - acc: 0.4929 - val_loss: 2.5418 - val_acc: 0.2467\n",
      "Epoch 2438/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2791 - acc: 0.4957 - val_loss: 2.5514 - val_acc: 0.2433\n",
      "Epoch 2439/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2794 - acc: 0.5043 - val_loss: 2.5584 - val_acc: 0.2433\n",
      "Epoch 2440/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2791 - acc: 0.5057 - val_loss: 2.5638 - val_acc: 0.2433\n",
      "Epoch 2441/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2779 - acc: 0.4943 - val_loss: 2.5361 - val_acc: 0.2367\n",
      "Epoch 2442/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2790 - acc: 0.5000 - val_loss: 2.5638 - val_acc: 0.2400\n",
      "Epoch 2443/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2784 - acc: 0.5043 - val_loss: 2.5668 - val_acc: 0.2433\n",
      "Epoch 2444/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2779 - acc: 0.5014 - val_loss: 2.5476 - val_acc: 0.2467\n",
      "Epoch 2445/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2787 - acc: 0.5029 - val_loss: 2.5443 - val_acc: 0.2400\n",
      "Epoch 2446/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2786 - acc: 0.5043 - val_loss: 2.5438 - val_acc: 0.2367\n",
      "Epoch 2447/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2780 - acc: 0.5057 - val_loss: 2.5652 - val_acc: 0.2400\n",
      "Epoch 2448/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2780 - acc: 0.5043 - val_loss: 2.5447 - val_acc: 0.2433\n",
      "Epoch 2449/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2783 - acc: 0.5029 - val_loss: 2.5574 - val_acc: 0.2367\n",
      "Epoch 2450/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2779 - acc: 0.5057 - val_loss: 2.5440 - val_acc: 0.2300\n",
      "Epoch 2451/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2782 - acc: 0.5014 - val_loss: 2.5501 - val_acc: 0.2400\n",
      "Epoch 2452/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2785 - acc: 0.5057 - val_loss: 2.5549 - val_acc: 0.2400\n",
      "Epoch 2453/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2776 - acc: 0.5029 - val_loss: 2.5409 - val_acc: 0.2367\n",
      "Epoch 2454/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2780 - acc: 0.5000 - val_loss: 2.5836 - val_acc: 0.2467\n",
      "Epoch 2455/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2783 - acc: 0.5000 - val_loss: 2.5587 - val_acc: 0.2367\n",
      "Epoch 2456/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2774 - acc: 0.5086 - val_loss: 2.5704 - val_acc: 0.2433\n",
      "Epoch 2457/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2780 - acc: 0.5029 - val_loss: 2.5582 - val_acc: 0.2400\n",
      "Epoch 2458/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2775 - acc: 0.5014 - val_loss: 2.5350 - val_acc: 0.2467\n",
      "Epoch 2459/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2777 - acc: 0.5014 - val_loss: 2.5464 - val_acc: 0.2433\n",
      "Epoch 2460/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.2775 - acc: 0.4971 - val_loss: 2.5360 - val_acc: 0.2433\n",
      "Epoch 2461/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2776 - acc: 0.5029 - val_loss: 2.5461 - val_acc: 0.2467\n",
      "Epoch 2462/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2770 - acc: 0.4971 - val_loss: 2.5589 - val_acc: 0.2400\n",
      "Epoch 2463/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2776 - acc: 0.5014 - val_loss: 2.5428 - val_acc: 0.2400\n",
      "Epoch 2464/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2770 - acc: 0.5029 - val_loss: 2.5426 - val_acc: 0.2433\n",
      "Epoch 2465/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2770 - acc: 0.4986 - val_loss: 2.5781 - val_acc: 0.2433\n",
      "Epoch 2466/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2765 - acc: 0.5000 - val_loss: 2.5489 - val_acc: 0.2433\n",
      "Epoch 2467/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2773 - acc: 0.5014 - val_loss: 2.5157 - val_acc: 0.2433\n",
      "Epoch 2468/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2770 - acc: 0.5014 - val_loss: 2.5542 - val_acc: 0.2433\n",
      "Epoch 2469/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2767 - acc: 0.4971 - val_loss: 2.5489 - val_acc: 0.2333\n",
      "Epoch 2470/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2772 - acc: 0.5000 - val_loss: 2.5515 - val_acc: 0.2433\n",
      "Epoch 2471/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2772 - acc: 0.5014 - val_loss: 2.5359 - val_acc: 0.2500\n",
      "Epoch 2472/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2769 - acc: 0.5000 - val_loss: 2.5631 - val_acc: 0.2367\n",
      "Epoch 2473/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2771 - acc: 0.5071 - val_loss: 2.5836 - val_acc: 0.2333\n",
      "Epoch 2474/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2783 - acc: 0.4986 - val_loss: 2.5493 - val_acc: 0.2300\n",
      "Epoch 2475/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2765 - acc: 0.5014 - val_loss: 2.5690 - val_acc: 0.2433\n",
      "Epoch 2476/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2763 - acc: 0.5029 - val_loss: 2.5653 - val_acc: 0.2433\n",
      "Epoch 2477/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2767 - acc: 0.4986 - val_loss: 2.5494 - val_acc: 0.2400\n",
      "Epoch 2478/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2772 - acc: 0.4986 - val_loss: 2.5583 - val_acc: 0.2367\n",
      "Epoch 2479/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2754 - acc: 0.5043 - val_loss: 2.5437 - val_acc: 0.2467\n",
      "Epoch 2480/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2753 - acc: 0.5071 - val_loss: 2.5818 - val_acc: 0.2333\n",
      "Epoch 2481/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2757 - acc: 0.5029 - val_loss: 2.5634 - val_acc: 0.2433\n",
      "Epoch 2482/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2759 - acc: 0.5000 - val_loss: 2.5704 - val_acc: 0.2367\n",
      "Epoch 2483/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2764 - acc: 0.5000 - val_loss: 2.5520 - val_acc: 0.2367\n",
      "Epoch 2484/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2769 - acc: 0.5000 - val_loss: 2.5564 - val_acc: 0.2367\n",
      "Epoch 2485/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2763 - acc: 0.5014 - val_loss: 2.5499 - val_acc: 0.2333\n",
      "Epoch 2486/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.2758 - acc: 0.5029 - val_loss: 2.5479 - val_acc: 0.2433\n",
      "Epoch 2487/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.2760 - acc: 0.5057 - val_loss: 2.5802 - val_acc: 0.2467\n",
      "Epoch 2488/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2759 - acc: 0.5000 - val_loss: 2.5463 - val_acc: 0.2467\n",
      "Epoch 2489/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2768 - acc: 0.5043 - val_loss: 2.5690 - val_acc: 0.2400\n",
      "Epoch 2490/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2755 - acc: 0.5014 - val_loss: 2.5672 - val_acc: 0.2433\n",
      "Epoch 2491/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 97us/step - loss: 1.2764 - acc: 0.4971 - val_loss: 2.5555 - val_acc: 0.2367\n",
      "Epoch 2492/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2766 - acc: 0.5014 - val_loss: 2.5470 - val_acc: 0.2467\n",
      "Epoch 2493/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2759 - acc: 0.5014 - val_loss: 2.5815 - val_acc: 0.2400\n",
      "Epoch 2494/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2759 - acc: 0.4943 - val_loss: 2.5610 - val_acc: 0.2367\n",
      "Epoch 2495/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2755 - acc: 0.5014 - val_loss: 2.5890 - val_acc: 0.2367\n",
      "Epoch 2496/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2767 - acc: 0.4986 - val_loss: 2.5791 - val_acc: 0.2433\n",
      "Epoch 2497/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2756 - acc: 0.4986 - val_loss: 2.5737 - val_acc: 0.2400\n",
      "Epoch 2498/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2757 - acc: 0.5043 - val_loss: 2.5855 - val_acc: 0.2433\n",
      "Epoch 2499/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.2754 - acc: 0.5071 - val_loss: 2.5463 - val_acc: 0.2333\n",
      "Epoch 2500/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2750 - acc: 0.5057 - val_loss: 2.5411 - val_acc: 0.2500\n",
      "Epoch 2501/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2756 - acc: 0.5057 - val_loss: 2.5938 - val_acc: 0.2400\n",
      "Epoch 2502/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2755 - acc: 0.5043 - val_loss: 2.5623 - val_acc: 0.2433\n",
      "Epoch 2503/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.2749 - acc: 0.5043 - val_loss: 2.5705 - val_acc: 0.2400\n",
      "Epoch 2504/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2750 - acc: 0.5071 - val_loss: 2.5699 - val_acc: 0.2433\n",
      "Epoch 2505/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2765 - acc: 0.4957 - val_loss: 2.5507 - val_acc: 0.2433\n",
      "Epoch 2506/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2748 - acc: 0.5057 - val_loss: 2.5671 - val_acc: 0.2400\n",
      "Epoch 2507/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2749 - acc: 0.5057 - val_loss: 2.5578 - val_acc: 0.2400\n",
      "Epoch 2508/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2747 - acc: 0.5014 - val_loss: 2.5971 - val_acc: 0.2467\n",
      "Epoch 2509/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2750 - acc: 0.5086 - val_loss: 2.5647 - val_acc: 0.2433\n",
      "Epoch 2510/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2744 - acc: 0.4986 - val_loss: 2.5747 - val_acc: 0.2367\n",
      "Epoch 2511/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2748 - acc: 0.5000 - val_loss: 2.5690 - val_acc: 0.2367\n",
      "Epoch 2512/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2747 - acc: 0.5029 - val_loss: 2.5760 - val_acc: 0.2467\n",
      "Epoch 2513/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2754 - acc: 0.5057 - val_loss: 2.5581 - val_acc: 0.2433\n",
      "Epoch 2514/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.2740 - acc: 0.5000 - val_loss: 2.5502 - val_acc: 0.2433\n",
      "Epoch 2515/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2742 - acc: 0.5014 - val_loss: 2.5597 - val_acc: 0.2333\n",
      "Epoch 2516/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2744 - acc: 0.5014 - val_loss: 2.5796 - val_acc: 0.2433\n",
      "Epoch 2517/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2749 - acc: 0.5043 - val_loss: 2.5829 - val_acc: 0.2433\n",
      "Epoch 2518/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2745 - acc: 0.5043 - val_loss: 2.5705 - val_acc: 0.2433\n",
      "Epoch 2519/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2755 - acc: 0.5057 - val_loss: 2.5815 - val_acc: 0.2400\n",
      "Epoch 2520/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2738 - acc: 0.5000 - val_loss: 2.5758 - val_acc: 0.2367\n",
      "Epoch 2521/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2742 - acc: 0.5000 - val_loss: 2.5697 - val_acc: 0.2300\n",
      "Epoch 2522/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2744 - acc: 0.4986 - val_loss: 2.5655 - val_acc: 0.2367\n",
      "Epoch 2523/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2747 - acc: 0.5071 - val_loss: 2.5580 - val_acc: 0.2367\n",
      "Epoch 2524/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2736 - acc: 0.5000 - val_loss: 2.5638 - val_acc: 0.2433\n",
      "Epoch 2525/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2742 - acc: 0.5000 - val_loss: 2.5709 - val_acc: 0.2433\n",
      "Epoch 2526/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2741 - acc: 0.5000 - val_loss: 2.5609 - val_acc: 0.2367\n",
      "Epoch 2527/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2739 - acc: 0.5029 - val_loss: 2.5733 - val_acc: 0.2367\n",
      "Epoch 2528/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2732 - acc: 0.5014 - val_loss: 2.5741 - val_acc: 0.2333\n",
      "Epoch 2529/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2746 - acc: 0.5071 - val_loss: 2.5887 - val_acc: 0.2367\n",
      "Epoch 2530/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2732 - acc: 0.5029 - val_loss: 2.5750 - val_acc: 0.2367\n",
      "Epoch 2531/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.2734 - acc: 0.5043 - val_loss: 2.5386 - val_acc: 0.2433\n",
      "Epoch 2532/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2735 - acc: 0.5071 - val_loss: 2.5748 - val_acc: 0.2433\n",
      "Epoch 2533/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2745 - acc: 0.5057 - val_loss: 2.5705 - val_acc: 0.2433\n",
      "Epoch 2534/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2743 - acc: 0.5000 - val_loss: 2.5830 - val_acc: 0.2400\n",
      "Epoch 2535/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2739 - acc: 0.5000 - val_loss: 2.5662 - val_acc: 0.2433\n",
      "Epoch 2536/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.2735 - acc: 0.5057 - val_loss: 2.5885 - val_acc: 0.2400\n",
      "Epoch 2537/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2740 - acc: 0.5043 - val_loss: 2.5561 - val_acc: 0.2400\n",
      "Epoch 2538/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2730 - acc: 0.5043 - val_loss: 2.5799 - val_acc: 0.2367\n",
      "Epoch 2539/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2739 - acc: 0.5029 - val_loss: 2.5868 - val_acc: 0.2400\n",
      "Epoch 2540/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2733 - acc: 0.5057 - val_loss: 2.5926 - val_acc: 0.2433\n",
      "Epoch 2541/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2733 - acc: 0.5057 - val_loss: 2.5763 - val_acc: 0.2400\n",
      "Epoch 2542/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2729 - acc: 0.5043 - val_loss: 2.5686 - val_acc: 0.2433\n",
      "Epoch 2543/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2731 - acc: 0.5043 - val_loss: 2.5750 - val_acc: 0.2333\n",
      "Epoch 2544/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2738 - acc: 0.5014 - val_loss: 2.5701 - val_acc: 0.2367\n",
      "Epoch 2545/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2732 - acc: 0.5071 - val_loss: 2.5954 - val_acc: 0.2367\n",
      "Epoch 2546/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2734 - acc: 0.5043 - val_loss: 2.5921 - val_acc: 0.2400\n",
      "Epoch 2547/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2733 - acc: 0.5029 - val_loss: 2.5898 - val_acc: 0.2433\n",
      "Epoch 2548/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2725 - acc: 0.5014 - val_loss: 2.5805 - val_acc: 0.2400\n",
      "Epoch 2549/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2729 - acc: 0.5014 - val_loss: 2.5720 - val_acc: 0.2367\n",
      "Epoch 2550/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2730 - acc: 0.5043 - val_loss: 2.5710 - val_acc: 0.2367\n",
      "Epoch 2551/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2722 - acc: 0.5000 - val_loss: 2.5949 - val_acc: 0.2433\n",
      "Epoch 2552/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2726 - acc: 0.5043 - val_loss: 2.5600 - val_acc: 0.2333\n",
      "Epoch 2553/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2723 - acc: 0.5014 - val_loss: 2.5674 - val_acc: 0.2367\n",
      "Epoch 2554/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2724 - acc: 0.4986 - val_loss: 2.5606 - val_acc: 0.2333\n",
      "Epoch 2555/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2729 - acc: 0.5029 - val_loss: 2.5923 - val_acc: 0.2433\n",
      "Epoch 2556/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2728 - acc: 0.4986 - val_loss: 2.5652 - val_acc: 0.2400\n",
      "Epoch 2557/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2720 - acc: 0.5000 - val_loss: 2.5948 - val_acc: 0.2433\n",
      "Epoch 2558/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2722 - acc: 0.4986 - val_loss: 2.5980 - val_acc: 0.2433\n",
      "Epoch 2559/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2722 - acc: 0.5000 - val_loss: 2.5857 - val_acc: 0.2367\n",
      "Epoch 2560/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2738 - acc: 0.5029 - val_loss: 2.5877 - val_acc: 0.2400\n",
      "Epoch 2561/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2721 - acc: 0.5029 - val_loss: 2.5720 - val_acc: 0.2367\n",
      "Epoch 2562/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2717 - acc: 0.5000 - val_loss: 2.5684 - val_acc: 0.2433\n",
      "Epoch 2563/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2718 - acc: 0.5043 - val_loss: 2.5839 - val_acc: 0.2467\n",
      "Epoch 2564/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2726 - acc: 0.4986 - val_loss: 2.5801 - val_acc: 0.2400\n",
      "Epoch 2565/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2721 - acc: 0.5029 - val_loss: 2.5743 - val_acc: 0.2400\n",
      "Epoch 2566/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.2728 - acc: 0.5043 - val_loss: 2.5856 - val_acc: 0.2400\n",
      "Epoch 2567/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2731 - acc: 0.5029 - val_loss: 2.5809 - val_acc: 0.2433\n",
      "Epoch 2568/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2720 - acc: 0.5057 - val_loss: 2.5766 - val_acc: 0.2367\n",
      "Epoch 2569/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2708 - acc: 0.4971 - val_loss: 2.5643 - val_acc: 0.2433\n",
      "Epoch 2570/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2721 - acc: 0.4957 - val_loss: 2.5905 - val_acc: 0.2433\n",
      "Epoch 2571/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2716 - acc: 0.5057 - val_loss: 2.5846 - val_acc: 0.2400\n",
      "Epoch 2572/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2718 - acc: 0.5071 - val_loss: 2.5974 - val_acc: 0.2433\n",
      "Epoch 2573/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2710 - acc: 0.5029 - val_loss: 2.6173 - val_acc: 0.2433\n",
      "Epoch 2574/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2718 - acc: 0.4986 - val_loss: 2.5487 - val_acc: 0.2433\n",
      "Epoch 2575/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.2715 - acc: 0.5014 - val_loss: 2.5859 - val_acc: 0.2367\n",
      "Epoch 2576/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2711 - acc: 0.5043 - val_loss: 2.5976 - val_acc: 0.2433\n",
      "Epoch 2577/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2715 - acc: 0.5043 - val_loss: 2.5901 - val_acc: 0.2433\n",
      "Epoch 2578/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2715 - acc: 0.5014 - val_loss: 2.5857 - val_acc: 0.2433\n",
      "Epoch 2579/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2714 - acc: 0.5014 - val_loss: 2.5798 - val_acc: 0.2367\n",
      "Epoch 2580/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2710 - acc: 0.5057 - val_loss: 2.5867 - val_acc: 0.2433\n",
      "Epoch 2581/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2705 - acc: 0.5043 - val_loss: 2.5657 - val_acc: 0.2367\n",
      "Epoch 2582/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2712 - acc: 0.5029 - val_loss: 2.6016 - val_acc: 0.2367\n",
      "Epoch 2583/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2714 - acc: 0.5029 - val_loss: 2.5957 - val_acc: 0.2367\n",
      "Epoch 2584/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2710 - acc: 0.5114 - val_loss: 2.5888 - val_acc: 0.2367\n",
      "Epoch 2585/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2705 - acc: 0.5000 - val_loss: 2.5866 - val_acc: 0.2400\n",
      "Epoch 2586/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2715 - acc: 0.5071 - val_loss: 2.5710 - val_acc: 0.2433\n",
      "Epoch 2587/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2709 - acc: 0.5071 - val_loss: 2.5946 - val_acc: 0.2367\n",
      "Epoch 2588/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.2710 - acc: 0.5014 - val_loss: 2.5889 - val_acc: 0.2400\n",
      "Epoch 2589/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2707 - acc: 0.5000 - val_loss: 2.5814 - val_acc: 0.2400\n",
      "Epoch 2590/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2700 - acc: 0.5043 - val_loss: 2.5721 - val_acc: 0.2333\n",
      "Epoch 2591/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2703 - acc: 0.5043 - val_loss: 2.5735 - val_acc: 0.2433\n",
      "Epoch 2592/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2704 - acc: 0.5043 - val_loss: 2.6088 - val_acc: 0.2433\n",
      "Epoch 2593/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2701 - acc: 0.5043 - val_loss: 2.5696 - val_acc: 0.2400\n",
      "Epoch 2594/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2710 - acc: 0.5043 - val_loss: 2.5774 - val_acc: 0.2367\n",
      "Epoch 2595/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2706 - acc: 0.4986 - val_loss: 2.5856 - val_acc: 0.2333\n",
      "Epoch 2596/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2705 - acc: 0.5057 - val_loss: 2.5797 - val_acc: 0.2333\n",
      "Epoch 2597/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2705 - acc: 0.5043 - val_loss: 2.5622 - val_acc: 0.2367\n",
      "Epoch 2598/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2702 - acc: 0.5000 - val_loss: 2.5709 - val_acc: 0.2433\n",
      "Epoch 2599/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2705 - acc: 0.5043 - val_loss: 2.5718 - val_acc: 0.2367\n",
      "Epoch 2600/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2697 - acc: 0.5057 - val_loss: 2.5829 - val_acc: 0.2433\n",
      "Epoch 2601/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2698 - acc: 0.5071 - val_loss: 2.5868 - val_acc: 0.2433\n",
      "Epoch 2602/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2708 - acc: 0.5100 - val_loss: 2.6012 - val_acc: 0.2433\n",
      "Epoch 2603/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2702 - acc: 0.5071 - val_loss: 2.5699 - val_acc: 0.2400\n",
      "Epoch 2604/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2695 - acc: 0.5057 - val_loss: 2.5943 - val_acc: 0.2367\n",
      "Epoch 2605/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2702 - acc: 0.5043 - val_loss: 2.5817 - val_acc: 0.2367\n",
      "Epoch 2606/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2701 - acc: 0.5043 - val_loss: 2.5820 - val_acc: 0.2333\n",
      "Epoch 2607/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2695 - acc: 0.5043 - val_loss: 2.5769 - val_acc: 0.2400\n",
      "Epoch 2608/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2704 - acc: 0.5029 - val_loss: 2.6032 - val_acc: 0.2367\n",
      "Epoch 2609/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 107us/step - loss: 1.2696 - acc: 0.5057 - val_loss: 2.5830 - val_acc: 0.2400\n",
      "Epoch 2610/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2695 - acc: 0.5014 - val_loss: 2.5716 - val_acc: 0.2433\n",
      "Epoch 2611/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2692 - acc: 0.5043 - val_loss: 2.5789 - val_acc: 0.2400\n",
      "Epoch 2612/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2700 - acc: 0.5057 - val_loss: 2.5954 - val_acc: 0.2400\n",
      "Epoch 2613/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.2694 - acc: 0.5043 - val_loss: 2.5897 - val_acc: 0.2433\n",
      "Epoch 2614/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2691 - acc: 0.5029 - val_loss: 2.6077 - val_acc: 0.2433\n",
      "Epoch 2615/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2692 - acc: 0.5043 - val_loss: 2.5592 - val_acc: 0.2433\n",
      "Epoch 2616/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2695 - acc: 0.5057 - val_loss: 2.6077 - val_acc: 0.2400\n",
      "Epoch 2617/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2695 - acc: 0.5043 - val_loss: 2.5977 - val_acc: 0.2433\n",
      "Epoch 2618/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2699 - acc: 0.4971 - val_loss: 2.5735 - val_acc: 0.2367\n",
      "Epoch 2619/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2700 - acc: 0.5043 - val_loss: 2.5963 - val_acc: 0.2367\n",
      "Epoch 2620/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2692 - acc: 0.5029 - val_loss: 2.5976 - val_acc: 0.2367\n",
      "Epoch 2621/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2693 - acc: 0.5057 - val_loss: 2.5982 - val_acc: 0.2367\n",
      "Epoch 2622/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2693 - acc: 0.5014 - val_loss: 2.5726 - val_acc: 0.2367\n",
      "Epoch 2623/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2692 - acc: 0.5029 - val_loss: 2.6016 - val_acc: 0.2400\n",
      "Epoch 2624/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2685 - acc: 0.5043 - val_loss: 2.5785 - val_acc: 0.2333\n",
      "Epoch 2625/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2686 - acc: 0.5057 - val_loss: 2.6072 - val_acc: 0.2433\n",
      "Epoch 2626/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.2695 - acc: 0.5029 - val_loss: 2.6045 - val_acc: 0.2433\n",
      "Epoch 2627/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.2693 - acc: 0.5043 - val_loss: 2.5947 - val_acc: 0.2367\n",
      "Epoch 2628/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2684 - acc: 0.5043 - val_loss: 2.6011 - val_acc: 0.2367\n",
      "Epoch 2629/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2684 - acc: 0.5043 - val_loss: 2.5927 - val_acc: 0.2367\n",
      "Epoch 2630/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2685 - acc: 0.5043 - val_loss: 2.5641 - val_acc: 0.2467\n",
      "Epoch 2631/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2690 - acc: 0.5071 - val_loss: 2.6000 - val_acc: 0.2367\n",
      "Epoch 2632/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2692 - acc: 0.5014 - val_loss: 2.5963 - val_acc: 0.2433\n",
      "Epoch 2633/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2681 - acc: 0.5071 - val_loss: 2.5964 - val_acc: 0.2367\n",
      "Epoch 2634/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.2678 - acc: 0.5057 - val_loss: 2.5758 - val_acc: 0.2400\n",
      "Epoch 2635/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2692 - acc: 0.5014 - val_loss: 2.6125 - val_acc: 0.2367\n",
      "Epoch 2636/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2682 - acc: 0.5057 - val_loss: 2.6005 - val_acc: 0.2367\n",
      "Epoch 2637/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2691 - acc: 0.5029 - val_loss: 2.6004 - val_acc: 0.2400\n",
      "Epoch 2638/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2685 - acc: 0.5029 - val_loss: 2.5956 - val_acc: 0.2433\n",
      "Epoch 2639/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2686 - acc: 0.5000 - val_loss: 2.5714 - val_acc: 0.2433\n",
      "Epoch 2640/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2683 - acc: 0.5100 - val_loss: 2.6150 - val_acc: 0.2467\n",
      "Epoch 2641/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2677 - acc: 0.5071 - val_loss: 2.6369 - val_acc: 0.2467\n",
      "Epoch 2642/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2679 - acc: 0.5000 - val_loss: 2.5934 - val_acc: 0.2433\n",
      "Epoch 2643/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2679 - acc: 0.5129 - val_loss: 2.5705 - val_acc: 0.2333\n",
      "Epoch 2644/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2683 - acc: 0.5014 - val_loss: 2.5993 - val_acc: 0.2433\n",
      "Epoch 2645/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2679 - acc: 0.5014 - val_loss: 2.6081 - val_acc: 0.2467\n",
      "Epoch 2646/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2685 - acc: 0.5043 - val_loss: 2.6044 - val_acc: 0.2433\n",
      "Epoch 2647/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2681 - acc: 0.5014 - val_loss: 2.6013 - val_acc: 0.2467\n",
      "Epoch 2648/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2679 - acc: 0.5057 - val_loss: 2.6108 - val_acc: 0.2433\n",
      "Epoch 2649/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2681 - acc: 0.5043 - val_loss: 2.5870 - val_acc: 0.2367\n",
      "Epoch 2650/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2672 - acc: 0.5071 - val_loss: 2.5693 - val_acc: 0.2367\n",
      "Epoch 2651/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2672 - acc: 0.5029 - val_loss: 2.5949 - val_acc: 0.2433\n",
      "Epoch 2652/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2674 - acc: 0.5086 - val_loss: 2.5833 - val_acc: 0.2433\n",
      "Epoch 2653/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2681 - acc: 0.5114 - val_loss: 2.6213 - val_acc: 0.2467\n",
      "Epoch 2654/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2678 - acc: 0.4986 - val_loss: 2.5992 - val_acc: 0.2400\n",
      "Epoch 2655/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2677 - acc: 0.5043 - val_loss: 2.6035 - val_acc: 0.2400\n",
      "Epoch 2656/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2677 - acc: 0.5071 - val_loss: 2.6061 - val_acc: 0.2367\n",
      "Epoch 2657/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2668 - acc: 0.5029 - val_loss: 2.5969 - val_acc: 0.2333\n",
      "Epoch 2658/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2669 - acc: 0.5071 - val_loss: 2.6062 - val_acc: 0.2367\n",
      "Epoch 2659/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2670 - acc: 0.5000 - val_loss: 2.5934 - val_acc: 0.2367\n",
      "Epoch 2660/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2674 - acc: 0.5014 - val_loss: 2.6212 - val_acc: 0.2400\n",
      "Epoch 2661/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2683 - acc: 0.5029 - val_loss: 2.5997 - val_acc: 0.2400\n",
      "Epoch 2662/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2676 - acc: 0.5014 - val_loss: 2.5944 - val_acc: 0.2367\n",
      "Epoch 2663/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2667 - acc: 0.5071 - val_loss: 2.5931 - val_acc: 0.2367\n",
      "Epoch 2664/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2667 - acc: 0.5057 - val_loss: 2.5947 - val_acc: 0.2367\n",
      "Epoch 2665/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2666 - acc: 0.5100 - val_loss: 2.5883 - val_acc: 0.2367\n",
      "Epoch 2666/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2675 - acc: 0.5043 - val_loss: 2.5935 - val_acc: 0.2367\n",
      "Epoch 2667/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2660 - acc: 0.5100 - val_loss: 2.6002 - val_acc: 0.2433\n",
      "Epoch 2668/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2670 - acc: 0.5071 - val_loss: 2.6362 - val_acc: 0.2500\n",
      "Epoch 2669/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2670 - acc: 0.5071 - val_loss: 2.6183 - val_acc: 0.2367\n",
      "Epoch 2670/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2668 - acc: 0.5043 - val_loss: 2.6203 - val_acc: 0.2433\n",
      "Epoch 2671/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2672 - acc: 0.5086 - val_loss: 2.6234 - val_acc: 0.2400\n",
      "Epoch 2672/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2665 - acc: 0.5086 - val_loss: 2.6270 - val_acc: 0.2433\n",
      "Epoch 2673/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2668 - acc: 0.5057 - val_loss: 2.5893 - val_acc: 0.2367\n",
      "Epoch 2674/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2665 - acc: 0.5043 - val_loss: 2.6000 - val_acc: 0.2367\n",
      "Epoch 2675/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2664 - acc: 0.5029 - val_loss: 2.5844 - val_acc: 0.2367\n",
      "Epoch 2676/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2664 - acc: 0.5114 - val_loss: 2.6111 - val_acc: 0.2367\n",
      "Epoch 2677/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2665 - acc: 0.5057 - val_loss: 2.6140 - val_acc: 0.2467\n",
      "Epoch 2678/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2667 - acc: 0.5071 - val_loss: 2.6063 - val_acc: 0.2400\n",
      "Epoch 2679/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2668 - acc: 0.5043 - val_loss: 2.6101 - val_acc: 0.2467\n",
      "Epoch 2680/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2693 - acc: 0.5071 - val_loss: 2.5867 - val_acc: 0.2367\n",
      "Epoch 2681/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2668 - acc: 0.5100 - val_loss: 2.6239 - val_acc: 0.2433\n",
      "Epoch 2682/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2662 - acc: 0.5057 - val_loss: 2.6099 - val_acc: 0.2400\n",
      "Epoch 2683/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2665 - acc: 0.5043 - val_loss: 2.6101 - val_acc: 0.2433\n",
      "Epoch 2684/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2656 - acc: 0.5043 - val_loss: 2.6007 - val_acc: 0.2400\n",
      "Epoch 2685/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2660 - acc: 0.5071 - val_loss: 2.6018 - val_acc: 0.2400\n",
      "Epoch 2686/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2659 - acc: 0.5057 - val_loss: 2.6032 - val_acc: 0.2367\n",
      "Epoch 2687/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2659 - acc: 0.5014 - val_loss: 2.6009 - val_acc: 0.2333\n",
      "Epoch 2688/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2661 - acc: 0.5057 - val_loss: 2.6271 - val_acc: 0.2433\n",
      "Epoch 2689/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2654 - acc: 0.5071 - val_loss: 2.6110 - val_acc: 0.2433\n",
      "Epoch 2690/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2666 - acc: 0.5071 - val_loss: 2.5678 - val_acc: 0.2367\n",
      "Epoch 2691/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2660 - acc: 0.5043 - val_loss: 2.6150 - val_acc: 0.2467\n",
      "Epoch 2692/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2656 - acc: 0.5043 - val_loss: 2.6037 - val_acc: 0.2367\n",
      "Epoch 2693/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2657 - acc: 0.5071 - val_loss: 2.6201 - val_acc: 0.2433\n",
      "Epoch 2694/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2656 - acc: 0.5014 - val_loss: 2.6049 - val_acc: 0.2433\n",
      "Epoch 2695/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2647 - acc: 0.5086 - val_loss: 2.6129 - val_acc: 0.2467\n",
      "Epoch 2696/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2651 - acc: 0.5100 - val_loss: 2.6002 - val_acc: 0.2367\n",
      "Epoch 2697/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2662 - acc: 0.5043 - val_loss: 2.5929 - val_acc: 0.2400\n",
      "Epoch 2698/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2658 - acc: 0.5057 - val_loss: 2.6194 - val_acc: 0.2333\n",
      "Epoch 2699/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.2658 - acc: 0.5029 - val_loss: 2.6166 - val_acc: 0.2433\n",
      "Epoch 2700/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2652 - acc: 0.5071 - val_loss: 2.6147 - val_acc: 0.2467\n",
      "Epoch 2701/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2656 - acc: 0.5071 - val_loss: 2.6245 - val_acc: 0.2433\n",
      "Epoch 2702/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2652 - acc: 0.5071 - val_loss: 2.6257 - val_acc: 0.2367\n",
      "Epoch 2703/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2649 - acc: 0.5029 - val_loss: 2.6419 - val_acc: 0.2467\n",
      "Epoch 2704/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2645 - acc: 0.5043 - val_loss: 2.5934 - val_acc: 0.2400\n",
      "Epoch 2705/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2649 - acc: 0.5086 - val_loss: 2.6030 - val_acc: 0.2400\n",
      "Epoch 2706/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2657 - acc: 0.5057 - val_loss: 2.6132 - val_acc: 0.2433\n",
      "Epoch 2707/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2663 - acc: 0.5057 - val_loss: 2.6207 - val_acc: 0.2367\n",
      "Epoch 2708/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2648 - acc: 0.5014 - val_loss: 2.6237 - val_acc: 0.2367\n",
      "Epoch 2709/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2643 - acc: 0.5057 - val_loss: 2.6181 - val_acc: 0.2333\n",
      "Epoch 2710/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2650 - acc: 0.5043 - val_loss: 2.6281 - val_acc: 0.2333\n",
      "Epoch 2711/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2651 - acc: 0.5071 - val_loss: 2.6080 - val_acc: 0.2433\n",
      "Epoch 2712/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2645 - acc: 0.5043 - val_loss: 2.5793 - val_acc: 0.2367\n",
      "Epoch 2713/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2650 - acc: 0.5086 - val_loss: 2.6372 - val_acc: 0.2433\n",
      "Epoch 2714/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2648 - acc: 0.5057 - val_loss: 2.6334 - val_acc: 0.2467\n",
      "Epoch 2715/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2652 - acc: 0.5071 - val_loss: 2.6466 - val_acc: 0.2400\n",
      "Epoch 2716/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2646 - acc: 0.5071 - val_loss: 2.6334 - val_acc: 0.2467\n",
      "Epoch 2717/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2648 - acc: 0.5043 - val_loss: 2.6138 - val_acc: 0.2433\n",
      "Epoch 2718/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2649 - acc: 0.5071 - val_loss: 2.6258 - val_acc: 0.2467\n",
      "Epoch 2719/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2646 - acc: 0.5100 - val_loss: 2.6001 - val_acc: 0.2433\n",
      "Epoch 2720/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2646 - acc: 0.5057 - val_loss: 2.6152 - val_acc: 0.2367\n",
      "Epoch 2721/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2649 - acc: 0.5043 - val_loss: 2.6057 - val_acc: 0.2333\n",
      "Epoch 2722/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2639 - acc: 0.5086 - val_loss: 2.6229 - val_acc: 0.2467\n",
      "Epoch 2723/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.2649 - acc: 0.5043 - val_loss: 2.6270 - val_acc: 0.2467\n",
      "Epoch 2724/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2646 - acc: 0.5057 - val_loss: 2.6196 - val_acc: 0.2467\n",
      "Epoch 2725/3000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.2645 - acc: 0.5057 - val_loss: 2.6113 - val_acc: 0.2433\n",
      "Epoch 2726/3000\n",
      "700/700 [==============================] - 0s 163us/step - loss: 1.2640 - acc: 0.5071 - val_loss: 2.6132 - val_acc: 0.2433\n",
      "Epoch 2727/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 153us/step - loss: 1.2639 - acc: 0.5100 - val_loss: 2.6182 - val_acc: 0.2333\n",
      "Epoch 2728/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2632 - acc: 0.5043 - val_loss: 2.5910 - val_acc: 0.2433\n",
      "Epoch 2729/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2641 - acc: 0.5071 - val_loss: 2.6228 - val_acc: 0.2467\n",
      "Epoch 2730/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2635 - acc: 0.5071 - val_loss: 2.5927 - val_acc: 0.2333\n",
      "Epoch 2731/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2635 - acc: 0.5043 - val_loss: 2.6128 - val_acc: 0.2400\n",
      "Epoch 2732/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2646 - acc: 0.5057 - val_loss: 2.6308 - val_acc: 0.2400\n",
      "Epoch 2733/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.2648 - acc: 0.5057 - val_loss: 2.6003 - val_acc: 0.2367\n",
      "Epoch 2734/3000\n",
      "700/700 [==============================] - 0s 173us/step - loss: 1.2632 - acc: 0.5129 - val_loss: 2.6186 - val_acc: 0.2433\n",
      "Epoch 2735/3000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.2636 - acc: 0.5071 - val_loss: 2.6212 - val_acc: 0.2400\n",
      "Epoch 2736/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2634 - acc: 0.5086 - val_loss: 2.6289 - val_acc: 0.2433\n",
      "Epoch 2737/3000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.2628 - acc: 0.5100 - val_loss: 2.6356 - val_acc: 0.2467\n",
      "Epoch 2738/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2640 - acc: 0.5086 - val_loss: 2.6093 - val_acc: 0.2333\n",
      "Epoch 2739/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2631 - acc: 0.5086 - val_loss: 2.6536 - val_acc: 0.2467\n",
      "Epoch 2740/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2638 - acc: 0.5043 - val_loss: 2.6009 - val_acc: 0.2400\n",
      "Epoch 2741/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2643 - acc: 0.5043 - val_loss: 2.6384 - val_acc: 0.2400\n",
      "Epoch 2742/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2640 - acc: 0.5014 - val_loss: 2.6335 - val_acc: 0.2367\n",
      "Epoch 2743/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2634 - acc: 0.5029 - val_loss: 2.6133 - val_acc: 0.2400\n",
      "Epoch 2744/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2638 - acc: 0.5086 - val_loss: 2.6108 - val_acc: 0.2433\n",
      "Epoch 2745/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2633 - acc: 0.5043 - val_loss: 2.6283 - val_acc: 0.2433\n",
      "Epoch 2746/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2638 - acc: 0.5057 - val_loss: 2.6146 - val_acc: 0.2400\n",
      "Epoch 2747/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2638 - acc: 0.5000 - val_loss: 2.6178 - val_acc: 0.2333\n",
      "Epoch 2748/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2634 - acc: 0.5057 - val_loss: 2.6435 - val_acc: 0.2433\n",
      "Epoch 2749/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2636 - acc: 0.5000 - val_loss: 2.6378 - val_acc: 0.2467\n",
      "Epoch 2750/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2630 - acc: 0.5071 - val_loss: 2.6380 - val_acc: 0.2467\n",
      "Epoch 2751/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2632 - acc: 0.5043 - val_loss: 2.6215 - val_acc: 0.2400\n",
      "Epoch 2752/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2628 - acc: 0.5114 - val_loss: 2.6256 - val_acc: 0.2367\n",
      "Epoch 2753/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2629 - acc: 0.5043 - val_loss: 2.6319 - val_acc: 0.2433\n",
      "Epoch 2754/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2633 - acc: 0.5057 - val_loss: 2.6097 - val_acc: 0.2400\n",
      "Epoch 2755/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.2620 - acc: 0.5057 - val_loss: 2.5972 - val_acc: 0.2400\n",
      "Epoch 2756/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2626 - acc: 0.5057 - val_loss: 2.6371 - val_acc: 0.2467\n",
      "Epoch 2757/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2636 - acc: 0.5100 - val_loss: 2.6188 - val_acc: 0.2400\n",
      "Epoch 2758/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2634 - acc: 0.5043 - val_loss: 2.5812 - val_acc: 0.2333\n",
      "Epoch 2759/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2630 - acc: 0.5086 - val_loss: 2.6377 - val_acc: 0.2433\n",
      "Epoch 2760/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.2628 - acc: 0.5100 - val_loss: 2.6360 - val_acc: 0.2400\n",
      "Epoch 2761/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2625 - acc: 0.5071 - val_loss: 2.6119 - val_acc: 0.2367\n",
      "Epoch 2762/3000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.2623 - acc: 0.5143 - val_loss: 2.6236 - val_acc: 0.2367\n",
      "Epoch 2763/3000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.2629 - acc: 0.5071 - val_loss: 2.6379 - val_acc: 0.2400\n",
      "Epoch 2764/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2613 - acc: 0.5057 - val_loss: 2.6444 - val_acc: 0.2433\n",
      "Epoch 2765/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2624 - acc: 0.5000 - val_loss: 2.6293 - val_acc: 0.2400\n",
      "Epoch 2766/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.2467 - acc: 0.507 - 0s 101us/step - loss: 1.2616 - acc: 0.5071 - val_loss: 2.6395 - val_acc: 0.2433\n",
      "Epoch 2767/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2622 - acc: 0.5129 - val_loss: 2.6364 - val_acc: 0.2367\n",
      "Epoch 2768/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2620 - acc: 0.5157 - val_loss: 2.6428 - val_acc: 0.2467\n",
      "Epoch 2769/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2613 - acc: 0.5043 - val_loss: 2.6363 - val_acc: 0.2433\n",
      "Epoch 2770/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2617 - acc: 0.5029 - val_loss: 2.6169 - val_acc: 0.2367\n",
      "Epoch 2771/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2614 - acc: 0.5114 - val_loss: 2.6113 - val_acc: 0.2367\n",
      "Epoch 2772/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2626 - acc: 0.5129 - val_loss: 2.6174 - val_acc: 0.2400\n",
      "Epoch 2773/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2618 - acc: 0.5029 - val_loss: 2.5957 - val_acc: 0.2400\n",
      "Epoch 2774/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2620 - acc: 0.5071 - val_loss: 2.6316 - val_acc: 0.2467\n",
      "Epoch 2775/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2618 - acc: 0.5043 - val_loss: 2.6243 - val_acc: 0.2367\n",
      "Epoch 2776/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2624 - acc: 0.5043 - val_loss: 2.6313 - val_acc: 0.2400\n",
      "Epoch 2777/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2625 - acc: 0.5057 - val_loss: 2.6474 - val_acc: 0.2467\n",
      "Epoch 2778/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.2623 - acc: 0.5043 - val_loss: 2.6399 - val_acc: 0.2400\n",
      "Epoch 2779/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2609 - acc: 0.5071 - val_loss: 2.6032 - val_acc: 0.2367\n",
      "Epoch 2780/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2616 - acc: 0.5057 - val_loss: 2.6492 - val_acc: 0.2467\n",
      "Epoch 2781/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2618 - acc: 0.5043 - val_loss: 2.6341 - val_acc: 0.2400\n",
      "Epoch 2782/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2616 - acc: 0.5086 - val_loss: 2.5970 - val_acc: 0.2400\n",
      "Epoch 2783/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2617 - acc: 0.5029 - val_loss: 2.6459 - val_acc: 0.2433\n",
      "Epoch 2784/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2609 - acc: 0.5043 - val_loss: 2.6394 - val_acc: 0.2433\n",
      "Epoch 2785/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2613 - acc: 0.5086 - val_loss: 2.6343 - val_acc: 0.2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2786/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2619 - acc: 0.5071 - val_loss: 2.6525 - val_acc: 0.2467\n",
      "Epoch 2787/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2611 - acc: 0.5043 - val_loss: 2.6293 - val_acc: 0.2367\n",
      "Epoch 2788/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2612 - acc: 0.5057 - val_loss: 2.6566 - val_acc: 0.2400\n",
      "Epoch 2789/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2613 - acc: 0.5029 - val_loss: 2.6504 - val_acc: 0.2433\n",
      "Epoch 2790/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2613 - acc: 0.5071 - val_loss: 2.5977 - val_acc: 0.2367\n",
      "Epoch 2791/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2616 - acc: 0.5057 - val_loss: 2.6218 - val_acc: 0.2400\n",
      "Epoch 2792/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2612 - acc: 0.5043 - val_loss: 2.6387 - val_acc: 0.2367\n",
      "Epoch 2793/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2602 - acc: 0.5086 - val_loss: 2.6185 - val_acc: 0.2367\n",
      "Epoch 2794/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.2614 - acc: 0.5043 - val_loss: 2.6399 - val_acc: 0.2467\n",
      "Epoch 2795/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.2608 - acc: 0.5071 - val_loss: 2.6183 - val_acc: 0.2333\n",
      "Epoch 2796/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2608 - acc: 0.5043 - val_loss: 2.6449 - val_acc: 0.2467\n",
      "Epoch 2797/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2610 - acc: 0.5086 - val_loss: 2.6334 - val_acc: 0.2367\n",
      "Epoch 2798/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2602 - acc: 0.5143 - val_loss: 2.6524 - val_acc: 0.2400\n",
      "Epoch 2799/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2606 - acc: 0.5071 - val_loss: 2.6193 - val_acc: 0.2367\n",
      "Epoch 2800/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2616 - acc: 0.5029 - val_loss: 2.6374 - val_acc: 0.2433\n",
      "Epoch 2801/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2609 - acc: 0.5086 - val_loss: 2.6599 - val_acc: 0.2400\n",
      "Epoch 2802/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2610 - acc: 0.5071 - val_loss: 2.6440 - val_acc: 0.2433\n",
      "Epoch 2803/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2602 - acc: 0.5100 - val_loss: 2.6355 - val_acc: 0.2433\n",
      "Epoch 2804/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2605 - acc: 0.5086 - val_loss: 2.6419 - val_acc: 0.2433\n",
      "Epoch 2805/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2604 - acc: 0.5057 - val_loss: 2.6523 - val_acc: 0.2400\n",
      "Epoch 2806/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2606 - acc: 0.5029 - val_loss: 2.6365 - val_acc: 0.2467\n",
      "Epoch 2807/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2606 - acc: 0.5086 - val_loss: 2.6638 - val_acc: 0.2500\n",
      "Epoch 2808/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2603 - acc: 0.5057 - val_loss: 2.6263 - val_acc: 0.2467\n",
      "Epoch 2809/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2599 - acc: 0.5029 - val_loss: 2.6565 - val_acc: 0.2467\n",
      "Epoch 2810/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2604 - acc: 0.5029 - val_loss: 2.6323 - val_acc: 0.2467\n",
      "Epoch 2811/3000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.2596 - acc: 0.5014 - val_loss: 2.6539 - val_acc: 0.2467\n",
      "Epoch 2812/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2603 - acc: 0.5057 - val_loss: 2.6360 - val_acc: 0.2433\n",
      "Epoch 2813/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2609 - acc: 0.5129 - val_loss: 2.6536 - val_acc: 0.2400\n",
      "Epoch 2814/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2600 - acc: 0.5114 - val_loss: 2.6313 - val_acc: 0.2367\n",
      "Epoch 2815/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2599 - acc: 0.5057 - val_loss: 2.6622 - val_acc: 0.2433\n",
      "Epoch 2816/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2603 - acc: 0.5057 - val_loss: 2.6300 - val_acc: 0.2400\n",
      "Epoch 2817/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2596 - acc: 0.5057 - val_loss: 2.6480 - val_acc: 0.2400\n",
      "Epoch 2818/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2599 - acc: 0.5057 - val_loss: 2.6428 - val_acc: 0.2433\n",
      "Epoch 2819/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2606 - acc: 0.5086 - val_loss: 2.6403 - val_acc: 0.2433\n",
      "Epoch 2820/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2604 - acc: 0.5043 - val_loss: 2.6246 - val_acc: 0.2333\n",
      "Epoch 2821/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2603 - acc: 0.5029 - val_loss: 2.6618 - val_acc: 0.2467\n",
      "Epoch 2822/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2601 - acc: 0.5100 - val_loss: 2.6481 - val_acc: 0.2400\n",
      "Epoch 2823/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2594 - acc: 0.5086 - val_loss: 2.6521 - val_acc: 0.2367\n",
      "Epoch 2824/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2592 - acc: 0.5086 - val_loss: 2.6472 - val_acc: 0.2367\n",
      "Epoch 2825/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2594 - acc: 0.5057 - val_loss: 2.6507 - val_acc: 0.2433\n",
      "Epoch 2826/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2592 - acc: 0.5086 - val_loss: 2.6579 - val_acc: 0.2400\n",
      "Epoch 2827/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2599 - acc: 0.5057 - val_loss: 2.6299 - val_acc: 0.2300\n",
      "Epoch 2828/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2599 - acc: 0.5071 - val_loss: 2.6669 - val_acc: 0.2433\n",
      "Epoch 2829/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2598 - acc: 0.5029 - val_loss: 2.6339 - val_acc: 0.2367\n",
      "Epoch 2830/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2587 - acc: 0.5057 - val_loss: 2.6277 - val_acc: 0.2400\n",
      "Epoch 2831/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2598 - acc: 0.5100 - val_loss: 2.6244 - val_acc: 0.2367\n",
      "Epoch 2832/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2592 - acc: 0.5100 - val_loss: 2.6694 - val_acc: 0.2433\n",
      "Epoch 2833/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2592 - acc: 0.5029 - val_loss: 2.6475 - val_acc: 0.2400\n",
      "Epoch 2834/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2595 - acc: 0.5029 - val_loss: 2.6403 - val_acc: 0.2400\n",
      "Epoch 2835/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2589 - acc: 0.5043 - val_loss: 2.6620 - val_acc: 0.2433\n",
      "Epoch 2836/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2593 - acc: 0.5071 - val_loss: 2.6437 - val_acc: 0.2400\n",
      "Epoch 2837/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2586 - acc: 0.5086 - val_loss: 2.6595 - val_acc: 0.2433\n",
      "Epoch 2838/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2595 - acc: 0.5129 - val_loss: 2.6034 - val_acc: 0.2367\n",
      "Epoch 2839/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2587 - acc: 0.5071 - val_loss: 2.6477 - val_acc: 0.2433\n",
      "Epoch 2840/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2591 - acc: 0.5057 - val_loss: 2.6316 - val_acc: 0.2367\n",
      "Epoch 2841/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2587 - acc: 0.5086 - val_loss: 2.6283 - val_acc: 0.2400\n",
      "Epoch 2842/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2589 - acc: 0.5114 - val_loss: 2.6441 - val_acc: 0.2367\n",
      "Epoch 2843/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2590 - acc: 0.5071 - val_loss: 2.6512 - val_acc: 0.2367\n",
      "Epoch 2844/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2585 - acc: 0.5086 - val_loss: 2.6508 - val_acc: 0.2467\n",
      "Epoch 2845/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2593 - acc: 0.5071 - val_loss: 2.6610 - val_acc: 0.2367\n",
      "Epoch 2846/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2581 - acc: 0.5129 - val_loss: 2.6929 - val_acc: 0.2467\n",
      "Epoch 2847/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2586 - acc: 0.5086 - val_loss: 2.6557 - val_acc: 0.2433\n",
      "Epoch 2848/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2580 - acc: 0.5071 - val_loss: 2.6350 - val_acc: 0.2367\n",
      "Epoch 2849/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2585 - acc: 0.5057 - val_loss: 2.6545 - val_acc: 0.2367\n",
      "Epoch 2850/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2585 - acc: 0.5071 - val_loss: 2.6507 - val_acc: 0.2400\n",
      "Epoch 2851/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2587 - acc: 0.5071 - val_loss: 2.6475 - val_acc: 0.2333\n",
      "Epoch 2852/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2584 - acc: 0.5100 - val_loss: 2.6819 - val_acc: 0.2467\n",
      "Epoch 2853/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.2582 - acc: 0.5057 - val_loss: 2.6705 - val_acc: 0.2433\n",
      "Epoch 2854/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2587 - acc: 0.5029 - val_loss: 2.6258 - val_acc: 0.2333\n",
      "Epoch 2855/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2581 - acc: 0.5086 - val_loss: 2.6606 - val_acc: 0.2367\n",
      "Epoch 2856/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2582 - acc: 0.5043 - val_loss: 2.6605 - val_acc: 0.2367\n",
      "Epoch 2857/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2580 - acc: 0.5086 - val_loss: 2.6737 - val_acc: 0.2467\n",
      "Epoch 2858/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2578 - acc: 0.5071 - val_loss: 2.6742 - val_acc: 0.2467\n",
      "Epoch 2859/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2579 - acc: 0.5029 - val_loss: 2.6399 - val_acc: 0.2367\n",
      "Epoch 2860/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2580 - acc: 0.5100 - val_loss: 2.6139 - val_acc: 0.2367\n",
      "Epoch 2861/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2581 - acc: 0.5100 - val_loss: 2.6635 - val_acc: 0.2433\n",
      "Epoch 2862/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2577 - acc: 0.5057 - val_loss: 2.6548 - val_acc: 0.2400\n",
      "Epoch 2863/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.2574 - acc: 0.5071 - val_loss: 2.6521 - val_acc: 0.2433\n",
      "Epoch 2864/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2578 - acc: 0.5029 - val_loss: 2.6428 - val_acc: 0.2400\n",
      "Epoch 2865/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2582 - acc: 0.5129 - val_loss: 2.6618 - val_acc: 0.2400\n",
      "Epoch 2866/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2580 - acc: 0.5100 - val_loss: 2.6663 - val_acc: 0.2400\n",
      "Epoch 2867/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2574 - acc: 0.5143 - val_loss: 2.6630 - val_acc: 0.2433\n",
      "Epoch 2868/3000\n",
      "700/700 [==============================] - 0s 199us/step - loss: 1.2581 - acc: 0.5071 - val_loss: 2.6285 - val_acc: 0.2333\n",
      "Epoch 2869/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2575 - acc: 0.5057 - val_loss: 2.6494 - val_acc: 0.2400\n",
      "Epoch 2870/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2571 - acc: 0.5071 - val_loss: 2.7058 - val_acc: 0.2467\n",
      "Epoch 2871/3000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.2579 - acc: 0.5086 - val_loss: 2.6527 - val_acc: 0.2367\n",
      "Epoch 2872/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2575 - acc: 0.5086 - val_loss: 2.6646 - val_acc: 0.2400\n",
      "Epoch 2873/3000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.2572 - acc: 0.5100 - val_loss: 2.6330 - val_acc: 0.2333\n",
      "Epoch 2874/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2567 - acc: 0.5129 - val_loss: 2.6279 - val_acc: 0.2367\n",
      "Epoch 2875/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2573 - acc: 0.5100 - val_loss: 2.6572 - val_acc: 0.2433\n",
      "Epoch 2876/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2584 - acc: 0.5057 - val_loss: 2.6874 - val_acc: 0.2467\n",
      "Epoch 2877/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2575 - acc: 0.5086 - val_loss: 2.6719 - val_acc: 0.2433\n",
      "Epoch 2878/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2570 - acc: 0.5086 - val_loss: 2.6541 - val_acc: 0.2433\n",
      "Epoch 2879/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2563 - acc: 0.5100 - val_loss: 2.6676 - val_acc: 0.2467\n",
      "Epoch 2880/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2565 - acc: 0.5100 - val_loss: 2.6745 - val_acc: 0.2400\n",
      "Epoch 2881/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2576 - acc: 0.5129 - val_loss: 2.6611 - val_acc: 0.2400\n",
      "Epoch 2882/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2572 - acc: 0.5129 - val_loss: 2.6494 - val_acc: 0.2433\n",
      "Epoch 2883/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2562 - acc: 0.5114 - val_loss: 2.6251 - val_acc: 0.2400\n",
      "Epoch 2884/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2567 - acc: 0.5086 - val_loss: 2.6911 - val_acc: 0.2433\n",
      "Epoch 2885/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2571 - acc: 0.5043 - val_loss: 2.6378 - val_acc: 0.2333\n",
      "Epoch 2886/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2571 - acc: 0.5100 - val_loss: 2.6531 - val_acc: 0.2400\n",
      "Epoch 2887/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2570 - acc: 0.5157 - val_loss: 2.6738 - val_acc: 0.2433\n",
      "Epoch 2888/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2567 - acc: 0.5071 - val_loss: 2.6808 - val_acc: 0.2467\n",
      "Epoch 2889/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2570 - acc: 0.5114 - val_loss: 2.6366 - val_acc: 0.2400\n",
      "Epoch 2890/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2566 - acc: 0.5129 - val_loss: 2.6421 - val_acc: 0.2367\n",
      "Epoch 2891/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2569 - acc: 0.5057 - val_loss: 2.6623 - val_acc: 0.2433\n",
      "Epoch 2892/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2571 - acc: 0.5029 - val_loss: 2.6626 - val_acc: 0.2400\n",
      "Epoch 2893/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2576 - acc: 0.5071 - val_loss: 2.6582 - val_acc: 0.2433\n",
      "Epoch 2894/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2566 - acc: 0.5057 - val_loss: 2.6879 - val_acc: 0.2467\n",
      "Epoch 2895/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2563 - acc: 0.5114 - val_loss: 2.6713 - val_acc: 0.2367\n",
      "Epoch 2896/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2563 - acc: 0.5071 - val_loss: 2.6687 - val_acc: 0.2400\n",
      "Epoch 2897/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2562 - acc: 0.5129 - val_loss: 2.6977 - val_acc: 0.2433\n",
      "Epoch 2898/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2561 - acc: 0.5071 - val_loss: 2.6830 - val_acc: 0.2400\n",
      "Epoch 2899/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2566 - acc: 0.5100 - val_loss: 2.6664 - val_acc: 0.2433\n",
      "Epoch 2900/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2557 - acc: 0.5100 - val_loss: 2.6613 - val_acc: 0.2433\n",
      "Epoch 2901/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2562 - acc: 0.5114 - val_loss: 2.6582 - val_acc: 0.2400\n",
      "Epoch 2902/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2564 - acc: 0.5100 - val_loss: 2.6989 - val_acc: 0.2433\n",
      "Epoch 2903/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2567 - acc: 0.5100 - val_loss: 2.6535 - val_acc: 0.2367\n",
      "Epoch 2904/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 105us/step - loss: 1.2564 - acc: 0.5086 - val_loss: 2.6508 - val_acc: 0.2400\n",
      "Epoch 2905/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2562 - acc: 0.5129 - val_loss: 2.6706 - val_acc: 0.2433\n",
      "Epoch 2906/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2560 - acc: 0.5086 - val_loss: 2.6644 - val_acc: 0.2367\n",
      "Epoch 2907/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2551 - acc: 0.5071 - val_loss: 2.6734 - val_acc: 0.2433\n",
      "Epoch 2908/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2554 - acc: 0.5143 - val_loss: 2.6629 - val_acc: 0.2367\n",
      "Epoch 2909/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2554 - acc: 0.5071 - val_loss: 2.6449 - val_acc: 0.2367\n",
      "Epoch 2910/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2559 - acc: 0.5129 - val_loss: 2.6514 - val_acc: 0.2367\n",
      "Epoch 2911/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2559 - acc: 0.5043 - val_loss: 2.6324 - val_acc: 0.2333\n",
      "Epoch 2912/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2561 - acc: 0.5086 - val_loss: 2.6377 - val_acc: 0.2333\n",
      "Epoch 2913/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.2564 - acc: 0.5043 - val_loss: 2.6074 - val_acc: 0.2400\n",
      "Epoch 2914/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2558 - acc: 0.5071 - val_loss: 2.6577 - val_acc: 0.2400\n",
      "Epoch 2915/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2561 - acc: 0.5071 - val_loss: 2.6349 - val_acc: 0.2367\n",
      "Epoch 2916/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2557 - acc: 0.5057 - val_loss: 2.6882 - val_acc: 0.2433\n",
      "Epoch 2917/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2555 - acc: 0.5114 - val_loss: 2.6642 - val_acc: 0.2433\n",
      "Epoch 2918/3000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.2552 - acc: 0.5114 - val_loss: 2.6797 - val_acc: 0.2467\n",
      "Epoch 2919/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.2550 - acc: 0.5071 - val_loss: 2.6805 - val_acc: 0.2433\n",
      "Epoch 2920/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2555 - acc: 0.5100 - val_loss: 2.6518 - val_acc: 0.2333\n",
      "Epoch 2921/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2553 - acc: 0.5143 - val_loss: 2.6436 - val_acc: 0.2333\n",
      "Epoch 2922/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2550 - acc: 0.5057 - val_loss: 2.6745 - val_acc: 0.2400\n",
      "Epoch 2923/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2548 - acc: 0.5129 - val_loss: 2.6536 - val_acc: 0.2333\n",
      "Epoch 2924/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2553 - acc: 0.5086 - val_loss: 2.6703 - val_acc: 0.2367\n",
      "Epoch 2925/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2549 - acc: 0.5100 - val_loss: 2.6935 - val_acc: 0.2400\n",
      "Epoch 2926/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2552 - acc: 0.5114 - val_loss: 2.6729 - val_acc: 0.2433\n",
      "Epoch 2927/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2553 - acc: 0.5129 - val_loss: 2.7064 - val_acc: 0.2467\n",
      "Epoch 2928/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2552 - acc: 0.5100 - val_loss: 2.6590 - val_acc: 0.2433\n",
      "Epoch 2929/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2550 - acc: 0.5086 - val_loss: 2.6724 - val_acc: 0.2433\n",
      "Epoch 2930/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2540 - acc: 0.5086 - val_loss: 2.7036 - val_acc: 0.2467\n",
      "Epoch 2931/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2553 - acc: 0.5100 - val_loss: 2.6961 - val_acc: 0.2400\n",
      "Epoch 2932/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2547 - acc: 0.5043 - val_loss: 2.6663 - val_acc: 0.2433\n",
      "Epoch 2933/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2545 - acc: 0.5071 - val_loss: 2.6628 - val_acc: 0.2400\n",
      "Epoch 2934/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2553 - acc: 0.5157 - val_loss: 2.6834 - val_acc: 0.2400\n",
      "Epoch 2935/3000\n",
      "700/700 [==============================] - 0s 55us/step - loss: 1.2551 - acc: 0.5129 - val_loss: 2.6684 - val_acc: 0.2400\n",
      "Epoch 2936/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2541 - acc: 0.5114 - val_loss: 2.6563 - val_acc: 0.2400\n",
      "Epoch 2937/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2549 - acc: 0.5129 - val_loss: 2.6863 - val_acc: 0.2433\n",
      "Epoch 2938/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2556 - acc: 0.5071 - val_loss: 2.6690 - val_acc: 0.2400\n",
      "Epoch 2939/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.2544 - acc: 0.5114 - val_loss: 2.6370 - val_acc: 0.2333\n",
      "Epoch 2940/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2543 - acc: 0.5086 - val_loss: 2.6654 - val_acc: 0.2333\n",
      "Epoch 2941/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2534 - acc: 0.5100 - val_loss: 2.6571 - val_acc: 0.2400\n",
      "Epoch 2942/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.2569 - acc: 0.5114 - val_loss: 2.6795 - val_acc: 0.2367\n",
      "Epoch 2943/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2539 - acc: 0.5157 - val_loss: 2.6976 - val_acc: 0.2433\n",
      "Epoch 2944/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2542 - acc: 0.5143 - val_loss: 2.6760 - val_acc: 0.2400\n",
      "Epoch 2945/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2539 - acc: 0.5114 - val_loss: 2.6943 - val_acc: 0.2467\n",
      "Epoch 2946/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2540 - acc: 0.5100 - val_loss: 2.6940 - val_acc: 0.2400\n",
      "Epoch 2947/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2546 - acc: 0.5100 - val_loss: 2.6620 - val_acc: 0.2400\n",
      "Epoch 2948/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2542 - acc: 0.5057 - val_loss: 2.6824 - val_acc: 0.2400\n",
      "Epoch 2949/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2549 - acc: 0.5129 - val_loss: 2.6700 - val_acc: 0.2367\n",
      "Epoch 2950/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2538 - acc: 0.5143 - val_loss: 2.6728 - val_acc: 0.2433\n",
      "Epoch 2951/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2543 - acc: 0.5086 - val_loss: 2.7112 - val_acc: 0.2400\n",
      "Epoch 2952/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2541 - acc: 0.5100 - val_loss: 2.6802 - val_acc: 0.2367\n",
      "Epoch 2953/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2537 - acc: 0.5100 - val_loss: 2.6804 - val_acc: 0.2433\n",
      "Epoch 2954/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2546 - acc: 0.5100 - val_loss: 2.6809 - val_acc: 0.2367\n",
      "Epoch 2955/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.2536 - acc: 0.5100 - val_loss: 2.6526 - val_acc: 0.2400\n",
      "Epoch 2956/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2551 - acc: 0.5100 - val_loss: 2.6885 - val_acc: 0.2367\n",
      "Epoch 2957/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2540 - acc: 0.5157 - val_loss: 2.6880 - val_acc: 0.2433\n",
      "Epoch 2958/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.2543 - acc: 0.5100 - val_loss: 2.6772 - val_acc: 0.2433\n",
      "Epoch 2959/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2540 - acc: 0.5100 - val_loss: 2.6684 - val_acc: 0.2367\n",
      "Epoch 2960/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2540 - acc: 0.5143 - val_loss: 2.6732 - val_acc: 0.2400\n",
      "Epoch 2961/3000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.2533 - acc: 0.5143 - val_loss: 2.6702 - val_acc: 0.2367\n",
      "Epoch 2962/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2539 - acc: 0.5100 - val_loss: 2.6796 - val_acc: 0.2433\n",
      "Epoch 2963/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2531 - acc: 0.5143 - val_loss: 2.6794 - val_acc: 0.2367\n",
      "Epoch 2964/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2536 - acc: 0.5086 - val_loss: 2.6763 - val_acc: 0.2367\n",
      "Epoch 2965/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2540 - acc: 0.5114 - val_loss: 2.5946 - val_acc: 0.2333\n",
      "Epoch 2966/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2542 - acc: 0.5057 - val_loss: 2.6584 - val_acc: 0.2267\n",
      "Epoch 2967/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2537 - acc: 0.5100 - val_loss: 2.6580 - val_acc: 0.2367\n",
      "Epoch 2968/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.2533 - acc: 0.5057 - val_loss: 2.6944 - val_acc: 0.2400\n",
      "Epoch 2969/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2535 - acc: 0.5100 - val_loss: 2.6882 - val_acc: 0.2400\n",
      "Epoch 2970/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.2526 - acc: 0.5086 - val_loss: 2.7095 - val_acc: 0.2433\n",
      "Epoch 2971/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2532 - acc: 0.5129 - val_loss: 2.6600 - val_acc: 0.2367\n",
      "Epoch 2972/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2538 - acc: 0.5114 - val_loss: 2.6618 - val_acc: 0.2367\n",
      "Epoch 2973/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2531 - acc: 0.5086 - val_loss: 2.6548 - val_acc: 0.2367\n",
      "Epoch 2974/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2529 - acc: 0.5114 - val_loss: 2.6599 - val_acc: 0.2400\n",
      "Epoch 2975/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.2533 - acc: 0.5143 - val_loss: 2.6841 - val_acc: 0.2367\n",
      "Epoch 2976/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2530 - acc: 0.5129 - val_loss: 2.6868 - val_acc: 0.2367\n",
      "Epoch 2977/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2526 - acc: 0.5100 - val_loss: 2.6966 - val_acc: 0.2367\n",
      "Epoch 2978/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2525 - acc: 0.5129 - val_loss: 2.6889 - val_acc: 0.2433\n",
      "Epoch 2979/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2526 - acc: 0.5143 - val_loss: 2.6521 - val_acc: 0.2367\n",
      "Epoch 2980/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2524 - acc: 0.5071 - val_loss: 2.7022 - val_acc: 0.2467\n",
      "Epoch 2981/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2529 - acc: 0.5114 - val_loss: 2.6881 - val_acc: 0.2333\n",
      "Epoch 2982/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2527 - acc: 0.5114 - val_loss: 2.6592 - val_acc: 0.2367\n",
      "Epoch 2983/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2527 - acc: 0.5100 - val_loss: 2.6924 - val_acc: 0.2333\n",
      "Epoch 2984/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2523 - acc: 0.5114 - val_loss: 2.6905 - val_acc: 0.2433\n",
      "Epoch 2985/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2526 - acc: 0.5114 - val_loss: 2.6946 - val_acc: 0.2433\n",
      "Epoch 2986/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2522 - acc: 0.5129 - val_loss: 2.6877 - val_acc: 0.2367\n",
      "Epoch 2987/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2524 - acc: 0.5129 - val_loss: 2.6990 - val_acc: 0.2400\n",
      "Epoch 2988/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2526 - acc: 0.5143 - val_loss: 2.6977 - val_acc: 0.2367\n",
      "Epoch 2989/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2522 - acc: 0.5057 - val_loss: 2.6536 - val_acc: 0.2400\n",
      "Epoch 2990/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2525 - acc: 0.5129 - val_loss: 2.6919 - val_acc: 0.2433\n",
      "Epoch 2991/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2527 - acc: 0.5129 - val_loss: 2.6743 - val_acc: 0.2400\n",
      "Epoch 2992/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2527 - acc: 0.5143 - val_loss: 2.6752 - val_acc: 0.2467\n",
      "Epoch 2993/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2521 - acc: 0.5100 - val_loss: 2.6870 - val_acc: 0.2400\n",
      "Epoch 2994/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.2524 - acc: 0.5114 - val_loss: 2.6820 - val_acc: 0.2400\n",
      "Epoch 2995/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2519 - acc: 0.5086 - val_loss: 2.6994 - val_acc: 0.2467\n",
      "Epoch 2996/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.2522 - acc: 0.5143 - val_loss: 2.7000 - val_acc: 0.2467\n",
      "Epoch 2997/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2518 - acc: 0.5086 - val_loss: 2.6725 - val_acc: 0.2367\n",
      "Epoch 2998/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2524 - acc: 0.5143 - val_loss: 2.6977 - val_acc: 0.2333\n",
      "Epoch 2999/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2522 - acc: 0.5100 - val_loss: 2.6860 - val_acc: 0.2367\n",
      "Epoch 3000/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.2518 - acc: 0.5129 - val_loss: 2.7011 - val_acc: 0.2467\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAEKCAYAAAChTwphAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnWd4VEUXgN+TAAm9Kh0BAaWDgIIoYEMRxYYKiiIWREWw4CfYsDdQAUURBRFFEcSCiKAoVUF6700INZQAISGknO/H7GZLdpNNsps67/PcZ++devZucs89M2fOiKpisVgsFkt+ICy3BbBYLBaLJVCs0rJYLBZLvsEqLYvFYrHkG6zSslgsFku+wSoti8ViseQbrNKyWCwWS77BKi2LxWKx5Bus0rJYLBZLvsEqLYvFYrHkG4rktgCZJSwsTIsXL57bYlgsFku+Ii4uTlU13xsq+U5pFS9enNOnT+e2GBaLxZKvEJH43JYhGOR7rWuxWCyWwoNVWhaLxWLJN1ilZbFYLJZ8Q76b0/JFYmIiUVFRnDlzJrdFybdERkZSo0YNihYtmtuiWCwWi18KhNKKioqidOnS1K5dGxHJbXHyHarK0aNHiYqKok6dOrktjsVisfilQAwPnjlzhooVK1qFlUVEhIoVK1pL1WKx5HkKhNICrMLKJvb+WSyW/ECBUVoWi8WSm+zbB7/8Enj5o0dh6lTPtPXr4f33YeHwf5kw/Ai6azfYERAPrNIKAjExMXz88cdZqnv99dcTExMTcPmXX36Z4cOHZ6kvi8USGpKToUYN6NYNVGHDBnjpJXPuzYaVCbzY5Edu7XqGO+4wZfv3h5ce3EfTpvD009DhmUvo80wlwurWRopHIgIicHDT8Zz/cnmMAuGIkds4ldajjz6aJi85OZnw8HC/dWfOnBlK0SwWSwaoGoXgzsGD0KwZ/PknNG3qUj7e5S65BB5+GBo0cKX9+SfcdRdER8Ps2XD//VCvHlx9NVx2GSxaFAHcklq+SRPnWfUMZa3aqLxPRViYsJZWEBg8eDA7duygRYsWPPPMM8ybN48rrriCu+66i6ZNmwJw880306pVKxo3bszYsWNT69auXZsjR46we/duGjZsyEMPPUTjxo3p3Lkz8fHpR11ZvXo1bdu2pVmzZtxyyy0cP27ewkaNGkWjRo1o1qwZPXr0AGD+/Pm0aNGCFi1a0LJlS06dOhWiu2Gx5B82boSwMPjpJ1i3zpU+ZYpROs2awZAhpsw555ghwKNHIT4eliyBpUvhgQfg8stddQcNgrg4c750KfTrZxQWwKJFOffdCiqi+UxtlyxZUr1jD27atImGDRsCsG3bE8TGrg5qn6VKtaB+/RF+83fv3s0NN9zA+vXrAZg3bx5du3Zl/fr1qS7kx44do0KFCsTHx9OmTRvmz59PxYoVqV27NsuXLyc2NpZ69eqxfPlyWrRowR133EG3bt3o1auXR18vv/wypUqVYtCgQTRr1owPP/yQjh078tJLL3Hy5ElGjBhBtWrV2LVrFxEREcTExFCuXDluvPFGBg8eTPv27YmNjSUyMpIiRTwNbff7aLHkJrt2wfbtcM01vvNnzjQWUM2akJAA330H99wDEyfCnXdCZKSr7JIlUKKEUUDejB9vlI6TtWtNu3nZLymrj2wRiVPVksGVJuexllaIuPjiiz3WPI0aNYrmzZvTtm1b9u7dy7Zt29LUqVOnDi1atACgVatW7N6922/7J06cICYmho4dOwLQu3dvFixYAECzZs24++67+frrr1MVU/v27XnqqacYNWoUMTExaRSWxZKXqFcPOnf2nacKXbtCrVpmGC8yEnr3NhbNfffBbbdBw4ZGkQ0fDu3aQfPmRhHVqwdPPAH79xvF+Mwznm3v2WPmmPIqax/5JLdFyHUK3JMrPYsoJylZ0vVCM2/ePObMmcPixYspUaIEnTp18rkmKiIiIvU8PDw8w+FBf/z6668sWLCA6dOn89prr7FhwwYGDx5M165dmTlzJm3btmXOnDlceOGFWWrfYgkE77miVavghhuMNVOxokm75RbjMXfuuWb+p3lzmDABUlJM/t69UL26GZ5zWhgJCa42b77Zde4cdXdOEztGxj3YsQNGjoQtW2DWrLT5N9yQpa+aI1zK3zS9rUHGBbOBiFwHjATCgc9V9W2v/PuAYcA+R9JHqvq5I6838IIj/XVV/TIUMlpLKwiULl063TmiEydOUL58eUqUKMHmzZtZsmRJtvssW7Ys5cuXZ+HChQB89dVXdOzYkZSUFPbu3csVV1zBu+++S0xMDLGxsezYsYOmTZvy7LPP0rp1azZv3pxtGSwWf0ydahTNb7+Z65QU6NXLWDjvvQdJSUYJ/fSTGQb85x/4+GPYudNYQk5q1YLwcKP8wsLM4b6d3r//Zk0+XworL/E6z7OV+pzLIU5TghEM5PtSfeCqq0LWp4iEA6OBLkAjoKeINPJR9DtVbeE4nAqrAjAUuAS4GBgqIuVDIWeBs7Ryg4oVK9K+fXuaNGlCly5d6Nq1q0f+ddddx5gxY2jWrBkXXHABbdu2DUq/X375Jf369SMuLo66devyxRdfkJycTK9evThx4gSqypNPPkm5cuV48cUXmTt3LuHh4TRq1IguXboERQaLxZulS+GOO8z5yy+beammTcH5nvTWW+Zwec0Znn3WfK5cmWOiZouLLoL4mAQ27YzIuLAP9lKDmkRxJX9yN5NowWrCSaYiR6nhMGQOUQWAgYyC8xoHTXY/XAxsV9WdACIyGbgJ2BhA3WuBP1T1mKPuH8B1wLdBl1JV89VRokQJ9Wbjxo1p0iyZx97HwsuZM6oDB6oeO+aZPmKEau3aqikpqt9+q/rjjyb9zz9N3oABps7zz6vWr6/ar59q2bKqxo4qOMfff6tecYXrunqZE6ozZ+r+yi3SlD1AZd1LdV3EpQqqk+ipW6mnpymuJymla2misZRQBT1GOT1DsYwFCAtTXb06W78xcFrTebYC3TFDgs7rezDDf+5l7gMOAGuB74GajvRBwAtu5V4EBqXXX1aPXFM+WT2s0god9j4WXsaNM0+D8HDVq69WXbrU85m5ebPrvGlTz7wHHwy90gjWUaGCao0aGZcb/sYZj2vdvt3cqL170xTuzygF1aEM1c+5P/NCXX6567xcOfN5662utJiYoPzGQAKw3O3oq27PVuB2H0rrQ68yFYEIx3k/4C/H+TM+lNbT7nWDddg5LYslH1Khghmeyoj//jPzQZMnu9JUzfokMGuRDh+Gs2fNdXIyzJkDF1/s2c6117rO3dczAXz+eeblzw1GjzZrrHbs8Ew/dQo++ACiolxpT6/tTQrC+0Oi2U9V43aYkmK8Sbz4kAEowsu8wgOMz7xg//uf69zZfp8+rrR0ghNkkiRVbe12jPXKjwJqul3XAPa7F1DVo6rqdIX5DGgVaN2gEQpNGMrDWlqhw97H/IPzJdxpAKiq7tunOmuWZ7kffjDlbrnFXB88qHrnnSbts89c7Zx7buYNhLxwvPmmauvWrut581QHD1bds0e1QwdX+jffpL2HF11k8tzZulV1yxZVbd7cZI4YEfov4f6D+vqR4+Ky9bfiai7D4cEiwE6gDlAMWAM09ipT1e38FmCJ47wCsAso7zh2ARXS6y+rR9AbdPtCNYG5wCZgAzDQT7lOwGpHmfkZtWuVVuiw9zH/4P3MUzVzT+7XmzerNmzoKlerVuifv8E8PvzQd/qNN3p+92XL0t4LVTPvBqqLF/u+h/Hbo/TYjfeqxsamzWzQIDhf4sknVXv3dl23bGk+27QxX3DePM8f1NePnJCQqb8Nf2SktEwRrge2AjuA5x1prwLdHOdvOZ7VaxzP9wvd6t4PbHccfTLqK6tHSBp1fIGqwEWO89KOG9HIq0w5jGdKLcf1uRm1a5VW6LD3Mf/g/lycM0c1Ksp1/eKLZp4pkLmbnDqc82A9enimR0b6r7N4sfl88EHznU+cUL32WtXdu1XHj1d95RWTnpCg2q2b6po1mbyJ99xjOnj3XdXXXjPeJr17q44aFbwv7sR5AyZOdH36+kF9pSUlZfKL+SYQpZUfjpzrCH4GrvFKexSzCC3gdqzSCh32PuYPjhwJ3jM11Mf06WnlnzhRdcUK1U8/Vd20yXguvvJK2ropKSG8ibGxqjfcENov/847rv46dTJpGzeqHj+eVp66dY17ojtBvhEFRWnlyDotEakNtAS8lwI2AIqKyDyMNTZSVSf6qN8X6AtQrFixUIqaY5QqVYrY2NiA0y2Fl99/N2uaqlUz15Uq5a483vTtC2vWeC70nToV2reHqlXTlr/nHvPp7kjy0kvw2GOwdSsUKwZVqgQp/t/KldCqlYnzNGGCidHkvUAsVNSv7zqfPNlE4b3wQt9fzNs7xJ28HAgxNwi1VgRKASuAW33kfQQsAUoClYBtQIP02isollbJkiUzlZ4T5Mf7WFBISVEdOlR1yhSXo8SDD5oXc+cLd716Zookp6yk8HCXq3tYmOqBA6qnT3uWGT7cyP/jj+Y6IsJ87t6dAzft8GHVHTtc18nJZpw0MVF1/34jhLuw994bmht14IDrfNQo1ffeU/311+x/v7/+Un300ey344ACYmmFtnEoCswGnvKTPxh42e16HHB7em3mRaX1v//9T0ePHp16PXToUB0+fLieOnVKr7zySm3ZsqU2adJEf/rpp9QyGSmtlJQUHTRokDZu3FibNGmikydPVlXV/fv36+WXX67NmzfXxo0b64IFCzQpKUl79+6dWvb999/P0vfI7ftY0Pj6azMqFAi7doXmeRrI4b3uqls31TvuUP33XzN051RggdCsmSm/Z0+Wb1vgFHMsynXy+uuhuUEdO3peP/OM+ezVy7hs+pIlD1JQlFbIhgdFRBxKaJOqvu+n2M/ARyJSBONieQnwQbY6fuIJWB3crUlo0QJG+A/E26NHD5544onUTSCnTJnCrFmziIyM5Mcff6RMmTIcOXKEtm3b0q1bNyQAc/+HH35g9erVrFmzhiNHjtCmTRs6dOjAN998w7XXXsvzzz9PcnIycXFxrF69mn379qVujZKZnZAtocN9V5nt2806oCuugOXLzYiVk4MH4euvc06uTp1g3jzX9dq1Zg1T//5maO7nn115ycnmM5A1YQAzZsD335stQ0KOc3GZk99/D00/M2eaNVqNGpkIvt27wx9/mBhVzjHbtWth8eLQ9G/xIJRzWu0xK6rXiYhTizwH1AJQ1TGquklEZmFCgqRgVmOvD6FMIaFly5YcPnyY/fv3Ex0dTfny5alVqxaJiYk899xzLFiwgLCwMPbt28ehQ4eoUqVKhm0uWrSInj17Eh4eTuXKlenYsSPLli2jTZs23H///SQmJnLzzTfTokUL6taty86dO3n88cfp2rUrnf3t6WAJCklJZs6mR4/Aphv27PGc3rj6ahg1ysztnDzpe94nlPz1l5kzOnzY9S722GNmF17vP83wcJg/P/BpoJo14ckngyuvT9zfCBITjbYNFRER5kZcdJFRWjVrpl1kfMEF5rCEnJApLVVdBGT4L62qwzCh7oNDOhZRKOnevTvff/89Bw8eTN0teNKkSURHR7NixQqKFi1K7dq1fW5J4gtjzaelQ4cOLFiwgF9//ZV77rmHZ555hnvvvZc1a9Ywe/ZsRo8ezZQpUxg/Pgsr8y3pcvYsPP88lCwJr7xirnv3duUvXmwcEtauhU/ctj06cMCznZgYuPdec+Qkx48bmUVMpIwtWzw3Rmzd2ne9Dh1yRj7AjJLMmAEvvOC/zBNPwKRJrutgKawqVYzZC8aqWr0aTpxwRaT46itYtizn3zIsnuT2+GRmj7w4p6Wqun79em3Xrp3Wr19f9+/fr6qqI0aM0P79+6uq6l9//aWA7tq1S1UzntOaNm2adu7cWZOSkvTw4cNaq1YtPXDggO7evVsTExNVVfWDDz7QgQMHanR0tJ44cUJVVVetWqXNmzfP0nfIC/cxLzN+fNrpDndya07KvW/Hn5t+8olnmbp1c/ZeZZmwMCNwSoo5PvpIdedO4+zwyCPBWUM1cKCJ9DtmjLl+4AHjAn/mjAnCGBWV23chJFBA5rRyXYDMHnlVaamqNmnSRDu5zbxHR0dr27ZttVWrVvrAAw/ohRdeGLDS8ueIMWHCBG3cuLG2aNFCL7vsMt25c6euXr1aW7Zsqc2bN9fmzZvrzJkzsyR/XrmPuc2ll5r/jJMnzfW2beaZ6fSM8z4WL1atXDn7z9JAjosvVn3iCdVLLjHXQ4caGcHI4M6CBapTp6q+/7557ucpVqwwQrt7/6m6vmhysupbbwXvxjnXSbm/aWzfbq7//jtnv3suYZVWLh15WWnldwrzfTxzRvXxx43Xm/uz7osvMn4elioVvGerv2PGDJcSVTVGyM8/G+9uVdV//jGKNd/Qv7/5Yk8/bSKnO3F+4auuyv5NGz5ctWZN4x6pqlqnjnoorUJGQVFaYr5L/qFkyZJ6+vRpj7RNmzbRsGHDXJKo4FCY72PVqq7pjNxm+XIoW9acR0SYnXrz2oLibKEKt95qti12Mm6c2SnSO7x8Zhg3Dh54wLMfd44eNROMObW4OI8hInGqWjK35cgudmsSS6Fj7FjjjCACf/9t0vKKwgLjnFavnjlq1ixgCgvgiy88FRYYZZMdhQVw//1mbQFAnTpp8ytWLLQKqyBRYJRWfrMY8xoF8f5t3mwU0x9/QMOG5vzwYXj4YVeZyy7L+Sg5M2fCokVp08uXN59hBea/EjhzBoYPN5t0nTpl0hYuDH4/GzaYzxIlzKf7GgNLgaJA/HtERkZy9OjRAvngzQlUlaNHjxIZGZnbogQVp2KYPNkoMIDKlUPfr/uGid4GBUCXLiYuX6NGrrTY2AKkrGJjzWIwMGObzzwD11wDZcrAG2+YGICB0rGj67xUKeOW/ttvrrTDh41buvNmVq0K06d77nppKVDkSMDcUFOjRg2ioqKIjo7ObVHyLZGRkdSoUSO3xQgqTiWQkpKz/TZrBrNnm0AqN90ERYqY0a9PP4XnnnOVe/ppk75rl1n75SRPv3vt2WOUQv/+nul790KNGsZsLV3apL32Wtr66a2/8sUPP5g3jaQks6C3Xj3P/HPOSVvnxhsz14clX1EgHDEsFiexsSbixNix0Lx5zvbdqZMJezRtmnlujh/vaU1lxPnnw86dEB2dh+exGjeGjRtNmIxevcxQ3759xnQcM8b8AIMGBaevZ5+Ft9/2nbdkiZmIvPnm4PRVCCgojhhWaVkKDPv2mZd9MJ9RUcFt/623oE0boxQBWrY0zmhOJ461a40DXFbZudMYFsF65meLlBTj2PDIIya+k5MqVeDQodD126oVrFhhJiKdN9oSFAqK0iooo+iWQsSsWSYUEpgpjTlzzLn76GZWFVbdukY5RUcbJfTyy668wYPhqqtMqKZNm8xWTZdd5so/99ys9ened55QWGBiPn35pZmAi4+HK6801k2oX3KdY7rOIUaLxQurtCx5HlUzPbJ/v1FSXbrAnXeavGuuMcc//2S9/YoVzedVVxmHjcGDzfBc06YwdKjJGzDAVb5ZM7OXH8B995nPBQtyxskjRzh71nVDjx83Hnlz50K7duYHCBa3324+hw93pVWvbj7LlAleP5YChVValjzPJ5+YnW27d4e4OJO2caOZzli71ly3b5/19hs0MIpxzhwoWjRtviqMHOm7bteuJv/yy7Pef57i88/NiuZu3YLXZp8+rnPn+Ono0a79TsqXN8OBs2aZNVzffGPWKFhyHBG5TkS2iMh2ERmcTrnuIqIi0tpxXVtE4kVkteMYEzIZ7ZyWJS8gYuaL5s51edLFxpplPr4cxLJCuXKuYcU//jDGRFiYibZeq1Zw+sh3REfDm2/Cu++a+atx44Lfhyp88AE89ZTp59JLzZGUZIYg77+/APn7510ymtMSkXBgK3ANEAUsA3qq6kavcqWBXzF7IPZX1eUiUhuYoaqhX72d23GkMnv4ij1oyf84w8U1aaI6bZrq/PlZDznn73j7bdf55s25/Y3zADNnql52WXBu7pVXpk3bsUN19WrTV0KC6rvvmk9LrkAGsQeBdsBst+shwBAf5UYANwDzgNaOtNrA+vTaD9ZhX28seYr16+G22zzXlGaV55/3vBYxL/rg2nC2wBMXBxMnmuG+IkVc46mvvgrXX+87NEdmuOMOePFFsweWO6rGs8S57qBYMbPIOJSbNVqyS3Vgr9t1lCMtFRFpCdRUVa8fHIA6IrJKROaLSMgGzAvE4mJL/iY+PvhtvveeGY164w1zXa+e2Sm4alXz7CyQLFliJt+++cYVm6pMGbN4zEl2F68lJBjPlwULjEfKd9+58n7/3Wyc6HSwsOQ1iojIcrfrsao61u3aV0Cz1PkjEQkDPgDu81HuAFBLVY+KSCvgJxFprKongyC3B3ZOyxJ01q41z8bx411z8P/9Z6Ywihc3u6PXrm3SzzvP5GWXSpXgyBFz7v4nPX68mdNv1y77feQZSpUyN/bDD831ggVGGzdo4CrTvDksXWqcKoJFv36eWzJb8hUBzGm1A15W1Wsd10MAVPUtx3VZYAcQ66hSBTgGdFPV5V5tzQMGeacHhVCNOwI1gbnAJmADMDCdsm2AZKB7Ru3aOa28w2+/mQ1f3Rk61HN+6vhx1aee8pzq+Omn4M9XqXqeF2jcv+iCBcG/mb5uriXfQ8ZzWkWAnUAdjJPFGqBxOuXn4ZrTOgcId5zXBfYBFdLrL6tHKOe0koCnVbUh0BZ4TETSBLVxeKy8A8wOoSyWILNtm1kv9eCDrrT4eHjlFdf1+vUm9t7773vWffXV4MgwaRL8+afLI/CRR4LTbp7lwAFwH2W4/HLo0CF0/c2ebW6wpVCgqklAf8yzeBMwRVU3iMirIpLRGogOwFoRWQN8D/RT1WOhkDPHhgdF5GfgI1X9wyv9CSARY23NUNXv02vHDg/mDVavNmGMmjc352Bc1HMqkEFKSs5vKZIjHDliwhi98IKZI/rvP3jsMfjlF9cq6GBxyy0mbpSI8fn/6CMzjvr44yauYNeuwe3PkqsUlDBOOeKI4fDhbwn865VeHbgFuBKjtPzV7wv0BShmvY9yjPPPN9sSzZrlSnv+ebOs59dfzbV7BHX3+f5QU6AU1unTEBkJ4eFm88JYx5RBhQquMsFUWEOGmFhVzpiCsbGmb+fWNN9+G7y+LJYgE3JLS0RKAfOBN1T1B6+8qcB7qrpERCZgLa08hVMxOP9ETpwwC3S9GTDARPqZNctldWWVIkWMw4Y7o0cbF/jPPzce1pUrG2/qAoGqa2FtUpK5AcFk4EAzzDdunPFKufhi6NvXBE5s0cIu6i1EFBRLK6RKS0SKAjMwC9be95G/C5ebZSUgDuirqj62zjNYpZVzeCutG25wWVihYOBA46rufG7Xq2eC0zo3oy1wnD1rwhb162eur7nGhOrILldcYUKLQB7fnMuSkxQUpRWy4UEREWAcsMmXwgJQ1Tpu5SdgLC2/CsuSO8TEGAvLuftvqChe3IxS/fAD3HqrGb0qkAorJcUMz3lviJgdhTVmDNSsaeJede5sJhfLl8+enBZLHiSUYwPtgXuAK92CKF4vIv1EpF8I+7UEgfr1XeeTJhmra8eO4LQdE2OCNIDZMik+3uzi69zV98Yb4X//gxEjgtNfrnPqlJknck4Ovv9+5nfw9ebMGVdQ261b4eGHTYSLW28167gmToRly7LXh8WSB7GLiy0+CYajw9mzrqjpTgeOQYNg2DCT9ssvZj+qAm8QZOVmRkSY6BPutG8Pf/9t9ktx3+jLYgmAgjI8aGdhLWnIzu677rhv8+FUTO7ehjfeWMAU1qlTRkENGGDGOBMSTOyoQDn/fDPMt3OncTkHM+cFJoTIokVmjsoqLEshxlpahYSXXjKhjtw3M5w504xaffWVK23wYHjnnez3V7Kky3MbzAaO7dubPavOPz/77ec5tm/3HFMFs9o50LBHF10ECxe6JvGio80Q4siRxrpq3NhsdW+xZJGCYmlZpVVI8PYEdE+Lj4d164w3dHbYscNsj1S8uLGiGjfOXnt5AlX/vv7ffAOdOrl2280q7dplb+tliyUArNLKJazSyhreSssZ1DZY/PdfAd1I8dNPjUt6y5bGu8+5yPfoUWO6ZpWhQ03bJUqYdVT16gVHXovFDwVFadk5rUJKdhVW9eoQFWWevWCCjBdIJk82n6tWmU24hgwxQ3lZUVhOU3blSjMvdeCAMU+twrJYAsZaWoUEd0vr55/h5puz196RI8EPhZcnadgwOAvUvv4a7r47++1YLFnEWlqWPMnx42YJj5P4eLM3oBORrCms3r3ht9/MEiPVAqSwjh41N6VSJfM5e7bx2CtSxFxnRmFNmpQ2bcwYs8/VddcFT2aLpRBjLa0ChogZvVqxwjignXtu9tv8/XcTYahA8v33wdtpNybGuElWqGACJKoWsMi+lvyMtbQsuc769a7IEu6sXGnWQwVDYUEBUFj798PixeY8Jsa4Nu7fb6537cp6uz17wt69xmVSFcqWNcOJlSubfKuwLJagkyNbk1hCg3MR8L33ms8nn3TlZWXvvvvvN+u52rc3S4Y++wwOHcq+nLlOkyZm3PTAAXj7bZgxI3tu6uPHm3HXhx82wRKdP4DFYgk5dngwH+Ptxp7VF/s77oApU0zsvzfeCI5seQb3rT8yy4ABZuX1pk1w221mke/UqdC9e3BltFhygIIyPGiVVj7GXWnFxZkoFJnl1lvNtM7XX8Odd0K+3mNzzx4TSqlxY5g2LfvKxf1/4+xZ457esGH22rRYcomCorQKzfBgSspZkpNPER5elrCw/P+1161znavCQw9lvo2+fU2UIJHMhcjLdU6fhsREcxMefthEpbjhhuxtD3/DDSYqer16ZviweHHP/GLFrMKyWPIAhcYR48iRH/n770rEx2/NbVGCQrNmrvPkZOMtmFnq1nXtsJ7n2bzZLA6LijJbb5QvDx06mKG7Tz7JvMJq0MB8vvEGzJtnQs4fPGiC0pYrZ6KsWyyFDBG5TkS2iMh2ERmcTrnuIqIi0totbYij3hYRuTZUMuZ/kyNAzCbKoJqYy5LnqNWOAAAgAElEQVRkn+hoz2v3aOrpsWaNMVKuvNKs5UpODr5sISNYVk7z5uYYP944UVgsFgBEJBwYDVwDRAHLRGS6qm70KlcaGAD865bWCOgBNAaqAXNEpIGqBv0pU+iUVkpK/lZa8+eb0bCs4LTOnn7aGBju24TkSf73PzjnHONWnh26dDELhiMioEyZrDtmWCwFm4uB7aq6E0BEJgM3ARu9yr0GvAsMcku7CZisqgnALhHZ7mhvcbCFLHRKKz9bWlFRWVNYF15oRr6cOA2MPKm0Vq+G884zC3Qzy3vvwdKlsGWLa14qNraARvK1WIJOdcD9DTEKuMS9gIi0BGqq6gwRGeRVd4lX3Wxuf+CbQvPKGfHrEi7vArJle26LkmVq1sxavY0b4dgx1/V99xkDJs84X6xYYZTLI4+YaOpZUVgPPghPPWUC3K5aZdZhVahgFZbF4qKIiCx3O/p65ftaNJPqQisiYcAHwNM+yqVbN5iEzNISkZrARKAKkAKMVdWRXmXuBp51XMYCj6jqmpDIE1aE8DPAmbhQNB9S7rrLLBEKhLg41z6CTrzXb9WpA4cPB0e2bNGunZlcW73a7Ay5Y0fgdVXNsN+sWdCmjVk0bLFY0iNJVVunkx8FuL8a1wD2u12XBpoA88Q8VKoA00WkWwB1g0YohweTgKdVdaVj4m6FiPzhNam3C+ioqsdFpAswFi9zNGhEGBdmPRMfkuZDybffBl7W6andvn3gii7H2LoVLrjACNa+vWdeRgqrUiXjPQiu9VMzZ8K+fVCjRvBltVgKH8uA+iJSB9iHcay4y5mpqieA1D15RGQeMEhVl4tIPPCNiLyPccSoDywNhZAhU1qqegA44Dg/JSKbMGOcG93KuG/XugSjnUNDMePbrQn5R2mNHp259bFz5pjPbdvM/laxsZ7rY3OdH380n94KKyOcO0yOHQsdO7rSRazCsliChKomiUh/YDYQDoxX1Q0i8iqwXFWnp1N3g4hMwTzfk4DHQuE5CDnkiCEitYGWuLlI+uAB4Dc/9fsCfQGKZTFkg0Q6FoInnEm/YB7g1Cm49FITEHfKlIzLR0ebWK1O13fnnoJZiZAREqKizJhkUlJg5R94wOzqGxbmGYapr/cQvMViCSaqOhOY6ZX2kp+ynbyu3wBCHggu5I4YIlIKmAY8oaon/ZS5AqO0nvWVr6pjVbW1qrYuUiRrelYi88/w4KRJRmEBLFiQfllVM3IW6FqtHOPYMZgwwbiZ16yZvsJ66y3X+VdfweefGxdHEeuebrFYPAjpE0GMn/k0YJKq/uCnTDPgc+AmVT0aMmEiHN4J+cDSWrYssHKbNoVWjoBRNcELT50yikbE7BLZp4+J2eeP0qXN5+DBJgr7M8+Y6L0Wi8Xih1B6DwowDtikqu/7KVML+AG4R1VDGl8prLhTaSWEsptsk5hogjVkRM2aZv1VjvPDD3D55cZnfvRoMy75ySfwzz8Z13VH1fwWsbHmulw5ePfd4MtrsVgKFKGc02oP3AOsE5HVjrTngFoAqjoGeAmoCHzscKHMyCUz6xRzKK2zeUtpbd8OQ4ea5/4FF3guAk6Pzz4LrVw+OXHCbNHRurUxB/v3z1o7ziG/iAgb489isWSKUHoPLsL3gjP3Mg8CD4ZKBndcjhh5Q2nFxBjjom9fmDvXGC4ZKayiRc362yefhNq1c0RMT5yuiFu2eIaZz4hDh2D3brPY99Ah6/FnsViyTOEJ45RHlFZSEgwfDkOGwE8/ufavmj8/47qdOpmtRHINZ4TdU6c8w8z7ok0bY43FxJghxHPPNelO10aLxWLJAoVGaYUVzxtK64034OWXzfn8+TB7tjlfvdpvldxl0SITYiMyMm14+fRYssQ4YeSbvU8sFkt+oNAoLYlweKrlstLa6BYP5IMPMlfXOxxTyDl40DhdZJbevc28lVVYFoslyBQapRUW6XTEyF2X9927M19nwQKz32HVqkEXJy3//QdHjxqvPvfoE74oXtwEuJ0wwYx7zp0L999vlZXFYgkZhUZpIUJKUXLM0kpONl7gTkNl1y6zQe7STETjmj3b5do+blwOLGGaMgXuvDPw8nFewYftdvQWiyXEFKpwAylFJceU1rvvGuto7lxzXbeuMUICZds26NzZ6AERU7dUqdDICsD33wemsKpVg4kT0180bLFYLCGi8FhagBYTiM8ZpeWMVjFtGlxxRebr54iTXXw8TJ1q5qACZd++0MljsVgKBSLSRFXXZ6VuobK0kouHIXGhV1rDh5sQemCCRmTWgWLevKCLlJZTp4xXYEYK66GHzOfzz2duvyuLxWLxzxgRWSoij4pIucxUFM1Te1dkTMmSJfX06dNZqht3fnES65Sj7JwDQZbKxfLlZolSdgjpT6JqtOKVVwZWfu9euxjYYikAiEicquaVvR8QkfrA/cDtmL23vlDVPzKqV6gsLS0eTlhcYsjaj47OusJq3Di4sqQhMdFMtIWFZaywli835XfvtgrLYrGEBFXdBryA2d2jIzBKRDaLyK3p1StUc1opJYoi8aFTWiNGZL1ez55QuXJw5Unl7Fnjhnj4cMZl586FVq3M+XnnhUggi8VSmHHs7tEH6Ar8Adzo2OW+GrAYE0jdJ4VKaWnxooSfiA1Z+2++mbnyVaqYYLn9+plRu8hIM3UUdDIKSturFzz7rClXv34IBLBYLBYPPgI+A55T1dRNDlV1v4i8kF7FQqW0UkpEEBZ/IrfFSOWA29SaiHHmCwpHjxotOGKEiRvlizZt4PHH4eRJeOyxIHVssVgsGaOqHdLJ+yq9uoVKaWmJCMLik3NbDMAEngg6P/1k1ltNmpR+uWHDzHhk9eohEMJisVjSx+GE8RbQCEgNoaOqdTOqW6iUFiUiCDuTErTmvv7aTBfdfz9Mnpxx+cGDzfBfkSLZjHT03XdmGO+ii4zresuWgbujr1hh6lksFkvu8QUwFPgAuAIzvxXQ4qBC5fJ+7OFWlBu3krCk7H3nSZPMNJCTuDiz5CkjgnarnQu/YmNN1N0XX0y/fJUqsHgxnDmTS9sdWyyW3CYQl3cRuQ4YCYQDn6vq2175/YDHgGQgFuirqhtFpDawCdjiKLpEVful088KVW0lIutUtakjbaGqZhihu1BZWlqyBGHJGPPIuZFVFnBXWAA33JA9uQJixQqza+T557vS0ovrNGMGdO0aerksFkuBQETCgdHANUAUsExEpquq294UfOPYdR4R6Qa8D1znyNuhqi0C7O6MiIQB20SkP7APODeQigGt0xKRgSJSRgzjRGSliHQOULg8g5Q0Lxkpp2KC2u5ff/nP++gj89mlSzY7ad3axHaKzcD78YknzBorq7AsFkvmuBjYrqo7VfUsMBm4yb2Aqp50uywJZHX86AmgBDAAaAX0AgKKJxfo4uL7HcJ2Bs7BjD++nV4FEakpInNFZJOIbBCRgT7KiIiMEpHtIrJWREI72VK2PADJx/eHtBt3nAZdltfoHj8OKW7zcKVL+y87caIZLixSqAxoi8USGEVEZLnb0dcrvzqw1+06ypHmgYg8JiI7gHcxSsdJHRFZJSLzRcTvMJ/DortDVWNVNUpV+6jqbaq6JKAvEUghXBNk12NCbawRyTCiXhLwtGPBWGlghYj84WVqdgHqO45LgE8cn6GhQiUAkqP3UrReoFasITHRTCVlVh/06gV//w2vv565egAcOwYVK2Y8Z5XP5iUtFkuukKSqrdPJ9/VMT/NwUdXRwGgRuQsT0aI3cACopapHRaQV8JOINPayzJz1k0WklYiIZsGpIlBLa4WI/I5RWrMdSihdNzxVPaCqKx3npzCTdN5a+yZgohqWAOVEJGRbHYZVNCEnUo5m3tIqVixzPgzFi7s+J0yAcwMarXWgCtdcA2PGmOvXXktb5tlnjUBffpmJhi0Wi8UvUUBNt+saQHoPy8nAzQCqmqCqRx3nK4AdQIN06q4CfhaRe0TkVucRiJCB2g0PAC2AnaoaJyIVMEOEAeHwLGkJ/OuV5c8cDUlE21SldeRglurv2OE5UueL//0P7r7bOOzFZHbqLD7eZV3NmWMOf7zxBryd7gitxWKxZIZlQH0RqYNxjOgB3OVeQETqO2IGggnBtM2Rfg5wzGFF1cWMnu1Mp68KwFHAPRCqkk74JieBKq12wGpVPS0ivYCLMG6RGSIipYBpwBM+TMWAzFHH2GtfgGLZ8PoLq2QmlvR4ADH4/OC9Wa+T6dPhpptgyBDj5AeZtK7A5TdfpYr/MmvXGm0YHp7Jxi0Wi8U/qprk8OSbjXF5H6+qG0TkVWC5qk4H+ovI1UAicByX80QH4FURScK4w/dT1WPp9BWw0eNNQOu0RGQt0BxoBnwFjANuVdWOGdQrCswAZqvq+z7yPwXmqeq3justQCdV9WtpZWedVvyRdRQ/pxmnnrud0m9MyVTd9GbwwsIgORiBNjKaJvzrr6ztKGmxWAo9eWlrEhH5At/zZRnu7x6opZWkqioiNwEjVXWciKTrnuhw1BgHbPKlsBw4NfdkjAPGifQUVnYJL12F5EjgUHRQ280oHm26HDsGVavC1Vf7L2MdLSwWS8Fihtt5JHAL6c+fpRKo0jolIkOAe4DLHS6LRTOo095Rfp2IrHakPQfUAnAsUJuJce7YDsSRiXmyrFCkaDnOVIKwg0dC2U3mWLfOLHaeOTO3JbFYLJYcQVWnuV+LyLdAOpP4LgJVWndiJuTuV9WDIlILGJaBUIvIIJaUw90xx0KMh4UV5WylMCIOHc9Uvd9/Tz9/ZECze35wrj72R+d8t4bbYrFYMkt9HAZNRgQce1BEKgPOfXmXqmrWvRmyQXbmtACiO5eg7OYiFNuTZvlAGlRNuL6M4gpmafRuwgTo48ew/Ocf2LMHLr/ceBJma/zRYrFY8tyc1ik857QOAkO8LTBfBBrG6Q5gKXA7cAfwr4h0z4KsuU5y5dIUOXw6IE3zyivpK6yLLoJly7IgxIwZ/hWWKrRrB3feCdWqWYVlsVgKHKpaWlXLuB0NAlFYEPji4ueBNqraW1XvxcSoyiBMQ94kpUoFwhJSzEaJGTBuXPr5//5rQgIGTHy82ar4xhvT5v30k5nbslgslgKOiNwiImXdrsuJyM2B1A1UaYV5DQcezUTdPEXyBY4F3xs2ZKudxx7LZEinDRtMhPZXX/Wdf+ONUDQj3xaLxWIpEAxV1dRt5FU1BrO/VoYEqnhmichsEblPRO4DfsV4/uU7Us43G2Pq9u3pllu0CKKi/Odn5D+RhiZN4IAPb/7p02HvXrPYy2KxWAoHvh54AZkBAT0pVfUZYCxmcXFzYKyqPhuweHmIsNr1SI6AlDXpT0a9+WaQOjx92v+i4REjjIWV5RDwFovFki9ZLiLvi8j5IlJXRD4AVgRSMeABLsckWUATZXmZYiWqc6oBlPkznU2wgJPpOBeuWZOJDv1t1Pj22/D445loyGKxWAoMj2P8Ir5zXP+OiRifIekqLR9uialZmGVWZTIhZJ4gIqIaJxtD2Sk7jD97ZGSaMh9+aLYT8UezZul0sGyZ2cekfXvf+dHRUKlS5oS2WCyWAoSqngYGZ6VuukpLVdPZcTB/EhFxHrH1QVJSYNs2aNo0TZkBA3xUBIYNyyA84JEjcPHF/vMTEly7QlosFkshRUT+AG53OGAgIuWByap6bUZ1C90WtxER1YmrJYDCH3+kUVq7dvmve//9UKFCOo1v2uQ7vXp1+OQTq7AsFovFUMmpsABU9biIBLQvRqFzWQsLK0pyvWrm4umn0+TXreu/rl+P9K1bzfqrDh1850dF+V6bZbFYLIWTFEc4QCB1z8WAYgsVOksLoFhZ5x5nmAgUjjG/jDZ49GsoXXCB/0o2QrvFYrF48zywSETmO6474NgzMSMKnaUFEBl5PgdudcRncltkvHZt+vVSLa2ffzbeGsuW+bTWUhk4MHuCWiwWSwFEVWcBrYEtGA/Cp4H4QOoWSkurZMmG7OoRR9UfgIcegsWLAbj9dt/lW7aEVasc638PH4abM4g2cuKEs6OgyWyxWCwFBRF5EBgI1ABWA22BxcCVGdUtlJZWiRIXcvYcx8WSJbByJQC+gmRc1vg4f64qz7LpB0wwwsqVfTd6993GO1AVypQxR3h4aL6AxWKx5G8GYnYN+U9VrwBaAgHtzltIlVZDAE49c4tJaNWKv/ysNX6x4seUJ4bWp+fDgw/6LnT99fD119Y70GKxWALjjKqeARCRCFXdDKTjHOCiUCqtyMi6iBTlyF3npaZddZXvsp0PfGlOevZMm/nDD8Y8+/HHEEhpsVgsOYuIXCciW0Rku4ikWfwrIv1EZJ2IrBaRRSLSyC1viKPeFhHJaL1VlIiUA34C/hCRn4H9AckY6CaQeYXsbgLpZNmy5hQrVpXmLWYDIH68LdXf5svz5/t3cbdYLJY8RkabQIpIOLAVuAaIApYBPVV1o1uZMqp60nHeDXhUVa9zKK9vMdtWVQPmAA1UNTkAuToCZYFZqprh/kwhs7REZLyIHBaR9X7yy4rILyKyRkQ2iIifXRFDQ5kybTl1aim6cIHfMo3xIfqwYWbeyiosi8VSsLgY2K6qOx3KYzJwk3sBp8JyUBLX2qqbMBEtElR1F7Dd0V6GqOp8VZ0eiMKC0A4PTgCuSyf/MWCjqjYHOgHviUiOTQqVKXMJSUnHib/oXIiLS5M/hDdZjtcOj5ddBoMG5ZCEFovFElSKiMhyt8N7XVR1YK/bdZQjzQMReUxEdgDvAgMyUzcYhExpqeoC4Fh6RYDSIiJAKUfZpFDJ402ZMm0BOHlyCRQv7pHXmPW8yfNEkmASRo82W4wsXJhT4lksFkuwSVLV1m7HWK98X3MhaeZNVHW0qp4PPIsrMntAdYNBbjpifAQ0xEy+rQMGqmoGMSmCR4kSFxIeXsYoLS8e6R9udoFUNcejj0KJEjklmsViseQGUUBNt+sapO8cMRlwLlrNbN0sk5tK61rMorJqQAvgIxHxudWJiPR1mrRJScExxkTCKFPmEp9KSxo29L+1iMVisRRMlgH1RaSOY6qmBzDdvYCI1He77Apsc5xPB3qISISI1AHqA0tDIWRuKq0+wA9q2A7sAi70VVBVxzpN2iJFghfEo0yZS4iNXUdycva9ES0WiyU/o6pJQH9gNrAJmKKqG0TkVYenIEB/h+PcauApoLej7gZgCrARmAU8FojnYFbIzTBOe4CrgIUiUhmzsGxnTgpQtmwH4HWOH/8LcEVhDyuUq9csFkthR1VnAjO90l5yO/cbUFVV3wDeCJ10hpApLRH5FuMVWElEooChQFEAVR0DvAZMEJF1mEm8Z1X1SKjk8UW5ch0JDy/LkSM/4K600t3o0WKxWCy5RsiUlqr6CCHhkb8f6Byq/gMhLKwYlSrdyNSpuSmFxWKxWAKlUEZ5d6dYsdt56aVuroTws6QgOIxCi8ViseQhCv3sTdmyXkEHX4zg9dh0ti+2WCwWS65R6JXWsmVpQ3Htj43KBUksFovFkhGFXmnNmpXbElgsFoslUAq90nIPct+o0dbU87/3/J0L0lgsFoslPQq90nJnxIgmqeeXfXEZcYlpA+laLBaLJfco9ErL3dLadzbRIy8pJYk/d/7J6oOrc1gqi8Visfii0Lu8J7sFGumzPG3+1V9dDYAOzV+bZVosFktBpNBbWp98ktsSWCwWiyVQCr3ScrJiRW5LYLFYLJaMsErLwam4tDs9JycnpEmLS4yj6zdd2XncxPb9bv13PPP7MyGXz2KxWCyFfE7LfT5r2b60ptaevcPSpM3cNpOZ22YSWSSSaXdMo8e0HgAM65y2rMVisViCS6G2tMaMcZ2rpg3tvnfv+6nnX6/9molrJnL71NsBOBJ3hJJvpo2mYTF0n9KdfjP6+c2PPh1N8TeKs3jv4hyUymKx5HcKtdLa77YZdHhYWqUVXqRS6nm/Gf146JeHUq//2fuPXceVDtM2TePTFZ/6zV+4ZyFnks7w7j/v5qBUFoslv1Ooldabb7rOL22XVmmdX29E6nmyJnM22TXvlaIpHmUvG39Zmvo9vu+BvGLa7fxVZyq8UyG7IgeV5JRk5BXh1fmvAlDstWLcNuU2AJ7949lU2b35Y8cfyCvCliNbALjgowtoMaYFABujN/qt507RMBNFPzE5MYOSFovF4qJQKy13ioSnvRXlyl+Zep6cfMYjz1tp/b3XFfbpaNxRAL7b8F1q2h87/+D4meMkpyRzNO4ox+KPpebFno0lISmt00dmOZt8llMJp0hOSSbmTAwACUkJxJ6NBeDEmRMcjz9OQlICCUkJ7D25F4Ch84YSnxhPYkoiP2z6AcCnBaSq7I7ZzeT1kwGYu3suAFuPbmXNoTXEno1NE/7K2bc3RcON0joYe5ANhzdw4syJ1Gvn+dG4o6ja9XEWi8WFVVoOhLTWgfsDM9BH56zts6g0rBK/7/jdZ/5zfz5HpWGVqPhuRY7EmY2aS79Vmjaftcm0zN50nNCRMm+XYcBvAyj/TnnOJJ3hks8vofRbpQEo9045KrxbgYs/v5iLxl5EnZF1UuuWeLNE6vn83fNTz92V86crPqXOyDqMXz0eSKuQSr9VmpLFSqZJ80WRMOMDtOLACpp80oRy75Tj8OnDVH2vKuXeKcfWo1upNKwSo5eNzsqtsFgsBRSrtNLB/YGdEoDWik+M58OlHwKw8L+FqelO93iAUUtHpZ5Hn45OPV93eJ1HW+sOrfMYjgyEJVFLAPh4+ceAsbLWHFoDwH8x/6WWW3toLRujN/ptZ+WBlannySnJ7Du5j4OxB/l1268e5ZJTkklKSfJIc+/HyYFTB0jRFH7b9hu7Y3az8sBKhv2T1tvyi1VfpJ73/qk3AI//9jgv/vUiD05/kK/WfMX3G7/no6Ufsev4LgB2HNuRalVGn45mz4k9fr+Xk7m75jJlwxTAWJ/bj21PU8Z5/1WVlQdWBmzxJaUksebgmtTrFE1h1YFVAdUFY12630Nn/2CGXuMT4/3WTdEUFv63kD93/smh2EM+y+w8vpPj8cczLYc3249tT7WIvXHeryVRS1i0ZxE7ju1ITf9r119sP7bd454u+G8Bi/cuZnfMbo7HH/f4f9l/aj8L/lvgty9LcBGR60Rki4hsF5HBPvKfEpGNIrJWRP4UkfPc8pJFZLXjmB4qGUPm8i4i44EbgMOq2sRPmU7ACMw2wUdUtWOo5MkIER+WFu6WlpCRvXXXD3cxc9tMAF5f+Hpq+vmjzk89P5PkGmb01SeYB3+zMc14tPWjjO4aHEuj9sjaAZeNLBKZep6sydT4oAYANzS4waNcsibz4l8veqQ999dzadqr9n413r7qbQb/meZ/wAP3fKcCBte9HLdqXGra4789jg5V6n1Yj9rlarNr4C6qvFeFFE1JN+TWpuhNXDnRDPueU+IcHp35KJuPbPaoE3UyimZjmvFwq4e5ovYV9JjWg++6f8cdje9IV36AIXOGMHzxcDY/tpkLKl3Ah/9+yBOzn2D+ffPpcF6HDOufN+I8TieeTpVn3KpxPPTLQ3x727f0nNaTOxvfyeTuk33WHfXvKJ6c/WTqta/7cP6o86lWuhr7ntqXrhy1RtQiLjHO772s/2F9Gp/TmPWPrvdIn7ZxGt2nduf1K17nhbkvpKZ/1/077vz+To+yH3b5kLua3kXHCa5/++qlq7Pv1L7Ufqu/Xx2AZpWbsabfGiyhQ0TCgdHANUAUsExEpquq+xvuKqC1qsaJyCPAu4Dzh41X1RahljOU67QmAB8BE31likg54GPgOlXdIyLnhlAW/4QnQP3fCJPaabI8hwczftP+afNPmera15AkwPEz5k140d5FafKmb5lO03ObUqd8Hebvns8FlS6gSqkqzNk5J03ZX7b+kil5nLgrLadFAjBj6wyPcl+s/sKnleKLjBRWVnhzofGk2R2zm6iTUamW8c7jO6lTrg4T10xkz4k9hIeF88ylz1A0vKiHJfbZys/YfGQzAM0+aUbfVn1JSkmibERZwAyHbj1qtqu576f7iE+Mp0aZGoz8dyS/bP2FGmVqcFmtyygXUY7G5zbmVMIphi8ebmRb9CbFixRP9aDccWwH7Wu2587v7+Ro/FEan9OYt656i5H/juS37b8x7JphRBaJ5HTiacDc92X7lvHHzj8A6DmtJ2DmSTdGb2R45+H8vuN3Lq15KUkpSSQmJ3ooLIBtR7cxdN5Q2tZoS5VSVWhZpSVgrJftx7YzdsVY6lWox6oDq1CUncd3UqF4BTqe1zHVM/a/mP9Ye2gtn638jCfbPsnR+KMcPn0YgA3RG3jvn/cA6HZBN2ZsncGENRMA+HzV5x6yeCssgMnrJ7P+sKfS23fKKNOrJ15Nm2quIfO1h9YC8N4/71GvQj0SkhMYv2o8V9S+gl7NelG9TPXUsjuO7eD4meO0rtaazUc2k5CUQPMqzdP0HyhOq7JVtVaZque8z4G8rOQRLga2q+pOABGZDNwEpCotVZ3rVn4J0CtHJQQklBPdIlIbmOHL0hKRR4FqqvqCd156lCxZUk+fPp1t2f76C666Crj2SWg3glHXjWLArAEeZb6//Xu6T+2e7b78saX/FhpUbJDqbed8u1x3aB3NxjSjyblNWPeIa9gwOSWZIq8VoXW11ix7aBnyilCzTE22Pb6NyDciffaRFSbdOom7f7g7aO3lBGUjynIiwTWE5P0dXuzwIq9e8SrTt0znpsk35bh847qNY9vRbbz999s53ndB4b8n/uO8EeelSS8TUYYTg12/vfv/k/f/VlbIaht1RtZhd8xuUl5K8TuqkpOIyFnAfR5irKqOdcvvjjEiHnRc3wNcoqr9/bT3EXBQVV93XCcBq4Ek4G1VzdxbfIDk5pxWA6C8iMwTkRUicm9Odbxrl0NhAZTbDZD6huyO01EiVHhbWvtPmYVjYWJ+lvWH16OqNBzdkLum3UViinEPX75/OfN2zwNg76l5qoAAACAASURBVMm9Hg/rYDBxjU/jOE/jfQ+8le5rC16jzWdtckVhATww/QGrsLKJL4UFcDLhJOcMO4cBvw3wWG7R9vO2qedPz37ao07s2Vje++e9NF7AYCyrl+a+hLwiNB/jstDu/uFu6o6sa14WP6iJvCLU/7A+F316Edd8dQ1jlo+hyvAqyCtCizEt2B2zG4BHfn2EmDMxvPfPe4S/Gs6A3wbQ5+c+VB5emesnXc+cnXOIS4xjyJwh1P+wPvN2z+Pbdd+m9vvl6i95Z9E7yCuS6dEcL5JUtbXbMdYr35dm9ampRaQX0Bpwn5yupaqtgbuAESJyvq+62SU3La2PMF/6KqA4sBjoqqpbfZTtC/QFKFasWKuEhOy5hz/+OHz0kePiju7QaJrPch9f/zGPznw0W32lx7bHt1GvQr3Uf7SWVVqy8uGVbD6ymYajGwIw6+5ZXDfpOgC29t9Kg48apGnn9ka3M3Xj1JDJabEUBM6+cDZ1qcUTs55g5L8jmXr7VLo38hxNKft2WU4mnAxq390bdef7jd/7zX/usud4c9GbHmk6VFFVwl512RZX1bmKOfemnQoIBBGJU1W/YXxEpB3wsqpe67geAqCqb3mVuxr4EOioqof9tDUB8+z3/6WzSG7GHozCOF+cBk6LyAKgOZBGaTneCMaCGR7Mbscelrr6NzaTNdlvXjB45NdHmNHTNU/ktOwW/LcgNS3BLWivvwgcVmFZLBlT7PViadKcYdlCTXoKC0ijsMAMS55b0nOq37lUJEQsA+qLSB1gH9ADYzW5ZBJpCXyKGUY87JZeHohT1QQRqQS0xzhpBJ3cHB78GbhcRIqISAngEmBTTnQc5v6t01FavoYOgsmcnXP4Zt03adIfnvFw6rlzqBDItAu8xWLJ3zidXpwUL1o8ZH2pahLQH5iNeRZPUdUNIvKqiHRzFBsGlAKmerm2NwSWi8gaYC5mTsv/uppsEEqX92+BTkAlEYkChmJc21HVMaq6SURmAWuBFOBzVV3vr71g8t13bhfpWVopobW0wNOac0aocOfGb29MPX/q96dCLk+oqVa6WurcnSVv0eG8Dsy/zywsDyQUl5M7G9/pEf3Fkn9R1ZnATK+0l9zOr/ZT7x+gaWilM4TM0lLVnqpaVVWLqmoNVR3nUFZj3MoMU9VGqtpEVUek116weOEFOHjQLSEl3G/ZUFtamWXRnrQu8PkNXy8CE2/Oe44fHc/zXDLYrka7kPTTs0nPdPOrla6WJu2Blg8AUK9CvYD7GdRuEIPaDfJI+6jLR/Ro0oOO53WkTEQZvr3NNfm/6uFVDL/G5ZzUp0UfAD694VMuqX4J19e/ni39t/Bs+2f54qYveLb9swxqN4gvb/4ytc533b+jbQ2XM4ST0sV8R0mxZExeeyblBiF1xAgF2XV5T+N5enNvaOH7ofnO1e/w7Jxns9xXVqhVtlZAUR3yMlv7b+Xm7272GXWjeeXmqVE6nDhdiTPzdp9V7m1+r0/vyPKR5dn75F5KvVUqdSGruzzu7tPu9GrWi6/Xfg0YJZLeurVG5zRKc090qNJ+fHv+2fsPi/oson2t9oCnm/VFn17EqoOrOP3caUoULeFR31vGjPKcbtiJLyYGND+SWXfvJVFLaDeunUcd7/v2612/0vWbrum2s7DPQi7/4nK/+QXh/yQrdK3flRl3zci4oA8ycsTIL9gwTukMD+ZGBPL88o/Y6JxGadJ+7vEzj7V5jPoV6zP19qlcXP1iul3Qjcm3uSI4zLx7Jgv7LOSXnukvfK5csrLH9YMtH+THO3/MttzvdX7PZ/rKh1dSslhJpnSfwm93/5ZuG1/f8jVPtX2KMV3HMOGmCanp83rP45tbXXOU71z9Tur597d/z5x75vByx5fTtOd8cXRfwP7rXb+ytb/xSfrmtm/4/MbP0ygsgNm9ZjP5tsn8ee+fafJ83a9FfRYxpfuUgCf0lz20jEV9ArfwL6l+Cfc0u4eFfVxhzGb3ms36R9Yzo+cMHr/4cbrU68K6R9ZxZR1XQOrx3cZzdd2rGddtHAv7LKRkUd/P1lLFSjHtjmksuG+Bh2WYVXz9HfsiIjwi4DbdrXT37+iPq+v6HHHzSYgdMfIFhcrSUvVywgDo9gBcND77ghUChlw2hLcWvcWYrmN4uLXLWSSQt3FfZZxv/c60Sz6/hKX7lgJpXYSDYY01qNiAtf3W+lyI7Ut2f5aWP4vGmd5lUhdmbZ/FgacPUPW9qnSq3Ym5vU0ggejT0Zw7/FyPdh/+5WHGrhzLhkc3BPwQDRR5RahTrg47B+7MuHAu4O+e7ju5jxof1EgzXzbsmmEMutQMc55KOEWZt8sA8HCrh9Pdv80Xr3R6hZc6vkTl4ZXTODzUKVeHXTG7Uq/9WdreeP+dfn3L1/T60QSN2DlgJ3VH1fVZx7vtWxveyor9K/jvhGf8xxcuf4HXrnwtgG+XloJiaRUqte1T16n/Oa3CyN4n9zJ1w1TqV6zP6oOrebTNo/y9529KFStFp9qd6HheRzqf39mjzsy7Zmb4Brjh0Q2UKlbKI23pg0s9nE9m95rN2kNr+X3H77zc6eVUpbX0waVp2nupw0scOn0oUw+qv+//m4giESx+YDFVS1XNVDxGgI2PbvRp7XjzXffvWH94PVVKVeGf+//xUETnlDyHWXfPYsfxHalv2CO7jKRn055BV1gAyx9aznnlfC/KzQts7b/Vw0PWSfUy1Vlw3wJaVm2ZqrRm3T2La86/JrVM6YjSqUrNuT8bwLklz+Xw6cPcfOHNvHHlG5QsWjL1t941cBdrD61l+f7lvNDBBONZ228tP2/5mfPKnkeraq1Ye2gt7Wu2Z/5/86n5//bOPDqO6kr4v9t7S2pJLcmytXiRF/CGLS/YTtjMZrYQEyDBARJiGMgkhsHhTMZA+IInMPkIc5KPE5gETOIvJmEgE4i/QE7ixDjITgIGbGPA8YJsy4tsSZZkWVJLavX2vj+q1G5J3dqsraX3O6dPV7169erequ669d67dW/6eJw2o5d18IGDlDeU47a78QV87KveR01zDfPy5pHpysRtO+vZd+D+A9gsNooyi6JGq8hbxIs3vsjC/IVsO7qNxQWLo1kRPvz6h2w+tJkriq6gJdRC8bhi5vx0DgBPXfkUiwsXE4qEWDppaT+d+eRlVPW0ampgzJgOhZ/7Z1jYuye0kcq3lnyLH13zo6EWI0q8p3D5d6HAU0D5Q+WU1ZXFfXKN5eGLHmbz4c3srNjZ6Wl+zk/nRKPrx+tppf/vdBoDjQm3dyWnpv+46qWr2FK2Je753XxoM8t+tYxffuGXfGXjVwD4/hXf59G/PMqeb+xhVu4sAOa9MI/dlbuH5Bp1JX9XTP3xVA7VHYqGeztXRkpPa1QZrWPHYGLsQ6clCA+cB94j/SLbcGVl8Ur+7+6zaT+qv12NIIgIwXCQpmATgjA+Y/ywGjOPZwwqfZWk2FNIdxrDQofrDuMP+fEFfEzNmsrpltNMe3YaYMwxXTzhYvwhP2f8Z9oFVQUjlE9ZXRkF6QVkuTtnlT7jP4P3B95OMvRETk3/0RJsoballsL0wrjbP639lPOyz6O6qRqbxUaGK4NDpw8xLXtatI4v4KOhtSGuN+ZA0538iTjv2fMoPV0azRhwrowUozV87lCDQHPHgBJXfmdEGazJ3sntchG1cf+i+9sZrZyUnMEUq8/kpOR0eqF6XNq4duuTve17WrHG57JJxoR4qiO1U3JKMCb1Lxib+NWSTFcmQFy37VjyPfntMlFr+he33U2hPfENv60XMib17DBKrMEC41p3HJ4eLLqTPxF3z7ubR7Y80k4vzSjrae3aBQtiswvceQ1MjZ9hOFk48dAJ7BY7DqsDj9NDQ2sDdoud+tZ6LGIh252N3WrHH/Lj/g9jzD1ZegRtCSZ72/vrz55PIBzAKlaslsRzn6FICKVUNK6dRtMfKKVoDbe2SxV0LoyUntaocnnv2NOaMHznpxPS8YXSfE8+Y1LHkOHKwCIWMl2ZpDpSyffkMy5tXPRG6rK5+NaSb0VzRSUDNoutT8OVaY40/u2z/9YvMjisji4NFhhyaoOl6W9EpN8M1khiVPW0/vxnuOYaY15ryxb4xt+vYXPZ8O5pTU2DF83eYXb255k+fT12e/bQCqXRaJIO3dNKQtp6Whs3wpQpEMfTdtix7uY/k5JipCmprX2Dd97Jo6RE+OijqwmHW4ZYOo1GoxlckuC23X/Um3kCf7TPSBbXXUDcxy55jAkZEwZBsvY8f4MRnvG++fdxedHVLFq0l8suizBz5v8wdqzh1ltX9xZ//WsKJSVCZeVLBAJVgy6nRqPRDDajymh97WvG969KnwXgg5MfdFnfYXWw6Y5N3bb73HXPdVunO9pC/vz61l/z1blfZWXxSp684snodhEhN/eLTJ/+cxYvLiM392xm3v377+Kdd8ZRUiLs33834bD/nOXRaDSa4ciomtOKBstdayx4HJ7oy6PxeOaaZ3hwyYP8yx//hWfffzZhvZ6EeHnvn97jxldu7BQuJraNvtDcfICjR5+kqupXnbbl569i4sRHcDoL4uyp0WhGEyNlTmtEGK1gMEh5eTl+f9c9jNpaaGmBcJoRz0tE6Er/CRkTEBEiKkJjayNn/GcA412hthdWASZmTuTomaOd9rdYLFjFSoo9hUxXJscbjhOJRPA4PVjEQkRF8If8pDvT++UdkkgkSChURyQSf67LavVgs3mRmFD3LpeLwsJC7Hbt/abRjGRGitEaES8Xl5eX4/F4mDRpUrsbckdKy/zUO/cAxsu1bYYjETPz28eC23FyBwDF+cXt1mfkz6D5ZHO7KN0AhemF7V6GlRrBF/BRPLYYm3VgT71SEYLBGoLBGiKRWF9/Y9liScVuz6W+PkJ5eTlFRUUDKo9Go9H0ByPCaPn9/m4NFkBQfO3We9vLnJEzo90xZo6ZGW1jdu5saltqyXJnEY6EOd1yulN6janeqfgCvgE3WAAiFhyOXByO3KgBCwQqUMpItxKJNNHaWobTCeXlp3jvveuYOfNlPJ4F3bSs0Wg0Q8eIMFpAtwYLoNlxpN16x55Rd3QMBRQb8dtpc7aLaxYvbJDNaiPTndmrY/YHsQYMDGMdDNbS2nrEnOez0NJygJ07FwJGL8xmy2TKlB+Qm3t7j86tRqPRDAYD5j0oIutF5JSI7Omm3oUiEhaRWwdKlt4wPWc6s8fMZs7YOT3e58yZM/zkJz/p0/Guv/56zpw506d9+4qI4HDk4PEsJC1tPk5nIZMmnc3RE4k0EQicYN++O9m61UJJifC3v+WYrvXxHUk0Gk3yIyLXisgBETkoIg/H2f6QiOwVkY9FZIuITIzZdpeIlJqfuwZMxoFyxBCRSwEf8JJSanaCOlZgM+AH1iulXotXL5Z4jhj79u1jxowZ3crUNgfVFQvyFvS6Z3HkyBE+97nPsWdPZ/scDoexWod3zq6O5y8cbmLPnpupq+s6WkhaWjF5efeSk/MFHI6xSDK8ra3RjFK6c8Qw78efAlcD5cAHwJeVUntj6lwOvKeUahaRbwBLlVK3iUgWsANYCChgJ7BAKVXX33oM2F1GKbUN6C709QPA68CgPL5bwt0n8OvLUNjDDz/MoUOHKC4u5tvf/jYlJSVcfvnl3H777VxwgRFF/KabbmLBggXMmjWLdevWRfedNGkSNTU1HDlyhBkzZnDvvfcya9Ysli1bRktLZy/AN998k8WLFzNv3jyuuuoqqqqMl4p9Ph8rV67kggsuYM6cObz++usAbNq0ifnz5zN37lyuvPLKHuljtaYyd+6fWLpUsXSp4tJL/SxZcpzzznuBgoL7o/V8vt2Ulq7i3Xfz2brVSkmJUFIiHDjwz7S0HOn1edRoNEPKIuCgUuqwUioAvAosj62glHpbKdXm2bUdaAtffw2wWSl12jRUm4FrB0LIIZvTEpEC4AvAFcCF/dXu6tWwe3f8bb7WiShJ7C0I4HF0LisuhmeeSbzPU089xZ49e9htHrikpIT333+fPXv2RL3y1q9fT1ZWFi0tLVx44YXccsstZGe3jyFYWlrKK6+8wosvvsiXvvQlXn/9de688852dS6++GK2b9+OiPCzn/2Mp59+mh/+8Ic88cQTZGRk8MknRlLDuro6qquruffee9m2bRtFRUWcPt239BkWixOXq5D8/PsAmDbtWcLhJgKBU+zd+2UaG99rV7+i4gUqKs4m1nS5JpOevoSCglV4PIuwDKOcXRrNKMImIrHDTeuUUuti1guA4zHr5cDiLtq7B/hjF/sOyAuiQ3n3eAZYo5QKd9e7EZH7gPsAHI44VqWHKECUDSWhPrfRUxYtWtTOjfzHP/4xGzduBOD48eOUlpZ2MlpFRUUUFxvu9AsWLODIkSOd2i0vL+e2226joqKCQCAQPcZbb73Fq6++Gq3n9Xp58803ufTSS6N1srI6JzrsK1ZrKm53EQsWbI+WhcNNVFZuIBSqo6XlEJWVRg4vv/8wfv9hTp3672jd9PTPYLWmkpp6AW73eeTl3Y3F0vdrq9FouiWklFrYxfZ4N+K480cicifGUOBlvd33XBlKo7UQeNU0WDnA9SISUkr9v44VzaeBdWDMaXXVaFc9op3Hy7DjJmBNPMy6ML+ra9pzUlPPDh2XlJTw1ltv8e6775KSksLSpUvjvgjtdDqjy1arNe7w4AMPPMBDDz3E5z//eUpKSli7di1geAR2NP7xygYSqzWVgoJvRtenT18PQChUT23tH/D5PqS6+jX8/jIaGt4FjBiKAKWl32jXVnr6ZygsXE129o1Yre5B0kCjGdWUA+Nj1guBkx0richVwHeAy5RSrTH7Lu2wb8lACDlkRkspFe2GiMgvgN/HM1j9fFTiPxCcGx6Ph8bGxOGg6uvr8Xq9pKSksH//frZv356wbnfU19dTUGD0ujds2BAtX7ZsGc899xzPmFa7rq6Oz3zmM6xatYqysrLo8GB/9rZ6is2WwdixX2bs2C8zZcrT0fJg8DQVFS9SVfXfNDV93G6fhoZ32bv33XZlIk5SU2ehVIDs7M8xYcIjWK0e7ZKv0fQPHwDTRKQIOAGsAG6PrSAi84AXgGuVUrG+CH8Cvi8iXnN9GfDIQAg5YEZLRF7BsLw5IlIOPA7YAZRSzw/UcbtCkdjRYmrWVGqaa/rUbnZ2NhdddBGzZ8/muuuu44Ybbmi3/dprr+X5559nzpw5nH/++SxZ0nX69q5Yu3YtX/ziFykoKGDJkiWUlZUB8Nhjj7Fq1Spmz56N1Wrl8ccf5+abb2bdunXcfPPNRCIRcnNz2bx5c5+P3d/Y7VlMmLCGCRPWRMuUClNb+3t8vk+w2Ty0tp7g+PH/NLe14vPtAqCpaQ/Hjj3Vrj0RBxMnPobVmobXeyWpqbO1R6NG00OUUiERuR/DAFkxPLr/ISLfA3Yopd4A/hNIA35j3kuPKaU+r5Q6LSJPYBg+gO8ppfo2id4NIyL2YI9d3o9/jEvS8Vs6G6f+GhZMRnp6/oYapcI0Nn5IWdl3unXHb48VCDN27F1kZFxMevqFuFyTsVrTdC9NM2rQsQeTEVEIwoycGeyr2TfU0mh6iYiV9PSFzJ37p07blFK0tByitfU4e/YsJxyOHa418qZVVW2gqmpDp30B0tMvIjv7BkKhetzuyaSmzsHjWag9HTWaYcao+UeGI2GwBEHFD7GkSW5EhJSUqaSkTOWSSxo6bQ+FGgkEKvD7j3Dy5PPU1GzEas0gHDYygzY0/J2Ghr93e5y0tAVkZFyMx7MAr/dKRGzR8FgajWbgGTVGKxgxAsVaR4/KmhhsNg82m4eUlPPIylrWaXs47Kep6RN8vo+oq9uMiB2fbyfNzfvb1fP5duLz7Ux4HLs9h0gkSE7OcvLy7kHESkrKTERs2GyeftdLoxltjJo7eNvcnV20+7SmM1ari/T0C0lPv5D8/H9qt02pMGDB7z9Mc/MBGhq2E4kE8Pl2U1fXNmdtDEEGg8Z8aVXVS1RVvdTtcV2uybjdU5g27VlsNq/utWk03TBqjFbE9DfR8+6a3mKEZAO3ewpu9xSys69PWDccbqal5RDNzXuxWj2cObOV48efTli/7cXr99+f3mmbx3MhPt+HOBwFeDzzyc6+kczMpTidRuQci0Un7tSMPkaP0TKtlsR5Tys2xYhGcy5YrSmkpV1AWpoRczI7+3qmTPlBp3qtrScIherx+XZTVfUrTp82ouHY7TnR3lpj4wdm3aO0th6lpmZjwuOOG3c3tbVvEgxWU1BwPy5XEV7vMlJSzkfEpr0kNSOGUWO02oYHLXH+vOdnnz/Y4pCWlobP5+u+omZE4nQW4HQWkJo6k7Fjb49bp80jMhCopKFhO83N+7BYnJw+/Ues1gxaW48TDjegVIjKyvXR/U6ceC5uew5HAYHACTIyLgEspKcvxu2eRjjciNd7BVZrBk5nPiLWaO9SoxlujBqjFTGNVtsTZ6o9laag8b6X1aL/oJrhR6xHZGbmxV3WVUqhVIjGxp20tBygqWkvLS2fEgo14HSOp6pqA4HACQDq6/9qfm9N2J7dPhanMx+LxUVz835CISP0mdd7FQUF92OxuLHbs7FaPdjtudjtg5/cVDM6GbVGa2LmRPZW7+1qlx6zZs0aJk6cyDe/acTdW7t2LR6Ph69//essX76curo6gsEgTz75JMuXL++yrZtuuonjx4/j9/t58MEHue8+I7L6pk2bePTRRwmHw+Tk5LBlyxZ8Ph8PPPAAO3bsQER4/PHHueWWW/pFJ01yISKI2MnIWEJGRueIKzNm/CK6rFSEQKCC1tZympv309JyEIvFTU3N7/D7j2C1puFw5NHY+D4u16SowQIjVmRbvMiO2GxZhEJGEASv92osFje1tW/g8SwiLW0uDsdYrFYjpJfdnoOIXUcs0fSaERcRY/Wm1eyu7JybJBgO4w8345AUnHYrERWJ9rQ8jq5dkYvHFfPMtYkj8X744YesXr2arVuNJ9eZM2eyadMm8vPzaW5uJj09nZqaGpYsWUJpaSkiknB4sC0+YFsKk61btxKJRJg/f367FCNZWVmsWbOG1tbWdvEGvV5vpza7I1kiYmiGhkjEyIrQ2nqM1taTiFjw+T5ExI7ff4zGxvew23MJhxuorf19n47hcIzDZvPS3LyPtLT5pKbOJjNzKU1Nn5CdfQMOxziczvFYral66LKP6IgYScpATEfPmzePU6dOcfLkSaqrq/F6vUyYMIFgMMijjz7Ktm3bsFgsnDhxgqqqKsaNG5ewrXgpTKqrq+OmGImXjkSj6W/aooK43ZNxuycDkJHx2R7tGw77CYXqOH36D9TX/53a2jcZN24lZ868TWNjW2onIRCoJBCoBMDn24XPtyv6ykB5+f9p16bLNQm//zgQJjf3y9jtudTX/w2LxYndnsW4cStpbj6Ax7MQmy0dp3OCzqw9ghhxRitRj+hUfT3HmkopcE4nLzuNiIqwq2IXbpubWbmzzvm4t956K6+99hqVlZWsWLECgJdffpnq6mp27tyJ3W5n0qRJcVOStJEohUmiFCODnXpEo+ktVqsLqzWPvLx7yMu7p9v6SinC4QZ8vo+x2TJobt5Pff3fo2UQISVlFuHwnwkGq82enSIcPjtq0V1vz+kcj82WQSBQjcMxDpdrEllZV9PUtJfU1Nmkpc0hEmklNXUWNpuR805ECASqcDrzz+V0aPqBEWe0EhHp4D1oEUu/BsldsWIF9957LzU1NdFhwvr6enJzc7Hb7bz99tscPXq0yzYSpTBJlGIkXjoS3dvSJDMigs2WQWbmJQCkpc0hN/dL3e4XiYQIBqtpaSkFhJqa3xIK1eP3H6W19Rh+/xEsFjfhcKM5n2ck2Q0Gq2hq+oja2t/1SD6HIx+3ewotLaW43efT1PQxDkc+Y8bcQih0Grf7PNzuabjdU6KOKvqVg/5l9BitSHtHjP5m1qxZNDY2UlBQQF5eHgB33HEHN954IwsXLqS4uJjp0zu/QBpLohQmY8aMiZtiJFE6Eo1mtGGx2HA683A6jf9em9HrCsPjMoDffxylgtTVbQEULtdEKip+hsORh9WaQnn5M7hcU/D7DxEK1UW9L9uGM0OhOo4e/UeP5LRa08jIuJQzZ7bi8cwnNXUWDkceLlcRdnsWSikqKl4gPX0JqakX4PEsxG7P1YGbYxhxjhiJOFZ9mlPBw0xNn0Vmmg7lFIt2xNBoeo9SikCgkkjETzBYTV3dW4RC9Tid42lu3o9SrTQ378duH0tLy0ECgUqczgLCYR8tLZ/26lhWazo2WyaFhasZP/5bfZJXO2IkGV6PA7/Pi9ulPY80Gs25IyLRnp3bXUR6+qJet6GUIhSqIxCoJBxuJBisoaLi5ygVAcI4neMBsFicNDXtxe2e0p8qJCWjxmh5XGl4XGlDLYZGo9FEERHs9izs9qxoWXb2DV3sodE+oBqNRqNJGgbMaInIehE5JSJ7Emy/Q0Q+Nj/viMjcczless3NDRf0edNoNMnEQPa0fgFc28X2MuAypdQc4AlgXV8P5HK5qK2t1TfgXqKUora2FpfLNdSiaDSaYYCIXCsiB0TkoIg8HGf7pSKyS0RCInJrh21hEdltft4YKBkHbE5LKbVNRCZ1sf2dmNXtQGFfj1VYWEh5eTnV1dV9bWLU4nK5KCzs86nXaDQjBDHiY/0XcDVQDnwgIm8opWKDtB4Dvgb8a5wmWpRSxQMt53BxxLgH+GNfd7bb7dEQRxqNRqPpE4uAg0qpwwAi8iqwHIgaLaXUEXNbZCgEhGHgiCEil2MYrTVd1LlPRHaIyI5QKDR4wmk0Gs3IwdZ2HzU/93XYXgAcj1kvN8t6istsd7uI3HTO0iZgSHtaIjIH+BlwnVKqNlE9pdQ6zDmv1NRUPXGl0Wg0vSeklOoqdl28cEG9ud9OUEqdFJHJwF9E5BOl1KHeidg9Q9bTEpEJwG+B9SxQaAAABxpJREFUryilevd6uEaj0Wj6m3JgfMx6IXCypzsrpU6a34eBEmBefwrXxoD1tETkFWApkCMi5cDjgB1AKfU88F0gG/iJGQ+wu6cAAJqbm5WItPRRLBswUsYXtS7Dk5Giy0jRA7QubXQXv+4DYJqIFAEngBXA7T1pWES8QLNSqlVEcoCLgKf7KGfXxxpNbuIisqMnhjEZ0LoMT0aKLiNFD9C69LL964FnACuwXin1HyLyPWCHUuoNEbkQ2Ah4AT9QqZSaJSKfBV4AIhgjeM8opX4+EDIOF+9BjUaj0QwxSqk/AH/oUPbdmOUPiPN6kvkK0wUDLiDDwHtQo9FoNJqeMtqMVp+jbgxDtC7Dk5Giy0jRA7QuI4pRNael0Wg0muRmtPW0NBqNRpPEjBqj1V0gyOGIiBwRkU/MAJQ7zLIsEdksIqXmt9csFxH5sanfxyIyfwjl7hThvy9yi8hdZv1SEblrGOmyVkROxAQHvT5m2yOmLgdE5JqY8iH//YnIeBF5W0T2icg/RORBszyprk0XeiTddRERl4i8LyIfmbr8u1leJCLvmef31yLiMMud5vpBc/uk7nQccSilRvwHw33zEDAZcAAfATOHWq4eyH0EyOlQ9jTwsLn8MPADc/l6jPiNAiwB3htCuS8F5gN7+io3kAUcNr+95rJ3mOiyFvjXOHVnmr8tJ1Bk/uasw+X3B+QB881lD/CpKXNSXZsu9Ei662Ke2zRz2Q68Z57r/wFWmOXPA98wl78JPG8urwB+3ZWOg/0bG4zPaOlpRQNBKqUCQFsgyGRkObDBXN4A3BRT/pIy2A5kikjeUAiolNoGnO5Q3Fu5rwE2K6VOK6XqgM10nepmQEigSyKWA68qpVqVUmXAQYzf3rD4/SmlKpRSu8zlRmAfRmy5pLo2XeiRiGF7Xcxz6zNX7eZHAVcAr5nlHa9J27V6DbhSRITEOo44RovROtdAkEOFAv4sIjvlbHDLsUqpCjD+vECuWT7cdeyt3MNdn/vNIbP1bcNpJJEu5rDSPIwn+6S9Nh30gCS8LiJiFZHdwCmMB4BDwBmlVFvki1i5ojKb2+sxIgsNC10Gg9FitM41EORQcZFSaj5wHbBKRC7tom6y6phI7uGsz0+BKUAxUAH80CxPCl1EJA14HVitlGroqmqcsmGjTxw9kvK6KKXCyshDVYjRO5oRr5r5Pax1GQxGi9E6p0CQQ4U6G4DyFEbolEVAVduwn/l9yqw+3HXsrdzDVh+lVJV5o4kAL3J2GGbY6yIidowb/ctKqd+axUl3beLpkczXBUApdQYj0OwSjKHYtohFsXJFZTa3Z2AMXw8rXQaS0WK0ooEgTS+cFcCApYPuD0QkVUQ8bcvAMmAPhtxt3lp3Ab8zl98Avmp6fC0B6tuGfIYJvZX7T8AyEfGawzzLzLIhp8Nc4RcwrgsYuqwwPbyKgGnA+wyT35859/FzYJ9S6kcxm5Lq2iTSIxmvi4iMEZFMc9kNXIUxR/c20JbOvuM1abtWtwJ/UYYnRiIdRx5D7QkyWB8MT6hPMcaLvzPU8vRA3skY3kAfAf9okxlj/HoLUGp+Z5nlgpEq+xDwCbBwCGV/BWN4JojxBHhPX+QG7saYUD4IrBxGuvzSlPVjjJtFXkz975i6HMDIEzdsfn/AxRhDRh8Du83P9cl2bbrQI+muCzAH+NCUeQ/wXbN8MobROQj8BnCa5S5z/aC5fXJ3Oo60j46IodFoNJqkYbQMD2o0Go1mBKCNlkaj0WiSBm20NBqNRpM0aKOl0Wg0mqRBGy2NRqPRJA3aaGk0g4iILBWR3w+1HBpNsqKNlkaj0WiSBm20NJo4iMidZp6j3SLyghnU1CciPxSRXSKyRUTGmHWLRWS7Gah1o5zNRzVVRN4ycyXtEpEpZvNpIvKaiOwXkZfNCA8ajaYHaKOl0XRARGYAt2EELC4GwsAdQCqwSxlBjLcCj5u7vASsUUrNwYjI0Fb+MvBfSqm5wGcxImuAEZV8NUYOpMnARQOulEYzQrB1X0WjGXVcCSwAPjA7QW6MILIR4NdmnV8BvxWRDCBTKbXVLN8A/MaMG1mglNoIoJTyA5jtva+UKjfXdwOTgL8NvFoaTfKjjZZG0xkBNiilHmlXKPK/OtTrKgZaV0N+rTHLYfT/UKPpMXp4UKPpzBbgVhHJBRCRLBGZiPF/aYu8fTvwN6VUPVAnIpeY5V8Btiojv1O5iNxktuEUkZRB1UKjGYHoJzyNpgNKqb0i8hhG1mgLRoT3VUATMEtEdmJkjL3N3OUu4HnTKB0GVprlXwFeEJHvmW18cRDV0GhGJDrKu0bTQ0TEp5RKG2o5NJrRjB4e1Gg0Gk3SoHtaGo1Go0kadE9Lo9FoNEmDNloajUajSRq00dJoNBpN0qCNlkaj0WiSBm20NBqNRpM0aKOl0Wg0mqTh/wOldqgwaDxtugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 13us/step\n",
      "\n",
      "loss : 2.9817888807296753\n",
      "accuray : 0.2598\n"
     ]
    }
   ],
   "source": [
    "###학습 조기종료 시키기\n",
    "#        https://tykimos.github.io/2017/07/09/Early_Stopping/\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "\n",
    "# 훈련셋과 시험셋 로딩\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋, 검증셋 고르기\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# 라벨링 전환\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(X_train, Y_train, epochs=3000, batch_size=10, validation_data=(X_val, Y_val))\n",
    "\n",
    "##----------------------------------------------------------------------------\n",
    "##----------------------------------------------------------------------------\n",
    "\n",
    "# 5. 모델 학습 과정 표시하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "##----------------------------------------------------------------------------\n",
    "##----------------------------------------------------------------------------\n",
    "\n",
    "# 6. 모델 사용하기\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "print('')\n",
    "print('loss : ' + str(loss_and_metrics[0]))\n",
    "print('accuray : ' + str(loss_and_metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 279us/step - loss: 2.2576 - acc: 0.1643 - val_loss: 2.2272 - val_acc: 0.1633\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 2.2072 - acc: 0.1657 - val_loss: 2.1908 - val_acc: 0.1800\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 2.1730 - acc: 0.1729 - val_loss: 2.1631 - val_acc: 0.1867\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 2.1441 - acc: 0.1786 - val_loss: 2.1372 - val_acc: 0.1867\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 2.1177 - acc: 0.1914 - val_loss: 2.1141 - val_acc: 0.1867\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 2.0940 - acc: 0.2029 - val_loss: 2.0931 - val_acc: 0.2033\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 2.0719 - acc: 0.2086 - val_loss: 2.0727 - val_acc: 0.2067\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 2.0521 - acc: 0.2143 - val_loss: 2.0563 - val_acc: 0.2067\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 2.0342 - acc: 0.2157 - val_loss: 2.0409 - val_acc: 0.2033\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 2.0188 - acc: 0.2143 - val_loss: 2.0271 - val_acc: 0.2067\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 2.0042 - acc: 0.2200 - val_loss: 2.0125 - val_acc: 0.2100\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.9912 - acc: 0.2186 - val_loss: 2.0036 - val_acc: 0.2100\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.9788 - acc: 0.2271 - val_loss: 1.9953 - val_acc: 0.2100\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.9684 - acc: 0.2314 - val_loss: 1.9833 - val_acc: 0.2033\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.9582 - acc: 0.2214 - val_loss: 1.9752 - val_acc: 0.2067\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.9484 - acc: 0.2357 - val_loss: 1.9685 - val_acc: 0.2000\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.9394 - acc: 0.2343 - val_loss: 1.9612 - val_acc: 0.2033\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.9309 - acc: 0.2314 - val_loss: 1.9537 - val_acc: 0.2100\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.9232 - acc: 0.2271 - val_loss: 1.9452 - val_acc: 0.2100\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.9156 - acc: 0.2386 - val_loss: 1.9392 - val_acc: 0.2100\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.9085 - acc: 0.2329 - val_loss: 1.9363 - val_acc: 0.2100\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.9011 - acc: 0.2386 - val_loss: 1.9289 - val_acc: 0.2033\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.8954 - acc: 0.2357 - val_loss: 1.9234 - val_acc: 0.2100\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.8895 - acc: 0.2314 - val_loss: 1.9201 - val_acc: 0.2067\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.8831 - acc: 0.2371 - val_loss: 1.9167 - val_acc: 0.2167\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.8771 - acc: 0.2329 - val_loss: 1.9108 - val_acc: 0.2167\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.8716 - acc: 0.2386 - val_loss: 1.9101 - val_acc: 0.2200\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.8663 - acc: 0.2386 - val_loss: 1.9095 - val_acc: 0.2000\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.8616 - acc: 0.2414 - val_loss: 1.9055 - val_acc: 0.1900\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.8567 - acc: 0.2271 - val_loss: 1.8978 - val_acc: 0.2167\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.8514 - acc: 0.2471 - val_loss: 1.8972 - val_acc: 0.1900\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.8464 - acc: 0.2371 - val_loss: 1.8928 - val_acc: 0.1867\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.8425 - acc: 0.2243 - val_loss: 1.8873 - val_acc: 0.2100\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.8384 - acc: 0.2300 - val_loss: 1.8811 - val_acc: 0.1967\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.8336 - acc: 0.2471 - val_loss: 1.8837 - val_acc: 0.1933\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.8300 - acc: 0.2386 - val_loss: 1.8756 - val_acc: 0.1900\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.8258 - acc: 0.2514 - val_loss: 1.8744 - val_acc: 0.1767\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.8221 - acc: 0.2357 - val_loss: 1.8700 - val_acc: 0.1967\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.8185 - acc: 0.2443 - val_loss: 1.8706 - val_acc: 0.1767\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.8145 - acc: 0.2357 - val_loss: 1.8681 - val_acc: 0.1967\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.8106 - acc: 0.2414 - val_loss: 1.8669 - val_acc: 0.1833\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.8076 - acc: 0.2471 - val_loss: 1.8636 - val_acc: 0.1800\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.8044 - acc: 0.2443 - val_loss: 1.8616 - val_acc: 0.1733\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.8002 - acc: 0.2371 - val_loss: 1.8577 - val_acc: 0.1967\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.7970 - acc: 0.2457 - val_loss: 1.8566 - val_acc: 0.1733\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.7939 - acc: 0.2243 - val_loss: 1.8528 - val_acc: 0.1933\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7914 - acc: 0.2600 - val_loss: 1.8552 - val_acc: 0.1800\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.7887 - acc: 0.2486 - val_loss: 1.8546 - val_acc: 0.1867\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.7859 - acc: 0.2471 - val_loss: 1.8503 - val_acc: 0.1833\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.7819 - acc: 0.2457 - val_loss: 1.8445 - val_acc: 0.2333\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7794 - acc: 0.2614 - val_loss: 1.8469 - val_acc: 0.1900\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.7762 - acc: 0.2500 - val_loss: 1.8413 - val_acc: 0.1967\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.7743 - acc: 0.2543 - val_loss: 1.8490 - val_acc: 0.2067\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.7715 - acc: 0.2700 - val_loss: 1.8483 - val_acc: 0.1867\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7685 - acc: 0.2514 - val_loss: 1.8356 - val_acc: 0.2033\n",
      "Epoch 56/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.7671 - acc: 0.2543 - val_loss: 1.8438 - val_acc: 0.2200\n",
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.7639 - acc: 0.2771 - val_loss: 1.8388 - val_acc: 0.2133\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.7613 - acc: 0.2586 - val_loss: 1.8348 - val_acc: 0.2233\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7587 - acc: 0.2657 - val_loss: 1.8331 - val_acc: 0.2200\n",
      "Epoch 60/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.7550 - acc: 0.2614 - val_loss: 1.8261 - val_acc: 0.2467\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7563 - acc: 0.2843 - val_loss: 1.8341 - val_acc: 0.2367\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.7529 - acc: 0.2714 - val_loss: 1.8318 - val_acc: 0.2233\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.7502 - acc: 0.2814 - val_loss: 1.8303 - val_acc: 0.2000\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7481 - acc: 0.2800 - val_loss: 1.8278 - val_acc: 0.2167\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7455 - acc: 0.2843 - val_loss: 1.8305 - val_acc: 0.2000\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.7437 - acc: 0.2800 - val_loss: 1.8305 - val_acc: 0.2067\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.7417 - acc: 0.2671 - val_loss: 1.8300 - val_acc: 0.2033\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.7402 - acc: 0.2757 - val_loss: 1.8243 - val_acc: 0.2000\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.7373 - acc: 0.2843 - val_loss: 1.8290 - val_acc: 0.2167\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.7353 - acc: 0.2843 - val_loss: 1.8273 - val_acc: 0.2433\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.7342 - acc: 0.2814 - val_loss: 1.8220 - val_acc: 0.2167\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.7324 - acc: 0.2843 - val_loss: 1.8232 - val_acc: 0.2133\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.7295 - acc: 0.2829 - val_loss: 1.8264 - val_acc: 0.2467\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.7281 - acc: 0.2843 - val_loss: 1.8263 - val_acc: 0.1967\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.7265 - acc: 0.2771 - val_loss: 1.8201 - val_acc: 0.2267\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.7252 - acc: 0.2857 - val_loss: 1.8203 - val_acc: 0.2200\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7225 - acc: 0.3100 - val_loss: 1.8236 - val_acc: 0.2033\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.7208 - acc: 0.2857 - val_loss: 1.8176 - val_acc: 0.1933\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.7195 - acc: 0.2814 - val_loss: 1.8201 - val_acc: 0.2433\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.7188 - acc: 0.2929 - val_loss: 1.8203 - val_acc: 0.2067\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7162 - acc: 0.2800 - val_loss: 1.8260 - val_acc: 0.2067\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.7138 - acc: 0.2829 - val_loss: 1.8158 - val_acc: 0.2667\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.7130 - acc: 0.2857 - val_loss: 1.8206 - val_acc: 0.2400\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.7124 - acc: 0.2971 - val_loss: 1.8229 - val_acc: 0.2133\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.7096 - acc: 0.2986 - val_loss: 1.8169 - val_acc: 0.2267\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.7078 - acc: 0.2757 - val_loss: 1.8158 - val_acc: 0.2633\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.7048 - acc: 0.3086 - val_loss: 1.8201 - val_acc: 0.2733\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.7059 - acc: 0.3043 - val_loss: 1.8131 - val_acc: 0.2433\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.7040 - acc: 0.3029 - val_loss: 1.8181 - val_acc: 0.2167\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.7025 - acc: 0.2829 - val_loss: 1.8167 - val_acc: 0.2233\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.7015 - acc: 0.3071 - val_loss: 1.8202 - val_acc: 0.2167\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6985 - acc: 0.3129 - val_loss: 1.8233 - val_acc: 0.2067\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6978 - acc: 0.3014 - val_loss: 1.8178 - val_acc: 0.2733\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6962 - acc: 0.3186 - val_loss: 1.8198 - val_acc: 0.2100\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.6936 - acc: 0.3043 - val_loss: 1.8252 - val_acc: 0.2833\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6942 - acc: 0.3071 - val_loss: 1.8119 - val_acc: 0.2200\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6923 - acc: 0.3071 - val_loss: 1.8264 - val_acc: 0.2200\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.6915 - acc: 0.3057 - val_loss: 1.8124 - val_acc: 0.2167\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.6895 - acc: 0.3129 - val_loss: 1.8250 - val_acc: 0.2200\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6882 - acc: 0.3043 - val_loss: 1.8225 - val_acc: 0.2300\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.6869 - acc: 0.3157 - val_loss: 1.8240 - val_acc: 0.2233\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.6869 - acc: 0.3043 - val_loss: 1.8230 - val_acc: 0.2300\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.6834 - acc: 0.3043 - val_loss: 1.8116 - val_acc: 0.2500\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.6834 - acc: 0.3171 - val_loss: 1.8144 - val_acc: 0.2167\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.6813 - acc: 0.3100 - val_loss: 1.8088 - val_acc: 0.2100\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6805 - acc: 0.3186 - val_loss: 1.8200 - val_acc: 0.2167\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6795 - acc: 0.3143 - val_loss: 1.8255 - val_acc: 0.2367\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.6775 - acc: 0.3143 - val_loss: 1.8198 - val_acc: 0.2767\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6771 - acc: 0.3143 - val_loss: 1.8200 - val_acc: 0.2333\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.6764 - acc: 0.3214 - val_loss: 1.8168 - val_acc: 0.2200\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.6765 - acc: 0.3057 - val_loss: 1.8224 - val_acc: 0.2267\n",
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.6734 - acc: 0.3186 - val_loss: 1.8218 - val_acc: 0.2267\n",
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.6725 - acc: 0.3143 - val_loss: 1.8204 - val_acc: 0.2367\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6714 - acc: 0.3086 - val_loss: 1.8224 - val_acc: 0.2200\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 92us/step - loss: 1.6699 - acc: 0.3171 - val_loss: 1.8156 - val_acc: 0.2367\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6689 - acc: 0.3243 - val_loss: 1.8308 - val_acc: 0.2300\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6684 - acc: 0.3143 - val_loss: 1.8230 - val_acc: 0.2300\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.6670 - acc: 0.3157 - val_loss: 1.8280 - val_acc: 0.2300\n",
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.6657 - acc: 0.3286 - val_loss: 1.8259 - val_acc: 0.2267\n",
      "Epoch 120/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 93us/step - loss: 1.6647 - acc: 0.3186 - val_loss: 1.8244 - val_acc: 0.2200\n",
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.6634 - acc: 0.3200 - val_loss: 1.8150 - val_acc: 0.2267\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6622 - acc: 0.3214 - val_loss: 1.8209 - val_acc: 0.2267\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.6614 - acc: 0.3229 - val_loss: 1.8173 - val_acc: 0.2233\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6601 - acc: 0.3186 - val_loss: 1.8245 - val_acc: 0.2367\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.6591 - acc: 0.3171 - val_loss: 1.8289 - val_acc: 0.2367\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 12us/step\n",
      "\n",
      "loss : 1.8434088474273682\n",
      "accuray : 0.2734\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "\n",
    "# 훈련셋과 시험셋 로딩\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋, 검증셋 고르기\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# 라벨링 전환\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "from keras.callbacks import EarlyStopping\n",
    "##early_stopping = EarlyStopping() # 조기종료 콜백함수 정의 ##keypoint\n",
    "early_stopping = EarlyStopping(patience = 20) # 조기종료 콜백함수 정의\n",
    "\n",
    "hist = model.fit(X_train, Y_train, epochs=3000, batch_size=10, validation_data=(X_val, Y_val), callbacks=[early_stopping])\n",
    "\n",
    "# 5. 모델 학습 과정 표시하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 6. 모델 사용하기\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "print('')\n",
    "print('loss : ' + str(loss_and_metrics[0]))\n",
    "print('accuray : ' + str(loss_and_metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
